{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Run_CV_Humour.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"fllY-TxkjyZq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596343272702,"user_tz":-330,"elapsed":39857,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"22338fec-e54d-44ae-83ac-409a4e1d7c77"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount = True)\n","import os\n","root_path = 'gdrive/My Drive/Code_Switch/'\n","os.chdir(root_path)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n0ZObXBPk8-F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1596343285053,"user_tz":-330,"elapsed":12195,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"0885dd68-6aed-44c4-a326-772f149354ed"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 34.6MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 44.9MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 37.4MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=16919c49c60b3b48a42d7d01e5816447eff78843095f9884f75b8112dc0f52b3\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F-i_0T3dJaxc","colab_type":"text"},"source":["22"]},{"cell_type":"code","metadata":{"id":"YVQT6s1wj9I_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596308267151,"user_tz":-330,"elapsed":1746032,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"8c120072-9703-48e3-9c32-9f93dad26c85"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-4 --num_labels 2"],"execution_count":3,"outputs":[{"output_type":"stream","text":["2020-08-01 17:55:26.597563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100% 996k/996k [00:01<00:00, 896kB/s]\n","Downloading: 100% 625/625 [00:00<00:00, 396kB/s]\n","Downloading: 100% 714M/714M [00:13<00:00, 53.8MB/s]\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6430, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.876686096191406\n","#############    Validation Set Stats\n","Total Validation Loss = 11.701240539550781\n","  Accuracy: 0.7339\n","  Micro F1: 0.7310\n","  Macro F1: 0.7290\n","\n"," 17% 1/6 [02:01<10:07, 121.53s/it]Loss = 0.0\n","Loss = tensor(0.5196, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.346370697021484\n","#############    Validation Set Stats\n","Total Validation Loss = 11.283238410949707\n","  Accuracy: 0.7448\n","  Micro F1: 0.7398\n","  Macro F1: 0.7377\n","\n"," 33% 2/6 [04:05<08:08, 122.22s/it]Loss = 0.0\n","Loss = tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.70330047607422\n","#############    Validation Set Stats\n","Total Validation Loss = 12.581235885620117\n","  Accuracy: 0.7202\n","  Micro F1: 0.7193\n","  Macro F1: 0.7192\n","\n"," 50% 3/6 [06:09<06:07, 122.66s/it]Loss = 0.0\n","Loss = tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.41151809692383\n","#############    Validation Set Stats\n","Total Validation Loss = 12.869606018066406\n","  Accuracy: 0.7154\n","  Micro F1: 0.7120\n","  Macro F1: 0.7119\n","\n"," 67% 4/6 [08:13<04:06, 123.06s/it]Loss = 0.0\n","Loss = tensor(0.3122, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.480493545532227\n","#############    Validation Set Stats\n","Total Validation Loss = 14.569860458374023\n","  Accuracy: 0.7140\n","  Micro F1: 0.7105\n","  Macro F1: 0.7105\n","\n"," 83% 5/6 [10:16<02:03, 123.21s/it]Loss = 0.0\n","Loss = tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.32379913330078\n","#############    Validation Set Stats\n","Total Validation Loss = 15.175219535827637\n","  Accuracy: 0.7098\n","  Micro F1: 0.7061\n","  Macro F1: 0.7061\n","\n","100% 6/6 [12:19<00:00, 123.30s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6681, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.50691604614258\n","#############    Validation Set Stats\n","Total Validation Loss = 12.74897289276123\n","  Accuracy: 0.7012\n","  Micro F1: 0.6974\n","  Macro F1: 0.6966\n","\n"," 17% 1/6 [02:03<10:16, 123.20s/it]Loss = 0.0\n","Loss = tensor(0.5215, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.72391891479492\n","#############    Validation Set Stats\n","Total Validation Loss = 12.30334758758545\n","  Accuracy: 0.7027\n","  Micro F1: 0.6988\n","  Macro F1: 0.6896\n","\n"," 33% 2/6 [04:06<08:12, 123.15s/it]Loss = 0.0\n","Loss = tensor(0.4624, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.07315444946289\n","#############    Validation Set Stats\n","Total Validation Loss = 12.547964096069336\n","  Accuracy: 0.7045\n","  Micro F1: 0.7032\n","  Macro F1: 0.6949\n","\n"," 50% 3/6 [06:09<06:09, 123.16s/it]Loss = 0.0\n","Loss = tensor(0.3993, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.46046447753906\n","#############    Validation Set Stats\n","Total Validation Loss = 12.855218887329102\n","  Accuracy: 0.7145\n","  Micro F1: 0.7135\n","  Macro F1: 0.7112\n","\n"," 67% 4/6 [08:12<04:06, 123.16s/it]Loss = 0.0\n","Loss = tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.525081634521484\n","#############    Validation Set Stats\n","Total Validation Loss = 14.000419616699219\n","  Accuracy: 0.7045\n","  Micro F1: 0.7032\n","  Macro F1: 0.7028\n","\n"," 83% 5/6 [10:15<02:03, 123.11s/it]Loss = 0.0\n","Loss = tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.327383041381836\n","#############    Validation Set Stats\n","Total Validation Loss = 14.725043296813965\n","  Accuracy: 0.7154\n","  Micro F1: 0.7120\n","  Macro F1: 0.7114\n","\n","100% 6/6 [12:18<00:00, 123.16s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6544, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.04106903076172\n","#############    Validation Set Stats\n","Total Validation Loss = 11.960890769958496\n","  Accuracy: 0.7183\n","  Micro F1: 0.7222\n","  Macro F1: 0.7201\n","\n"," 17% 1/6 [02:03<10:15, 123.17s/it]Loss = 0.0\n","Loss = tensor(0.4946, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.846405029296875\n","#############    Validation Set Stats\n","Total Validation Loss = 11.977945327758789\n","  Accuracy: 0.7088\n","  Micro F1: 0.7149\n","  Macro F1: 0.7141\n","\n"," 33% 2/6 [04:06<08:13, 123.36s/it]Loss = 0.0\n","Loss = tensor(0.4351, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.40388870239258\n","#############    Validation Set Stats\n","Total Validation Loss = 12.266386985778809\n","  Accuracy: 0.7116\n","  Micro F1: 0.7105\n","  Macro F1: 0.7076\n","\n"," 50% 3/6 [06:10<06:10, 123.35s/it]Loss = 0.0\n","Loss = tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.821250915527344\n","#############    Validation Set Stats\n","Total Validation Loss = 14.013084411621094\n","  Accuracy: 0.6894\n","  Micro F1: 0.6901\n","  Macro F1: 0.6900\n","\n"," 67% 4/6 [08:13<04:06, 123.24s/it]Loss = 0.0\n","Loss = tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.138790130615234\n","#############    Validation Set Stats\n","Total Validation Loss = 15.464906692504883\n","  Accuracy: 0.6780\n","  Micro F1: 0.6784\n","  Macro F1: 0.6783\n","\n"," 83% 5/6 [10:16<02:03, 123.33s/it]Loss = 0.0\n","Loss = tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.43890953063965\n","#############    Validation Set Stats\n","Total Validation Loss = 15.838257789611816\n","  Accuracy: 0.6851\n","  Micro F1: 0.6857\n","  Macro F1: 0.6849\n","\n","100% 6/6 [12:20<00:00, 123.43s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6511, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.14366912841797\n","#############    Validation Set Stats\n","Total Validation Loss = 11.766585350036621\n","  Accuracy: 0.7110\n","  Micro F1: 0.7189\n","  Macro F1: 0.7188\n","\n"," 17% 1/6 [02:03<10:15, 123.09s/it]Loss = 0.0\n","Loss = tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.696990966796875\n","#############    Validation Set Stats\n","Total Validation Loss = 11.495098114013672\n","  Accuracy: 0.7351\n","  Micro F1: 0.7438\n","  Macro F1: 0.7406\n","\n"," 33% 2/6 [04:05<08:11, 122.89s/it]Loss = 0.0\n","Loss = tensor(0.4726, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.30705261230469\n","#############    Validation Set Stats\n","Total Validation Loss = 14.27978515625\n","  Accuracy: 0.6813\n","  Micro F1: 0.6911\n","  Macro F1: 0.6861\n","\n"," 50% 3/6 [06:07<06:07, 122.60s/it]Loss = 0.0\n","Loss = tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.900264739990234\n","#############    Validation Set Stats\n","Total Validation Loss = 13.98355770111084\n","  Accuracy: 0.7014\n","  Micro F1: 0.7174\n","  Macro F1: 0.7171\n","\n"," 67% 4/6 [08:09<04:05, 122.51s/it]Loss = 0.0\n","Loss = tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.575796127319336\n","#############    Validation Set Stats\n","Total Validation Loss = 14.983987808227539\n","  Accuracy: 0.6985\n","  Micro F1: 0.7116\n","  Macro F1: 0.7116\n","\n"," 83% 5/6 [10:12<02:02, 122.58s/it]Loss = 0.0\n","Loss = tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.803363800048828\n","#############    Validation Set Stats\n","Total Validation Loss = 16.210893630981445\n","  Accuracy: 0.6773\n","  Micro F1: 0.6925\n","  Macro F1: 0.6923\n","\n","100% 6/6 [12:14<00:00, 122.46s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6413, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.770599365234375\n","#############    Validation Set Stats\n","Total Validation Loss = 13.30752182006836\n","  Accuracy: 0.6399\n","  Micro F1: 0.6428\n","  Macro F1: 0.6264\n","\n"," 17% 1/6 [02:02<10:11, 122.21s/it]Loss = 0.0\n","Loss = tensor(0.4940, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.15689468383789\n","#############    Validation Set Stats\n","Total Validation Loss = 11.652030944824219\n","  Accuracy: 0.7274\n","  Micro F1: 0.7218\n","  Macro F1: 0.7115\n","\n"," 33% 2/6 [04:04<08:08, 122.25s/it]Loss = 0.0\n","Loss = tensor(0.4554, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.842498779296875\n","#############    Validation Set Stats\n","Total Validation Loss = 11.730609893798828\n","  Accuracy: 0.7288\n","  Micro F1: 0.7233\n","  Macro F1: 0.7135\n","\n"," 50% 3/6 [06:06<06:06, 122.29s/it]Loss = 0.0\n","Loss = tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.724300384521484\n","#############    Validation Set Stats\n","Total Validation Loss = 15.1388521194458\n","  Accuracy: 0.6767\n","  Micro F1: 0.6779\n","  Macro F1: 0.6759\n","\n"," 67% 4/6 [08:08<04:04, 122.15s/it]Loss = 0.0\n","Loss = tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.354442596435547\n","#############    Validation Set Stats\n","Total Validation Loss = 15.873841285705566\n","  Accuracy: 0.6822\n","  Micro F1: 0.6808\n","  Macro F1: 0.6803\n","\n"," 83% 5/6 [10:10<02:02, 122.11s/it]Loss = 0.0\n","Loss = tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.974929809570312\n","#############    Validation Set Stats\n","Total Validation Loss = 16.429601669311523\n","  Accuracy: 0.6907\n","  Micro F1: 0.6896\n","  Macro F1: 0.6887\n","\n","100% 6/6 [12:12<00:00, 122.15s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7285\n","  Micro F1: 0.7282\n","  Macro F1: 0.7247\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r6GIr9rIJHDX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596311988758,"user_tz":-330,"elapsed":3721629,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"99b7189c-0007-49c6-8021-3ba00a577fa6"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":4,"outputs":[{"output_type":"stream","text":["2020-08-01 18:57:53.038902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6848, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 59.17852020263672\n","#############    Validation Set Stats\n","Total Validation Loss = 13.896296501159668\n","  Accuracy: 0.6686\n","  Micro F1: 0.6637\n","  Macro F1: 0.6637\n","\n"," 17% 1/6 [02:03<10:16, 123.25s/it]Loss = 0.0\n","Loss = tensor(0.5702, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.43939971923828\n","#############    Validation Set Stats\n","Total Validation Loss = 12.203346252441406\n","  Accuracy: 0.7259\n","  Micro F1: 0.7178\n","  Macro F1: 0.7159\n","\n"," 33% 2/6 [04:07<08:14, 123.60s/it]Loss = 0.0\n","Loss = tensor(0.4921, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.01942443847656\n","#############    Validation Set Stats\n","Total Validation Loss = 11.600153923034668\n","  Accuracy: 0.7353\n","  Micro F1: 0.7325\n","  Macro F1: 0.7323\n","\n"," 50% 3/6 [06:12<06:11, 123.90s/it]Loss = 0.0\n","Loss = tensor(0.4236, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.360572814941406\n","#############    Validation Set Stats\n","Total Validation Loss = 11.844783782958984\n","  Accuracy: 0.7311\n","  Micro F1: 0.7281\n","  Macro F1: 0.7280\n","\n"," 67% 4/6 [08:16<04:07, 123.90s/it]Loss = 0.0\n","Loss = tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.808666229248047\n","#############    Validation Set Stats\n","Total Validation Loss = 13.416213035583496\n","  Accuracy: 0.7003\n","  Micro F1: 0.6988\n","  Macro F1: 0.6988\n","\n"," 83% 5/6 [10:20<02:04, 124.08s/it]Loss = 0.0\n","Loss = tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.03162956237793\n","#############    Validation Set Stats\n","Total Validation Loss = 14.652702331542969\n","  Accuracy: 0.7003\n","  Micro F1: 0.6988\n","  Macro F1: 0.6985\n","\n","100% 6/6 [12:23<00:00, 123.98s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6581, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.48354721069336\n","#############    Validation Set Stats\n","Total Validation Loss = 12.840492248535156\n","  Accuracy: 0.7083\n","  Micro F1: 0.7047\n","  Macro F1: 0.6977\n","\n"," 17% 1/6 [02:02<10:14, 122.83s/it]Loss = 0.0\n","Loss = tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.406009674072266\n","#############    Validation Set Stats\n","Total Validation Loss = 12.794315338134766\n","  Accuracy: 0.6766\n","  Micro F1: 0.6769\n","  Macro F1: 0.6708\n","\n"," 33% 2/6 [04:06<08:12, 123.04s/it]Loss = 0.0\n","Loss = tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.95075225830078\n","#############    Validation Set Stats\n","Total Validation Loss = 12.367523193359375\n","  Accuracy: 0.7150\n","  Micro F1: 0.7164\n","  Macro F1: 0.7163\n","\n"," 50% 3/6 [06:09<06:08, 122.97s/it]Loss = 0.0\n","Loss = tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.23383331298828\n","#############    Validation Set Stats\n","Total Validation Loss = 13.802665710449219\n","  Accuracy: 0.7135\n","  Micro F1: 0.7149\n","  Macro F1: 0.7146\n","\n"," 67% 4/6 [08:12<04:06, 123.05s/it]Loss = 0.0\n","Loss = tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.732675552368164\n","#############    Validation Set Stats\n","Total Validation Loss = 14.731945037841797\n","  Accuracy: 0.7083\n","  Micro F1: 0.7047\n","  Macro F1: 0.7047\n","\n"," 83% 5/6 [10:15<02:03, 123.02s/it]Loss = 0.0\n","Loss = tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.346492767333984\n","#############    Validation Set Stats\n","Total Validation Loss = 16.076921463012695\n","  Accuracy: 0.7135\n","  Micro F1: 0.7076\n","  Macro F1: 0.7076\n","\n","100% 6/6 [12:18<00:00, 123.00s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6688, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.36029815673828\n","#############    Validation Set Stats\n","Total Validation Loss = 12.306475639343262\n","  Accuracy: 0.6970\n","  Micro F1: 0.7003\n","  Macro F1: 0.6960\n","\n"," 17% 1/6 [02:02<10:12, 122.57s/it]Loss = 0.0\n","Loss = tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.553916931152344\n","#############    Validation Set Stats\n","Total Validation Loss = 12.242860794067383\n","  Accuracy: 0.6903\n","  Micro F1: 0.6959\n","  Macro F1: 0.6957\n","\n"," 33% 2/6 [04:05<08:10, 122.68s/it]Loss = 0.0\n","Loss = tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.89140319824219\n","#############    Validation Set Stats\n","Total Validation Loss = 12.406928062438965\n","  Accuracy: 0.7031\n","  Micro F1: 0.7091\n","  Macro F1: 0.7079\n","\n"," 50% 3/6 [06:08<06:08, 122.68s/it]Loss = 0.0\n","Loss = tensor(0.3749, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.748815536499023\n","#############    Validation Set Stats\n","Total Validation Loss = 14.879999160766602\n","  Accuracy: 0.6889\n","  Micro F1: 0.6944\n","  Macro F1: 0.6933\n","\n"," 67% 4/6 [08:11<04:05, 122.75s/it]Loss = 0.0\n","Loss = tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.550697326660156\n","#############    Validation Set Stats\n","Total Validation Loss = 16.72295570373535\n","  Accuracy: 0.6676\n","  Micro F1: 0.6725\n","  Macro F1: 0.6717\n","\n"," 83% 5/6 [10:13<02:02, 122.75s/it]Loss = 0.0\n","Loss = tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.46676254272461\n","#############    Validation Set Stats\n","Total Validation Loss = 17.86670684814453\n","  Accuracy: 0.6714\n","  Micro F1: 0.6740\n","  Macro F1: 0.6727\n","\n","100% 6/6 [12:16<00:00, 122.81s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.75947570800781\n","#############    Validation Set Stats\n","Total Validation Loss = 11.878181457519531\n","  Accuracy: 0.7194\n","  Micro F1: 0.7247\n","  Macro F1: 0.7242\n","\n"," 17% 1/6 [02:03<10:15, 123.12s/it]Loss = 0.0\n","Loss = tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.90868377685547\n","#############    Validation Set Stats\n","Total Validation Loss = 11.739762306213379\n","  Accuracy: 0.7180\n","  Micro F1: 0.7233\n","  Macro F1: 0.7100\n","\n"," 33% 2/6 [04:05<08:11, 123.00s/it]Loss = 0.0\n","Loss = tensor(0.4628, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.470489501953125\n","#############    Validation Set Stats\n","Total Validation Loss = 12.343162536621094\n","  Accuracy: 0.7067\n","  Micro F1: 0.7145\n","  Macro F1: 0.7143\n","\n"," 50% 3/6 [06:08<06:08, 122.96s/it]Loss = 0.0\n","Loss = tensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.64642333984375\n","#############    Validation Set Stats\n","Total Validation Loss = 14.228145599365234\n","  Accuracy: 0.6839\n","  Micro F1: 0.6881\n","  Macro F1: 0.6879\n","\n"," 67% 4/6 [08:11<04:06, 123.05s/it]Loss = 0.0\n","Loss = tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.86420440673828\n","#############    Validation Set Stats\n","Total Validation Loss = 15.701496124267578\n","  Accuracy: 0.6996\n","  Micro F1: 0.7072\n","  Macro F1: 0.7040\n","\n"," 83% 5/6 [10:14<02:02, 122.98s/it]Loss = 0.0\n","Loss = tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.752147674560547\n","#############    Validation Set Stats\n","Total Validation Loss = 16.554443359375\n","  Accuracy: 0.6938\n","  Micro F1: 0.6984\n","  Macro F1: 0.6978\n","\n","100% 6/6 [12:17<00:00, 122.90s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6591, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.49998092651367\n","#############    Validation Set Stats\n","Total Validation Loss = 14.04153060913086\n","  Accuracy: 0.6568\n","  Micro F1: 0.6574\n","  Macro F1: 0.6421\n","\n"," 17% 1/6 [02:03<10:15, 123.02s/it]Loss = 0.0\n","Loss = tensor(0.4926, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.22358703613281\n","#############    Validation Set Stats\n","Total Validation Loss = 11.621625900268555\n","  Accuracy: 0.7389\n","  Micro F1: 0.7365\n","  Macro F1: 0.7353\n","\n"," 33% 2/6 [04:05<08:11, 122.93s/it]Loss = 0.0\n","Loss = tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.2874870300293\n","#############    Validation Set Stats\n","Total Validation Loss = 13.701648712158203\n","  Accuracy: 0.7035\n","  Micro F1: 0.7028\n","  Macro F1: 0.6991\n","\n"," 50% 3/6 [06:08<06:08, 122.93s/it]Loss = 0.0\n","Loss = tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.64457321166992\n","#############    Validation Set Stats\n","Total Validation Loss = 13.461505889892578\n","  Accuracy: 0.7150\n","  Micro F1: 0.7174\n","  Macro F1: 0.7174\n","\n"," 67% 4/6 [08:11<04:05, 122.85s/it]Loss = 0.0\n","Loss = tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.19747543334961\n","#############    Validation Set Stats\n","Total Validation Loss = 14.371467590332031\n","  Accuracy: 0.7193\n","  Micro F1: 0.7218\n","  Macro F1: 0.7212\n","\n"," 83% 5/6 [10:14<02:02, 122.88s/it]Loss = 0.0\n","Loss = tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.64794158935547\n","#############    Validation Set Stats\n","Total Validation Loss = 15.893345832824707\n","  Accuracy: 0.7164\n","  Micro F1: 0.7189\n","  Macro F1: 0.7188\n","\n","100% 6/6 [12:18<00:00, 123.12s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7223\n","  Micro F1: 0.7238\n","  Macro F1: 0.7232\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8u9RYHGiJG4p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596315776065,"user_tz":-330,"elapsed":3787328,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"1a8e8cb4-a220-4ce0-a2ff-0e6ba3c0dcb5"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-4 --num_labels 2 "],"execution_count":5,"outputs":[{"output_type":"stream","text":["2020-08-01 19:59:54.650942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6801, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.739986419677734\n","#############    Validation Set Stats\n","Total Validation Loss = 11.723268508911133\n","  Accuracy: 0.7367\n","  Micro F1: 0.7339\n","  Macro F1: 0.7339\n","\n"," 17% 1/6 [02:04<10:24, 124.87s/it]Loss = 0.0\n","Loss = tensor(0.5214, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.51272201538086\n","#############    Validation Set Stats\n","Total Validation Loss = 11.073301315307617\n","  Accuracy: 0.7524\n","  Micro F1: 0.7500\n","  Macro F1: 0.7461\n","\n"," 33% 2/6 [04:09<08:19, 124.93s/it]Loss = 0.0\n","Loss = tensor(0.4426, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.92362976074219\n","#############    Validation Set Stats\n","Total Validation Loss = 11.043920516967773\n","  Accuracy: 0.7633\n","  Micro F1: 0.7588\n","  Macro F1: 0.7580\n","\n"," 50% 3/6 [06:14<06:14, 124.95s/it]Loss = 0.0\n","Loss = tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.285953521728516\n","#############    Validation Set Stats\n","Total Validation Loss = 11.868420600891113\n","  Accuracy: 0.7509\n","  Micro F1: 0.7485\n","  Macro F1: 0.7473\n","\n"," 67% 4/6 [08:20<04:10, 125.17s/it]Loss = 0.0\n","Loss = tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.012907028198242\n","#############    Validation Set Stats\n","Total Validation Loss = 13.025598526000977\n","  Accuracy: 0.7467\n","  Micro F1: 0.7442\n","  Macro F1: 0.7421\n","\n"," 83% 5/6 [10:26<02:05, 125.26s/it]Loss = 0.0\n","Loss = tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.113040924072266\n","#############    Validation Set Stats\n","Total Validation Loss = 13.956756591796875\n","  Accuracy: 0.7268\n","  Micro F1: 0.7237\n","  Macro F1: 0.7223\n","\n","100% 6/6 [12:31<00:00, 125.20s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6879, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 59.588958740234375\n","#############    Validation Set Stats\n","Total Validation Loss = 14.789600372314453\n","  Accuracy: 0.5705\n","  Micro F1: 0.5702\n","  Macro F1: 0.5397\n","\n"," 17% 1/6 [02:04<10:24, 124.92s/it]Loss = 0.0\n","Loss = tensor(0.5947, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.512184143066406\n","#############    Validation Set Stats\n","Total Validation Loss = 12.231728553771973\n","  Accuracy: 0.7102\n","  Micro F1: 0.7091\n","  Macro F1: 0.7090\n","\n"," 33% 2/6 [04:10<08:20, 125.09s/it]Loss = 0.0\n","Loss = tensor(0.4887, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.38919448852539\n","#############    Validation Set Stats\n","Total Validation Loss = 11.618910789489746\n","  Accuracy: 0.7164\n","  Micro F1: 0.7105\n","  Macro F1: 0.7098\n","\n"," 50% 3/6 [06:16<06:15, 125.26s/it]Loss = 0.0\n","Loss = tensor(0.4668, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.372982025146484\n","#############    Validation Set Stats\n","Total Validation Loss = 12.413402557373047\n","  Accuracy: 0.7225\n","  Micro F1: 0.7193\n","  Macro F1: 0.7180\n","\n"," 67% 4/6 [08:21<04:10, 125.32s/it]Loss = 0.0\n","Loss = tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.961341857910156\n","#############    Validation Set Stats\n","Total Validation Loss = 13.124493598937988\n","  Accuracy: 0.7140\n","  Micro F1: 0.7105\n","  Macro F1: 0.7104\n","\n"," 83% 5/6 [10:26<02:05, 125.28s/it]Loss = 0.0\n","Loss = tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.736387252807617\n","#############    Validation Set Stats\n","Total Validation Loss = 14.232707023620605\n","  Accuracy: 0.7083\n","  Micro F1: 0.7047\n","  Macro F1: 0.7046\n","\n","100% 6/6 [12:32<00:00, 125.34s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6540, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.8683967590332\n","#############    Validation Set Stats\n","Total Validation Loss = 13.074304580688477\n","  Accuracy: 0.6742\n","  Micro F1: 0.6842\n","  Macro F1: 0.6831\n","\n"," 17% 1/6 [02:05<10:26, 125.40s/it]Loss = 0.0\n","Loss = tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.31538009643555\n","#############    Validation Set Stats\n","Total Validation Loss = 11.972210884094238\n","  Accuracy: 0.6913\n","  Micro F1: 0.6944\n","  Macro F1: 0.6934\n","\n"," 33% 2/6 [04:10<08:21, 125.32s/it]Loss = 0.0\n","Loss = tensor(0.4316, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.041038513183594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.542407035827637\n","  Accuracy: 0.6809\n","  Micro F1: 0.6886\n","  Macro F1: 0.6885\n","\n"," 50% 3/6 [06:16<06:16, 125.39s/it]Loss = 0.0\n","Loss = tensor(0.3565, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.47550964355469\n","#############    Validation Set Stats\n","Total Validation Loss = 14.25173282623291\n","  Accuracy: 0.6785\n","  Micro F1: 0.6886\n","  Macro F1: 0.6880\n","\n"," 67% 4/6 [08:21<04:10, 125.35s/it]Loss = 0.0\n","Loss = tensor(0.3049, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.434968948364258\n","#############    Validation Set Stats\n","Total Validation Loss = 16.517608642578125\n","  Accuracy: 0.6624\n","  Micro F1: 0.6696\n","  Macro F1: 0.6692\n","\n"," 83% 5/6 [10:26<02:05, 125.38s/it]Loss = 0.0\n","Loss = tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.38855743408203\n","#############    Validation Set Stats\n","Total Validation Loss = 18.270479202270508\n","  Accuracy: 0.6600\n","  Micro F1: 0.6696\n","  Macro F1: 0.6696\n","\n","100% 6/6 [12:32<00:00, 125.43s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.228309631347656\n","#############    Validation Set Stats\n","Total Validation Loss = 13.609212875366211\n","  Accuracy: 0.6513\n","  Micro F1: 0.6574\n","  Macro F1: 0.6463\n","\n"," 17% 1/6 [02:05<10:25, 125.11s/it]Loss = 0.0\n","Loss = tensor(0.5271, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.70703125\n","#############    Validation Set Stats\n","Total Validation Loss = 11.572602272033691\n","  Accuracy: 0.7437\n","  Micro F1: 0.7526\n","  Macro F1: 0.7520\n","\n"," 33% 2/6 [04:10<08:20, 125.19s/it]Loss = 0.0\n","Loss = tensor(0.4316, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.004486083984375\n","#############    Validation Set Stats\n","Total Validation Loss = 12.534770965576172\n","  Accuracy: 0.7054\n","  Micro F1: 0.7160\n","  Macro F1: 0.7159\n","\n"," 50% 3/6 [06:16<06:15, 125.30s/it]Loss = 0.0\n","Loss = tensor(0.3723, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.81400489807129\n","#############    Validation Set Stats\n","Total Validation Loss = 14.077107429504395\n","  Accuracy: 0.6910\n","  Micro F1: 0.6955\n","  Macro F1: 0.6923\n","\n"," 67% 4/6 [08:21<04:10, 125.28s/it]Loss = 0.0\n","Loss = tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.861217498779297\n","#############    Validation Set Stats\n","Total Validation Loss = 16.947797775268555\n","  Accuracy: 0.6601\n","  Micro F1: 0.6720\n","  Macro F1: 0.6718\n","\n"," 83% 5/6 [10:26<02:05, 125.34s/it]Loss = 0.0\n","Loss = tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.69404411315918\n","#############    Validation Set Stats\n","Total Validation Loss = 17.737783432006836\n","  Accuracy: 0.6701\n","  Micro F1: 0.6823\n","  Macro F1: 0.6822\n","\n","100% 6/6 [12:32<00:00, 125.40s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6749, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.42135238647461\n","#############    Validation Set Stats\n","Total Validation Loss = 12.381363868713379\n","  Accuracy: 0.7133\n","  Micro F1: 0.7101\n","  Macro F1: 0.7039\n","\n"," 17% 1/6 [02:05<10:25, 125.13s/it]Loss = 0.0\n","Loss = tensor(0.5272, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.266788482666016\n","#############    Validation Set Stats\n","Total Validation Loss = 11.792561531066895\n","  Accuracy: 0.7220\n","  Micro F1: 0.7218\n","  Macro F1: 0.7205\n","\n"," 33% 2/6 [04:10<08:21, 125.32s/it]Loss = 0.0\n","Loss = tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.420677185058594\n","#############    Validation Set Stats\n","Total Validation Loss = 12.865447998046875\n","  Accuracy: 0.7234\n","  Micro F1: 0.7233\n","  Macro F1: 0.7230\n","\n"," 50% 3/6 [06:16<06:16, 125.36s/it]Loss = 0.0\n","Loss = tensor(0.3761, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.394681930541992\n","#############    Validation Set Stats\n","Total Validation Loss = 14.377713203430176\n","  Accuracy: 0.7135\n","  Micro F1: 0.7130\n","  Macro F1: 0.7130\n","\n"," 67% 4/6 [08:21<04:10, 125.30s/it]Loss = 0.0\n","Loss = tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.45438575744629\n","#############    Validation Set Stats\n","Total Validation Loss = 16.514022827148438\n","  Accuracy: 0.6950\n","  Micro F1: 0.6940\n","  Macro F1: 0.6939\n","\n"," 83% 5/6 [10:26<02:05, 125.24s/it]Loss = 0.0\n","Loss = tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 19.980052947998047\n","#############    Validation Set Stats\n","Total Validation Loss = 17.781890869140625\n","  Accuracy: 0.7021\n","  Micro F1: 0.7013\n","  Macro F1: 0.7012\n","\n","100% 6/6 [12:32<00:00, 125.42s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7288\n","  Micro F1: 0.7297\n","  Macro F1: 0.7289\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U0blPJjcJDHZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596319511304,"user_tz":-330,"elapsed":3735254,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"bed76a7e-5584-4041-8734-bfc315313e3b"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-3 --num_labels 2 "],"execution_count":6,"outputs":[{"output_type":"stream","text":["2020-08-01 21:03:02.247299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6430, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.876686096191406\n","#############    Validation Set Stats\n","Total Validation Loss = 11.701240539550781\n","  Accuracy: 0.7339\n","  Micro F1: 0.7310\n","  Macro F1: 0.7290\n","\n"," 17% 1/6 [02:03<10:17, 123.42s/it]Loss = 0.0\n","Loss = tensor(0.5196, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.346370697021484\n","#############    Validation Set Stats\n","Total Validation Loss = 11.283238410949707\n","  Accuracy: 0.7448\n","  Micro F1: 0.7398\n","  Macro F1: 0.7377\n","\n"," 33% 2/6 [04:07<08:14, 123.56s/it]Loss = 0.0\n","Loss = tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.70330047607422\n","#############    Validation Set Stats\n","Total Validation Loss = 12.581235885620117\n","  Accuracy: 0.7202\n","  Micro F1: 0.7193\n","  Macro F1: 0.7192\n","\n"," 50% 3/6 [06:10<06:10, 123.57s/it]Loss = 0.0\n","Loss = tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.41151809692383\n","#############    Validation Set Stats\n","Total Validation Loss = 12.869606018066406\n","  Accuracy: 0.7154\n","  Micro F1: 0.7120\n","  Macro F1: 0.7119\n","\n"," 67% 4/6 [08:14<04:07, 123.65s/it]Loss = 0.0\n","Loss = tensor(0.3122, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.480493545532227\n","#############    Validation Set Stats\n","Total Validation Loss = 14.569860458374023\n","  Accuracy: 0.7140\n","  Micro F1: 0.7105\n","  Macro F1: 0.7105\n","\n"," 83% 5/6 [10:18<02:03, 123.63s/it]Loss = 0.0\n","Loss = tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.32379913330078\n","#############    Validation Set Stats\n","Total Validation Loss = 15.175219535827637\n","  Accuracy: 0.7098\n","  Micro F1: 0.7061\n","  Macro F1: 0.7061\n","\n","100% 6/6 [12:21<00:00, 123.60s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6681, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.50691604614258\n","#############    Validation Set Stats\n","Total Validation Loss = 12.74897289276123\n","  Accuracy: 0.7012\n","  Micro F1: 0.6974\n","  Macro F1: 0.6966\n","\n"," 17% 1/6 [02:03<10:17, 123.46s/it]Loss = 0.0\n","Loss = tensor(0.5215, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.72391891479492\n","#############    Validation Set Stats\n","Total Validation Loss = 12.30334758758545\n","  Accuracy: 0.7027\n","  Micro F1: 0.6988\n","  Macro F1: 0.6896\n","\n"," 33% 2/6 [04:07<08:14, 123.50s/it]Loss = 0.0\n","Loss = tensor(0.4624, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.07315444946289\n","#############    Validation Set Stats\n","Total Validation Loss = 12.547964096069336\n","  Accuracy: 0.7045\n","  Micro F1: 0.7032\n","  Macro F1: 0.6949\n","\n"," 50% 3/6 [06:10<06:10, 123.46s/it]Loss = 0.0\n","Loss = tensor(0.3993, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.46046447753906\n","#############    Validation Set Stats\n","Total Validation Loss = 12.855218887329102\n","  Accuracy: 0.7145\n","  Micro F1: 0.7135\n","  Macro F1: 0.7112\n","\n"," 67% 4/6 [08:14<04:07, 123.53s/it]Loss = 0.0\n","Loss = tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.525081634521484\n","#############    Validation Set Stats\n","Total Validation Loss = 14.000419616699219\n","  Accuracy: 0.7045\n","  Micro F1: 0.7032\n","  Macro F1: 0.7028\n","\n"," 83% 5/6 [10:17<02:03, 123.45s/it]Loss = 0.0\n","Loss = tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.327383041381836\n","#############    Validation Set Stats\n","Total Validation Loss = 14.725043296813965\n","  Accuracy: 0.7154\n","  Micro F1: 0.7120\n","  Macro F1: 0.7114\n","\n","100% 6/6 [12:20<00:00, 123.48s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6544, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.04106903076172\n","#############    Validation Set Stats\n","Total Validation Loss = 11.960890769958496\n","  Accuracy: 0.7183\n","  Micro F1: 0.7222\n","  Macro F1: 0.7201\n","\n"," 17% 1/6 [02:03<10:16, 123.38s/it]Loss = 0.0\n","Loss = tensor(0.4946, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.846405029296875\n","#############    Validation Set Stats\n","Total Validation Loss = 11.977945327758789\n","  Accuracy: 0.7088\n","  Micro F1: 0.7149\n","  Macro F1: 0.7141\n","\n"," 33% 2/6 [04:07<08:14, 123.57s/it]Loss = 0.0\n","Loss = tensor(0.4351, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.40388870239258\n","#############    Validation Set Stats\n","Total Validation Loss = 12.266386985778809\n","  Accuracy: 0.7116\n","  Micro F1: 0.7105\n","  Macro F1: 0.7076\n","\n"," 50% 3/6 [06:11<06:10, 123.59s/it]Loss = 0.0\n","Loss = tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.821250915527344\n","#############    Validation Set Stats\n","Total Validation Loss = 14.013084411621094\n","  Accuracy: 0.6894\n","  Micro F1: 0.6901\n","  Macro F1: 0.6900\n","\n"," 67% 4/6 [08:14<04:07, 123.51s/it]Loss = 0.0\n","Loss = tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.138790130615234\n","#############    Validation Set Stats\n","Total Validation Loss = 15.464906692504883\n","  Accuracy: 0.6780\n","  Micro F1: 0.6784\n","  Macro F1: 0.6783\n","\n"," 83% 5/6 [10:17<02:03, 123.40s/it]Loss = 0.0\n","Loss = tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.43890953063965\n","#############    Validation Set Stats\n","Total Validation Loss = 15.838257789611816\n","  Accuracy: 0.6851\n","  Micro F1: 0.6857\n","  Macro F1: 0.6849\n","\n","100% 6/6 [12:21<00:00, 123.55s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6511, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.14366912841797\n","#############    Validation Set Stats\n","Total Validation Loss = 11.766585350036621\n","  Accuracy: 0.7110\n","  Micro F1: 0.7189\n","  Macro F1: 0.7188\n","\n"," 17% 1/6 [02:03<10:19, 123.87s/it]Loss = 0.0\n","Loss = tensor(0.5240, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.696990966796875\n","#############    Validation Set Stats\n","Total Validation Loss = 11.495098114013672\n","  Accuracy: 0.7351\n","  Micro F1: 0.7438\n","  Macro F1: 0.7406\n","\n"," 33% 2/6 [04:07<08:15, 123.82s/it]Loss = 0.0\n","Loss = tensor(0.4726, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.30705261230469\n","#############    Validation Set Stats\n","Total Validation Loss = 14.27978515625\n","  Accuracy: 0.6813\n","  Micro F1: 0.6911\n","  Macro F1: 0.6861\n","\n"," 50% 3/6 [06:10<06:10, 123.66s/it]Loss = 0.0\n","Loss = tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.900264739990234\n","#############    Validation Set Stats\n","Total Validation Loss = 13.98355770111084\n","  Accuracy: 0.7014\n","  Micro F1: 0.7174\n","  Macro F1: 0.7171\n","\n"," 67% 4/6 [08:14<04:07, 123.68s/it]Loss = 0.0\n","Loss = tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.575796127319336\n","#############    Validation Set Stats\n","Total Validation Loss = 14.983987808227539\n","  Accuracy: 0.6985\n","  Micro F1: 0.7116\n","  Macro F1: 0.7116\n","\n"," 83% 5/6 [10:18<02:03, 123.77s/it]Loss = 0.0\n","Loss = tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.803363800048828\n","#############    Validation Set Stats\n","Total Validation Loss = 16.210893630981445\n","  Accuracy: 0.6773\n","  Micro F1: 0.6925\n","  Macro F1: 0.6923\n","\n","100% 6/6 [12:22<00:00, 123.71s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6413, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.770599365234375\n","#############    Validation Set Stats\n","Total Validation Loss = 13.30752182006836\n","  Accuracy: 0.6399\n","  Micro F1: 0.6428\n","  Macro F1: 0.6264\n","\n"," 17% 1/6 [02:03<10:17, 123.41s/it]Loss = 0.0\n","Loss = tensor(0.4940, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.15689468383789\n","#############    Validation Set Stats\n","Total Validation Loss = 11.652030944824219\n","  Accuracy: 0.7274\n","  Micro F1: 0.7218\n","  Macro F1: 0.7115\n","\n"," 33% 2/6 [04:07<08:14, 123.52s/it]Loss = 0.0\n","Loss = tensor(0.4554, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.842498779296875\n","#############    Validation Set Stats\n","Total Validation Loss = 11.730609893798828\n","  Accuracy: 0.7288\n","  Micro F1: 0.7233\n","  Macro F1: 0.7135\n","\n"," 50% 3/6 [06:11<06:11, 123.68s/it]Loss = 0.0\n","Loss = tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.724300384521484\n","#############    Validation Set Stats\n","Total Validation Loss = 15.1388521194458\n","  Accuracy: 0.6767\n","  Micro F1: 0.6779\n","  Macro F1: 0.6759\n","\n"," 67% 4/6 [08:14<04:07, 123.65s/it]Loss = 0.0\n","Loss = tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.354442596435547\n","#############    Validation Set Stats\n","Total Validation Loss = 15.873841285705566\n","  Accuracy: 0.6822\n","  Micro F1: 0.6808\n","  Macro F1: 0.6803\n","\n"," 83% 5/6 [10:18<02:03, 123.74s/it]Loss = 0.0\n","Loss = tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.974929809570312\n","#############    Validation Set Stats\n","Total Validation Loss = 16.429601669311523\n","  Accuracy: 0.6907\n","  Micro F1: 0.6896\n","  Macro F1: 0.6887\n","\n","100% 6/6 [12:22<00:00, 123.73s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7285\n","  Micro F1: 0.7282\n","  Macro F1: 0.7247\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"47o4WtA-JMqE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596323245919,"user_tz":-330,"elapsed":3734631,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"582a2f8e-30bc-4747-984c-e648223cd9ac"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-3 --num_labels 2 "],"execution_count":7,"outputs":[{"output_type":"stream","text":["2020-08-01 22:05:17.499599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6848, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 59.17852020263672\n","#############    Validation Set Stats\n","Total Validation Loss = 13.896296501159668\n","  Accuracy: 0.6686\n","  Micro F1: 0.6637\n","  Macro F1: 0.6637\n","\n"," 17% 1/6 [02:03<10:18, 123.69s/it]Loss = 0.0\n","Loss = tensor(0.5702, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.43939971923828\n","#############    Validation Set Stats\n","Total Validation Loss = 12.203346252441406\n","  Accuracy: 0.7259\n","  Micro F1: 0.7178\n","  Macro F1: 0.7159\n","\n"," 33% 2/6 [04:07<08:15, 123.87s/it]Loss = 0.0\n","Loss = tensor(0.4921, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.01942443847656\n","#############    Validation Set Stats\n","Total Validation Loss = 11.600153923034668\n","  Accuracy: 0.7353\n","  Micro F1: 0.7325\n","  Macro F1: 0.7323\n","\n"," 50% 3/6 [06:12<06:12, 124.01s/it]Loss = 0.0\n","Loss = tensor(0.4236, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.360572814941406\n","#############    Validation Set Stats\n","Total Validation Loss = 11.844783782958984\n","  Accuracy: 0.7311\n","  Micro F1: 0.7281\n","  Macro F1: 0.7280\n","\n"," 67% 4/6 [08:16<04:08, 124.03s/it]Loss = 0.0\n","Loss = tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.808666229248047\n","#############    Validation Set Stats\n","Total Validation Loss = 13.416213035583496\n","  Accuracy: 0.7003\n","  Micro F1: 0.6988\n","  Macro F1: 0.6988\n","\n"," 83% 5/6 [10:20<02:04, 124.16s/it]Loss = 0.0\n","Loss = tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.03162956237793\n","#############    Validation Set Stats\n","Total Validation Loss = 14.652702331542969\n","  Accuracy: 0.7003\n","  Micro F1: 0.6988\n","  Macro F1: 0.6985\n","\n","100% 6/6 [12:25<00:00, 124.18s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6581, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.48354721069336\n","#############    Validation Set Stats\n","Total Validation Loss = 12.840492248535156\n","  Accuracy: 0.7083\n","  Micro F1: 0.7047\n","  Macro F1: 0.6977\n","\n"," 17% 1/6 [02:04<10:20, 124.12s/it]Loss = 0.0\n","Loss = tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.406009674072266\n","#############    Validation Set Stats\n","Total Validation Loss = 12.794315338134766\n","  Accuracy: 0.6766\n","  Micro F1: 0.6769\n","  Macro F1: 0.6708\n","\n"," 33% 2/6 [04:08<08:17, 124.25s/it]Loss = 0.0\n","Loss = tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.95075225830078\n","#############    Validation Set Stats\n","Total Validation Loss = 12.367523193359375\n","  Accuracy: 0.7150\n","  Micro F1: 0.7164\n","  Macro F1: 0.7163\n","\n"," 50% 3/6 [06:12<06:12, 124.26s/it]Loss = 0.0\n","Loss = tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.23383331298828\n","#############    Validation Set Stats\n","Total Validation Loss = 13.802665710449219\n","  Accuracy: 0.7135\n","  Micro F1: 0.7149\n","  Macro F1: 0.7146\n","\n"," 67% 4/6 [08:17<04:08, 124.32s/it]Loss = 0.0\n","Loss = tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.732675552368164\n","#############    Validation Set Stats\n","Total Validation Loss = 14.731945037841797\n","  Accuracy: 0.7083\n","  Micro F1: 0.7047\n","  Macro F1: 0.7047\n","\n"," 83% 5/6 [10:21<02:04, 124.31s/it]Loss = 0.0\n","Loss = tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.346492767333984\n","#############    Validation Set Stats\n","Total Validation Loss = 16.076921463012695\n","  Accuracy: 0.7135\n","  Micro F1: 0.7076\n","  Macro F1: 0.7076\n","\n","100% 6/6 [12:25<00:00, 124.27s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6688, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.36029815673828\n","#############    Validation Set Stats\n","Total Validation Loss = 12.306475639343262\n","  Accuracy: 0.6970\n","  Micro F1: 0.7003\n","  Macro F1: 0.6960\n","\n"," 17% 1/6 [02:03<10:19, 123.80s/it]Loss = 0.0\n","Loss = tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.553916931152344\n","#############    Validation Set Stats\n","Total Validation Loss = 12.242860794067383\n","  Accuracy: 0.6903\n","  Micro F1: 0.6959\n","  Macro F1: 0.6957\n","\n"," 33% 2/6 [04:07<08:15, 123.90s/it]Loss = 0.0\n","Loss = tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.89140319824219\n","#############    Validation Set Stats\n","Total Validation Loss = 12.406928062438965\n","  Accuracy: 0.7031\n","  Micro F1: 0.7091\n","  Macro F1: 0.7079\n","\n"," 50% 3/6 [06:11<06:11, 123.87s/it]Loss = 0.0\n","Loss = tensor(0.3749, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.748815536499023\n","#############    Validation Set Stats\n","Total Validation Loss = 14.879999160766602\n","  Accuracy: 0.6889\n","  Micro F1: 0.6944\n","  Macro F1: 0.6933\n","\n"," 67% 4/6 [08:14<04:07, 123.56s/it]Loss = 0.0\n","Loss = tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.550697326660156\n","#############    Validation Set Stats\n","Total Validation Loss = 16.72295570373535\n","  Accuracy: 0.6676\n","  Micro F1: 0.6725\n","  Macro F1: 0.6717\n","\n"," 83% 5/6 [10:17<02:03, 123.28s/it]Loss = 0.0\n","Loss = tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.46676254272461\n","#############    Validation Set Stats\n","Total Validation Loss = 17.86670684814453\n","  Accuracy: 0.6714\n","  Micro F1: 0.6740\n","  Macro F1: 0.6727\n","\n","100% 6/6 [12:20<00:00, 123.34s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.75947570800781\n","#############    Validation Set Stats\n","Total Validation Loss = 11.878181457519531\n","  Accuracy: 0.7194\n","  Micro F1: 0.7247\n","  Macro F1: 0.7242\n","\n"," 17% 1/6 [02:02<10:13, 122.77s/it]Loss = 0.0\n","Loss = tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.90868377685547\n","#############    Validation Set Stats\n","Total Validation Loss = 11.739762306213379\n","  Accuracy: 0.7180\n","  Micro F1: 0.7233\n","  Macro F1: 0.7100\n","\n"," 33% 2/6 [04:05<08:11, 122.76s/it]Loss = 0.0\n","Loss = tensor(0.4628, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.470489501953125\n","#############    Validation Set Stats\n","Total Validation Loss = 12.343162536621094\n","  Accuracy: 0.7067\n","  Micro F1: 0.7145\n","  Macro F1: 0.7143\n","\n"," 50% 3/6 [06:08<06:08, 122.85s/it]Loss = 0.0\n","Loss = tensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.64642333984375\n","#############    Validation Set Stats\n","Total Validation Loss = 14.228145599365234\n","  Accuracy: 0.6839\n","  Micro F1: 0.6881\n","  Macro F1: 0.6879\n","\n"," 67% 4/6 [08:11<04:06, 123.01s/it]Loss = 0.0\n","Loss = tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.86420440673828\n","#############    Validation Set Stats\n","Total Validation Loss = 15.701496124267578\n","  Accuracy: 0.6996\n","  Micro F1: 0.7072\n","  Macro F1: 0.7040\n","\n"," 83% 5/6 [10:14<02:03, 123.01s/it]Loss = 0.0\n","Loss = tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.752147674560547\n","#############    Validation Set Stats\n","Total Validation Loss = 16.554443359375\n","  Accuracy: 0.6938\n","  Micro F1: 0.6984\n","  Macro F1: 0.6978\n","\n","100% 6/6 [12:17<00:00, 122.97s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6591, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.49998092651367\n","#############    Validation Set Stats\n","Total Validation Loss = 14.04153060913086\n","  Accuracy: 0.6568\n","  Micro F1: 0.6574\n","  Macro F1: 0.6421\n","\n"," 17% 1/6 [02:03<10:16, 123.22s/it]Loss = 0.0\n","Loss = tensor(0.4926, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.22358703613281\n","#############    Validation Set Stats\n","Total Validation Loss = 11.621625900268555\n","  Accuracy: 0.7389\n","  Micro F1: 0.7365\n","  Macro F1: 0.7353\n","\n"," 33% 2/6 [04:06<08:12, 123.11s/it]Loss = 0.0\n","Loss = tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.2874870300293\n","#############    Validation Set Stats\n","Total Validation Loss = 13.701648712158203\n","  Accuracy: 0.7035\n","  Micro F1: 0.7028\n","  Macro F1: 0.6991\n","\n"," 50% 3/6 [06:08<06:09, 123.05s/it]Loss = 0.0\n","Loss = tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.64457321166992\n","#############    Validation Set Stats\n","Total Validation Loss = 13.461505889892578\n","  Accuracy: 0.7150\n","  Micro F1: 0.7174\n","  Macro F1: 0.7174\n","\n"," 67% 4/6 [08:12<04:06, 123.28s/it]Loss = 0.0\n","Loss = tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.19747543334961\n","#############    Validation Set Stats\n","Total Validation Loss = 14.371467590332031\n","  Accuracy: 0.7193\n","  Micro F1: 0.7218\n","  Macro F1: 0.7212\n","\n"," 83% 5/6 [10:16<02:03, 123.33s/it]Loss = 0.0\n","Loss = tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.64794158935547\n","#############    Validation Set Stats\n","Total Validation Loss = 15.893345832824707\n","  Accuracy: 0.7164\n","  Micro F1: 0.7189\n","  Macro F1: 0.7188\n","\n","100% 6/6 [12:19<00:00, 123.20s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7223\n","  Micro F1: 0.7238\n","  Macro F1: 0.7232\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f-mKmADiJM1C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596327035297,"user_tz":-330,"elapsed":3789408,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"03263852-07cc-489f-bd6d-767a3d2bf105"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-3 --num_labels 2 "],"execution_count":8,"outputs":[{"output_type":"stream","text":["2020-08-01 23:07:32.033802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6801, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.739986419677734\n","#############    Validation Set Stats\n","Total Validation Loss = 11.723268508911133\n","  Accuracy: 0.7367\n","  Micro F1: 0.7339\n","  Macro F1: 0.7339\n","\n"," 17% 1/6 [02:03<10:19, 123.85s/it]Loss = 0.0\n","Loss = tensor(0.5214, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.51272201538086\n","#############    Validation Set Stats\n","Total Validation Loss = 11.073301315307617\n","  Accuracy: 0.7524\n","  Micro F1: 0.7500\n","  Macro F1: 0.7461\n","\n"," 33% 2/6 [04:08<08:15, 123.96s/it]Loss = 0.0\n","Loss = tensor(0.4426, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.92362976074219\n","#############    Validation Set Stats\n","Total Validation Loss = 11.043920516967773\n","  Accuracy: 0.7633\n","  Micro F1: 0.7588\n","  Macro F1: 0.7580\n","\n"," 50% 3/6 [06:12<06:12, 124.08s/it]Loss = 0.0\n","Loss = tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.285953521728516\n","#############    Validation Set Stats\n","Total Validation Loss = 11.868420600891113\n","  Accuracy: 0.7509\n","  Micro F1: 0.7485\n","  Macro F1: 0.7473\n","\n"," 67% 4/6 [08:17<04:08, 124.30s/it]Loss = 0.0\n","Loss = tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.012907028198242\n","#############    Validation Set Stats\n","Total Validation Loss = 13.025598526000977\n","  Accuracy: 0.7467\n","  Micro F1: 0.7442\n","  Macro F1: 0.7421\n","\n"," 83% 5/6 [10:21<02:04, 124.34s/it]Loss = 0.0\n","Loss = tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.113040924072266\n","#############    Validation Set Stats\n","Total Validation Loss = 13.956756591796875\n","  Accuracy: 0.7268\n","  Micro F1: 0.7237\n","  Macro F1: 0.7223\n","\n","100% 6/6 [12:25<00:00, 124.32s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6879, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 59.588958740234375\n","#############    Validation Set Stats\n","Total Validation Loss = 14.789600372314453\n","  Accuracy: 0.5705\n","  Micro F1: 0.5702\n","  Macro F1: 0.5397\n","\n"," 17% 1/6 [02:04<10:21, 124.23s/it]Loss = 0.0\n","Loss = tensor(0.5947, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.512184143066406\n","#############    Validation Set Stats\n","Total Validation Loss = 12.231728553771973\n","  Accuracy: 0.7102\n","  Micro F1: 0.7091\n","  Macro F1: 0.7090\n","\n"," 33% 2/6 [04:08<08:17, 124.31s/it]Loss = 0.0\n","Loss = tensor(0.4887, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.38919448852539\n","#############    Validation Set Stats\n","Total Validation Loss = 11.618910789489746\n","  Accuracy: 0.7164\n","  Micro F1: 0.7105\n","  Macro F1: 0.7098\n","\n"," 50% 3/6 [06:13<06:13, 124.44s/it]Loss = 0.0\n","Loss = tensor(0.4668, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.372982025146484\n","#############    Validation Set Stats\n","Total Validation Loss = 12.413402557373047\n","  Accuracy: 0.7225\n","  Micro F1: 0.7193\n","  Macro F1: 0.7180\n","\n"," 67% 4/6 [08:19<04:09, 124.89s/it]Loss = 0.0\n","Loss = tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.961341857910156\n","#############    Validation Set Stats\n","Total Validation Loss = 13.124493598937988\n","  Accuracy: 0.7140\n","  Micro F1: 0.7105\n","  Macro F1: 0.7104\n","\n"," 83% 5/6 [10:25<02:05, 125.10s/it]Loss = 0.0\n","Loss = tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.736387252807617\n","#############    Validation Set Stats\n","Total Validation Loss = 14.232707023620605\n","  Accuracy: 0.7083\n","  Micro F1: 0.7047\n","  Macro F1: 0.7046\n","\n","100% 6/6 [12:30<00:00, 125.14s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6540, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.8683967590332\n","#############    Validation Set Stats\n","Total Validation Loss = 13.074304580688477\n","  Accuracy: 0.6742\n","  Micro F1: 0.6842\n","  Macro F1: 0.6831\n","\n"," 17% 1/6 [02:05<10:29, 125.87s/it]Loss = 0.0\n","Loss = tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.31538009643555\n","#############    Validation Set Stats\n","Total Validation Loss = 11.972210884094238\n","  Accuracy: 0.6913\n","  Micro F1: 0.6944\n","  Macro F1: 0.6934\n","\n"," 33% 2/6 [04:11<08:23, 125.77s/it]Loss = 0.0\n","Loss = tensor(0.4316, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.041038513183594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.542407035827637\n","  Accuracy: 0.6809\n","  Micro F1: 0.6886\n","  Macro F1: 0.6885\n","\n"," 50% 3/6 [06:17<06:17, 125.79s/it]Loss = 0.0\n","Loss = tensor(0.3565, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.47550964355469\n","#############    Validation Set Stats\n","Total Validation Loss = 14.25173282623291\n","  Accuracy: 0.6785\n","  Micro F1: 0.6886\n","  Macro F1: 0.6880\n","\n"," 67% 4/6 [08:22<04:11, 125.70s/it]Loss = 0.0\n","Loss = tensor(0.3049, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.434968948364258\n","#############    Validation Set Stats\n","Total Validation Loss = 16.517608642578125\n","  Accuracy: 0.6624\n","  Micro F1: 0.6696\n","  Macro F1: 0.6692\n","\n"," 83% 5/6 [10:28<02:05, 125.76s/it]Loss = 0.0\n","Loss = tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.38855743408203\n","#############    Validation Set Stats\n","Total Validation Loss = 18.270479202270508\n","  Accuracy: 0.6600\n","  Micro F1: 0.6696\n","  Macro F1: 0.6696\n","\n","100% 6/6 [12:34<00:00, 125.81s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.228309631347656\n","#############    Validation Set Stats\n","Total Validation Loss = 13.609212875366211\n","  Accuracy: 0.6513\n","  Micro F1: 0.6574\n","  Macro F1: 0.6463\n","\n"," 17% 1/6 [02:05<10:27, 125.52s/it]Loss = 0.0\n","Loss = tensor(0.5271, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.70703125\n","#############    Validation Set Stats\n","Total Validation Loss = 11.572602272033691\n","  Accuracy: 0.7437\n","  Micro F1: 0.7526\n","  Macro F1: 0.7520\n","\n"," 33% 2/6 [04:11<08:22, 125.52s/it]Loss = 0.0\n","Loss = tensor(0.4316, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.004486083984375\n","#############    Validation Set Stats\n","Total Validation Loss = 12.534770965576172\n","  Accuracy: 0.7054\n","  Micro F1: 0.7160\n","  Macro F1: 0.7159\n","\n"," 50% 3/6 [06:16<06:16, 125.59s/it]Loss = 0.0\n","Loss = tensor(0.3723, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.81400489807129\n","#############    Validation Set Stats\n","Total Validation Loss = 14.077107429504395\n","  Accuracy: 0.6910\n","  Micro F1: 0.6955\n","  Macro F1: 0.6923\n","\n"," 67% 4/6 [08:22<04:11, 125.57s/it]Loss = 0.0\n","Loss = tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.861217498779297\n","#############    Validation Set Stats\n","Total Validation Loss = 16.947797775268555\n","  Accuracy: 0.6601\n","  Micro F1: 0.6720\n","  Macro F1: 0.6718\n","\n"," 83% 5/6 [10:28<02:05, 125.67s/it]Loss = 0.0\n","Loss = tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.69404411315918\n","#############    Validation Set Stats\n","Total Validation Loss = 17.737783432006836\n","  Accuracy: 0.6701\n","  Micro F1: 0.6823\n","  Macro F1: 0.6822\n","\n","100% 6/6 [12:34<00:00, 125.78s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6749, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.42135238647461\n","#############    Validation Set Stats\n","Total Validation Loss = 12.381363868713379\n","  Accuracy: 0.7133\n","  Micro F1: 0.7101\n","  Macro F1: 0.7039\n","\n"," 17% 1/6 [02:05<10:28, 125.75s/it]Loss = 0.0\n","Loss = tensor(0.5272, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.266788482666016\n","#############    Validation Set Stats\n","Total Validation Loss = 11.792561531066895\n","  Accuracy: 0.7220\n","  Micro F1: 0.7218\n","  Macro F1: 0.7205\n","\n"," 33% 2/6 [04:12<08:23, 125.99s/it]Loss = 0.0\n","Loss = tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.420677185058594\n","#############    Validation Set Stats\n","Total Validation Loss = 12.865447998046875\n","  Accuracy: 0.7234\n","  Micro F1: 0.7233\n","  Macro F1: 0.7230\n","\n"," 50% 3/6 [06:18<06:18, 126.05s/it]Loss = 0.0\n","Loss = tensor(0.3761, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.394681930541992\n","#############    Validation Set Stats\n","Total Validation Loss = 14.377713203430176\n","  Accuracy: 0.7135\n","  Micro F1: 0.7130\n","  Macro F1: 0.7130\n","\n"," 67% 4/6 [08:24<04:11, 125.97s/it]Loss = 0.0\n","Loss = tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.45438575744629\n","#############    Validation Set Stats\n","Total Validation Loss = 16.514022827148438\n","  Accuracy: 0.6950\n","  Micro F1: 0.6940\n","  Macro F1: 0.6939\n","\n"," 83% 5/6 [10:30<02:05, 125.99s/it]Loss = 0.0\n","Loss = tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 19.980052947998047\n","#############    Validation Set Stats\n","Total Validation Loss = 17.781890869140625\n","  Accuracy: 0.7021\n","  Micro F1: 0.7013\n","  Macro F1: 0.7012\n","\n","100% 6/6 [12:36<00:00, 126.13s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7288\n","  Micro F1: 0.7297\n","  Macro F1: 0.7289\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CpCuOyewJaDz","colab_type":"text"},"source":["9"]},{"cell_type":"code","metadata":{"id":"Lexg3MuUAMNU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596330767233,"user_tz":-330,"elapsed":3731955,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"0b48e942-e49c-4449-ea67-a87f51e6ff40"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-4 --num_labels 2 "],"execution_count":9,"outputs":[{"output_type":"stream","text":["2020-08-02 00:10:41.288427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6713, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.489871978759766\n","#############    Validation Set Stats\n","Total Validation Loss = 12.698173522949219\n","  Accuracy: 0.7022\n","  Micro F1: 0.7032\n","  Macro F1: 0.6872\n","\n"," 17% 1/6 [02:03<10:17, 123.58s/it]Loss = 0.0\n","Loss = tensor(0.5436, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.1158332824707\n","#############    Validation Set Stats\n","Total Validation Loss = 11.589290618896484\n","  Accuracy: 0.7268\n","  Micro F1: 0.7237\n","  Macro F1: 0.7138\n","\n"," 33% 2/6 [04:08<08:15, 123.87s/it]Loss = 0.0\n","Loss = tensor(0.4542, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.745025634765625\n","#############    Validation Set Stats\n","Total Validation Loss = 11.682018280029297\n","  Accuracy: 0.7382\n","  Micro F1: 0.7354\n","  Macro F1: 0.7353\n","\n"," 50% 3/6 [06:12<06:11, 123.96s/it]Loss = 0.0\n","Loss = tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.428340911865234\n","#############    Validation Set Stats\n","Total Validation Loss = 12.18560791015625\n","  Accuracy: 0.7235\n","  Micro F1: 0.7178\n","  Macro F1: 0.7168\n","\n"," 67% 4/6 [08:14<04:07, 123.52s/it]Loss = 0.0\n","Loss = tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.668394088745117\n","#############    Validation Set Stats\n","Total Validation Loss = 13.364690780639648\n","  Accuracy: 0.7254\n","  Micro F1: 0.7222\n","  Macro F1: 0.7222\n","\n"," 83% 5/6 [10:18<02:03, 123.52s/it]Loss = 0.0\n","Loss = tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.890012741088867\n","#############    Validation Set Stats\n","Total Validation Loss = 14.122973442077637\n","  Accuracy: 0.7098\n","  Micro F1: 0.7061\n","  Macro F1: 0.7061\n","\n","100% 6/6 [12:22<00:00, 123.69s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6829, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.91472244262695\n","#############    Validation Set Stats\n","Total Validation Loss = 14.12691879272461\n","  Accuracy: 0.6473\n","  Micro F1: 0.6564\n","  Macro F1: 0.6563\n","\n"," 17% 1/6 [02:03<10:16, 123.35s/it]Loss = 0.0\n","Loss = tensor(0.5717, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.00891876220703\n","#############    Validation Set Stats\n","Total Validation Loss = 12.191397666931152\n","  Accuracy: 0.7173\n","  Micro F1: 0.7164\n","  Macro F1: 0.7111\n","\n"," 33% 2/6 [04:06<08:13, 123.39s/it]Loss = 0.0\n","Loss = tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.5924072265625\n","#############    Validation Set Stats\n","Total Validation Loss = 12.094447135925293\n","  Accuracy: 0.7301\n","  Micro F1: 0.7295\n","  Macro F1: 0.7290\n","\n"," 50% 3/6 [06:10<06:10, 123.55s/it]Loss = 0.0\n","Loss = tensor(0.4435, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.83778381347656\n","#############    Validation Set Stats\n","Total Validation Loss = 14.028221130371094\n","  Accuracy: 0.7027\n","  Micro F1: 0.6988\n","  Macro F1: 0.6985\n","\n"," 67% 4/6 [08:14<04:07, 123.60s/it]Loss = 0.0\n","Loss = tensor(0.3735, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.276126861572266\n","#############    Validation Set Stats\n","Total Validation Loss = 15.012791633605957\n","  Accuracy: 0.6875\n","  Micro F1: 0.6857\n","  Macro F1: 0.6850\n","\n"," 83% 5/6 [10:18<02:03, 123.72s/it]Loss = 0.0\n","Loss = tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.082672119140625\n","#############    Validation Set Stats\n","Total Validation Loss = 15.946999549865723\n","  Accuracy: 0.6941\n","  Micro F1: 0.6901\n","  Macro F1: 0.6901\n","\n","100% 6/6 [12:22<00:00, 123.70s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6613, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.459815979003906\n","#############    Validation Set Stats\n","Total Validation Loss = 12.109565734863281\n","  Accuracy: 0.7098\n","  Micro F1: 0.7135\n","  Macro F1: 0.7129\n","\n"," 17% 1/6 [02:03<10:18, 123.61s/it]Loss = 0.0\n","Loss = tensor(0.5194, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.479061126708984\n","#############    Validation Set Stats\n","Total Validation Loss = 12.117166519165039\n","  Accuracy: 0.7083\n","  Micro F1: 0.7120\n","  Macro F1: 0.7120\n","\n"," 33% 2/6 [04:07<08:14, 123.59s/it]Loss = 0.0\n","Loss = tensor(0.4439, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.7346305847168\n","#############    Validation Set Stats\n","Total Validation Loss = 12.548294067382812\n","  Accuracy: 0.6918\n","  Micro F1: 0.6974\n","  Macro F1: 0.6972\n","\n"," 50% 3/6 [06:10<06:10, 123.60s/it]Loss = 0.0\n","Loss = tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.84874153137207\n","#############    Validation Set Stats\n","Total Validation Loss = 13.87736701965332\n","  Accuracy: 0.6884\n","  Micro F1: 0.6915\n","  Macro F1: 0.6914\n","\n"," 67% 4/6 [08:14<04:07, 123.68s/it]Loss = 0.0\n","Loss = tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.330928802490234\n","#############    Validation Set Stats\n","Total Validation Loss = 15.128458023071289\n","  Accuracy: 0.6776\n","  Micro F1: 0.6827\n","  Macro F1: 0.6808\n","\n"," 83% 5/6 [10:18<02:03, 123.69s/it]Loss = 0.0\n","Loss = tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.027076721191406\n","#############    Validation Set Stats\n","Total Validation Loss = 16.798542022705078\n","  Accuracy: 0.6723\n","  Micro F1: 0.6798\n","  Macro F1: 0.6798\n","\n","100% 6/6 [12:21<00:00, 123.63s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6558, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.22917556762695\n","#############    Validation Set Stats\n","Total Validation Loss = 12.45293140411377\n","  Accuracy: 0.6924\n","  Micro F1: 0.6969\n","  Macro F1: 0.6743\n","\n"," 17% 1/6 [02:02<10:14, 122.94s/it]Loss = 0.0\n","Loss = tensor(0.5077, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.94807052612305\n","#############    Validation Set Stats\n","Total Validation Loss = 11.821935653686523\n","  Accuracy: 0.7266\n","  Micro F1: 0.7350\n","  Macro F1: 0.7315\n","\n"," 33% 2/6 [04:06<08:12, 123.05s/it]Loss = 0.0\n","Loss = tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.038516998291016\n","#############    Validation Set Stats\n","Total Validation Loss = 12.256245613098145\n","  Accuracy: 0.7209\n","  Micro F1: 0.7291\n","  Macro F1: 0.7279\n","\n"," 50% 3/6 [06:10<06:10, 123.34s/it]Loss = 0.0\n","Loss = tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.969467163085938\n","#############    Validation Set Stats\n","Total Validation Loss = 15.959070205688477\n","  Accuracy: 0.6574\n","  Micro F1: 0.6720\n","  Macro F1: 0.6674\n","\n"," 67% 4/6 [08:13<04:06, 123.35s/it]Loss = 0.0\n","Loss = tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.084552764892578\n","#############    Validation Set Stats\n","Total Validation Loss = 15.083100318908691\n","  Accuracy: 0.6956\n","  Micro F1: 0.7086\n","  Macro F1: 0.7080\n","\n"," 83% 5/6 [10:16<02:03, 123.33s/it]Loss = 0.0\n","Loss = tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 20.95408821105957\n","#############    Validation Set Stats\n","Total Validation Loss = 15.93830394744873\n","  Accuracy: 0.6871\n","  Micro F1: 0.6999\n","  Macro F1: 0.6998\n","\n","100% 6/6 [12:19<00:00, 123.32s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6457, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.7227783203125\n","#############    Validation Set Stats\n","Total Validation Loss = 11.89955997467041\n","  Accuracy: 0.7302\n","  Micro F1: 0.7247\n","  Macro F1: 0.7212\n","\n"," 17% 1/6 [02:03<10:15, 123.15s/it]Loss = 0.0\n","Loss = tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.419044494628906\n","#############    Validation Set Stats\n","Total Validation Loss = 11.976825714111328\n","  Accuracy: 0.7147\n","  Micro F1: 0.7116\n","  Macro F1: 0.7078\n","\n"," 33% 2/6 [04:06<08:12, 123.07s/it]Loss = 0.0\n","Loss = tensor(0.4394, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.28465270996094\n","#############    Validation Set Stats\n","Total Validation Loss = 13.240885734558105\n","  Accuracy: 0.7106\n","  Micro F1: 0.7101\n","  Macro F1: 0.7092\n","\n"," 50% 3/6 [06:08<06:08, 122.94s/it]Loss = 0.0\n","Loss = tensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.635019302368164\n","#############    Validation Set Stats\n","Total Validation Loss = 14.288735389709473\n","  Accuracy: 0.7049\n","  Micro F1: 0.7042\n","  Macro F1: 0.7041\n","\n"," 67% 4/6 [08:11<04:05, 122.78s/it]Loss = 0.0\n","Loss = tensor(0.3178, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.956951141357422\n","#############    Validation Set Stats\n","Total Validation Loss = 15.421783447265625\n","  Accuracy: 0.6936\n","  Micro F1: 0.6925\n","  Macro F1: 0.6923\n","\n"," 83% 5/6 [10:14<02:03, 123.01s/it]Loss = 0.0\n","Loss = tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.93877410888672\n","#############    Validation Set Stats\n","Total Validation Loss = 15.795428276062012\n","  Accuracy: 0.6893\n","  Micro F1: 0.6881\n","  Macro F1: 0.6881\n","\n","100% 6/6 [12:18<00:00, 123.09s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7270\n","  Micro F1: 0.7276\n","  Macro F1: 0.7260\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iQtZJ0AmJWBC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596334518938,"user_tz":-330,"elapsed":3751735,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"fa3f7a76-5c94-4114-f91b-f0375686aa04"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":10,"outputs":[{"output_type":"stream","text":["2020-08-02 01:12:53.527127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6575, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.59801483154297\n","#############    Validation Set Stats\n","Total Validation Loss = 11.815478324890137\n","  Accuracy: 0.7311\n","  Micro F1: 0.7281\n","  Macro F1: 0.7281\n","\n"," 17% 1/6 [02:03<10:18, 123.75s/it]Loss = 0.0\n","Loss = tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.136199951171875\n","#############    Validation Set Stats\n","Total Validation Loss = 11.767925262451172\n","  Accuracy: 0.7453\n","  Micro F1: 0.7427\n","  Macro F1: 0.7424\n","\n"," 33% 2/6 [04:08<08:15, 123.92s/it]Loss = 0.0\n","Loss = tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.3509407043457\n","#############    Validation Set Stats\n","Total Validation Loss = 11.600709915161133\n","  Accuracy: 0.7382\n","  Micro F1: 0.7354\n","  Macro F1: 0.7351\n","\n"," 50% 3/6 [06:12<06:12, 124.05s/it]Loss = 0.0\n","Loss = tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.09782409667969\n","#############    Validation Set Stats\n","Total Validation Loss = 12.657078742980957\n","  Accuracy: 0.7268\n","  Micro F1: 0.7237\n","  Macro F1: 0.7215\n","\n"," 67% 4/6 [08:17<04:08, 124.21s/it]Loss = 0.0\n","Loss = tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.848346710205078\n","#############    Validation Set Stats\n","Total Validation Loss = 14.187692642211914\n","  Accuracy: 0.7088\n","  Micro F1: 0.7076\n","  Macro F1: 0.7043\n","\n"," 83% 5/6 [10:21<02:04, 124.24s/it]Loss = 0.0\n","Loss = tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.620309829711914\n","#############    Validation Set Stats\n","Total Validation Loss = 15.024633407592773\n","  Accuracy: 0.7169\n","  Micro F1: 0.7135\n","  Macro F1: 0.7127\n","\n","100% 6/6 [12:25<00:00, 124.22s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6742, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.620765686035156\n","#############    Validation Set Stats\n","Total Validation Loss = 12.57217788696289\n","  Accuracy: 0.7017\n","  Micro F1: 0.7003\n","  Macro F1: 0.6991\n","\n"," 17% 1/6 [02:04<10:20, 124.07s/it]Loss = 0.0\n","Loss = tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.02842712402344\n","#############    Validation Set Stats\n","Total Validation Loss = 11.859169006347656\n","  Accuracy: 0.7192\n","  Micro F1: 0.7135\n","  Macro F1: 0.7125\n","\n"," 33% 2/6 [04:07<08:15, 123.97s/it]Loss = 0.0\n","Loss = tensor(0.4107, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.98884201049805\n","#############    Validation Set Stats\n","Total Validation Loss = 13.678926467895508\n","  Accuracy: 0.6875\n","  Micro F1: 0.6857\n","  Macro F1: 0.6854\n","\n"," 50% 3/6 [06:11<06:11, 123.96s/it]Loss = 0.0\n","Loss = tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.766843795776367\n","#############    Validation Set Stats\n","Total Validation Loss = 13.684799194335938\n","  Accuracy: 0.7126\n","  Micro F1: 0.7091\n","  Macro F1: 0.7090\n","\n"," 67% 4/6 [08:15<04:07, 123.78s/it]Loss = 0.0\n","Loss = tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.614261627197266\n","#############    Validation Set Stats\n","Total Validation Loss = 14.256457328796387\n","  Accuracy: 0.7126\n","  Micro F1: 0.7091\n","  Macro F1: 0.7064\n","\n"," 83% 5/6 [10:19<02:04, 124.08s/it]Loss = 0.0\n","Loss = tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.64154815673828\n","#############    Validation Set Stats\n","Total Validation Loss = 15.83002758026123\n","  Accuracy: 0.7055\n","  Micro F1: 0.7018\n","  Macro F1: 0.7017\n","\n","100% 6/6 [12:24<00:00, 124.12s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6623, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.686553955078125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.310256004333496\n","  Accuracy: 0.6700\n","  Micro F1: 0.6798\n","  Macro F1: 0.6721\n","\n"," 17% 1/6 [02:04<10:22, 124.48s/it]Loss = 0.0\n","Loss = tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.15803527832031\n","#############    Validation Set Stats\n","Total Validation Loss = 12.794675827026367\n","  Accuracy: 0.7135\n","  Micro F1: 0.7222\n","  Macro F1: 0.7186\n","\n"," 33% 2/6 [04:08<08:17, 124.42s/it]Loss = 0.0\n","Loss = tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.73516845703125\n","#############    Validation Set Stats\n","Total Validation Loss = 12.468822479248047\n","  Accuracy: 0.7116\n","  Micro F1: 0.7178\n","  Macro F1: 0.7160\n","\n"," 50% 3/6 [06:13<06:13, 124.43s/it]Loss = 0.0\n","Loss = tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.586402893066406\n","#############    Validation Set Stats\n","Total Validation Loss = 15.01219654083252\n","  Accuracy: 0.6903\n","  Micro F1: 0.6959\n","  Macro F1: 0.6959\n","\n"," 67% 4/6 [08:17<04:08, 124.27s/it]Loss = 0.0\n","Loss = tensor(0.3022, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.174522399902344\n","#############    Validation Set Stats\n","Total Validation Loss = 16.627193450927734\n","  Accuracy: 0.6761\n","  Micro F1: 0.6813\n","  Macro F1: 0.6807\n","\n"," 83% 5/6 [10:21<02:04, 124.22s/it]Loss = 0.0\n","Loss = tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.867694854736328\n","#############    Validation Set Stats\n","Total Validation Loss = 17.276765823364258\n","  Accuracy: 0.6813\n","  Micro F1: 0.6842\n","  Macro F1: 0.6833\n","\n","100% 6/6 [12:26<00:00, 124.36s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6730, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.97843551635742\n","#############    Validation Set Stats\n","Total Validation Loss = 12.135457038879395\n","  Accuracy: 0.7264\n","  Micro F1: 0.7291\n","  Macro F1: 0.7263\n","\n"," 17% 1/6 [02:04<10:21, 124.30s/it]Loss = 0.0\n","Loss = tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.00550079345703\n","#############    Validation Set Stats\n","Total Validation Loss = 11.860118865966797\n","  Accuracy: 0.7194\n","  Micro F1: 0.7247\n","  Macro F1: 0.7245\n","\n"," 33% 2/6 [04:08<08:17, 124.38s/it]Loss = 0.0\n","Loss = tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.03931427001953\n","#############    Validation Set Stats\n","Total Validation Loss = 11.731865882873535\n","  Accuracy: 0.7308\n","  Micro F1: 0.7365\n","  Macro F1: 0.7354\n","\n"," 50% 3/6 [06:13<06:13, 124.37s/it]Loss = 0.0\n","Loss = tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.76181411743164\n","#############    Validation Set Stats\n","Total Validation Loss = 12.910176277160645\n","  Accuracy: 0.7279\n","  Micro F1: 0.7335\n","  Macro F1: 0.7325\n","\n"," 67% 4/6 [08:17<04:08, 124.44s/it]Loss = 0.0\n","Loss = tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.639177322387695\n","#############    Validation Set Stats\n","Total Validation Loss = 15.799542427062988\n","  Accuracy: 0.6896\n","  Micro F1: 0.6940\n","  Macro F1: 0.6940\n","\n"," 83% 5/6 [10:22<02:04, 124.39s/it]Loss = 0.0\n","Loss = tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.67281150817871\n","#############    Validation Set Stats\n","Total Validation Loss = 16.550989151000977\n","  Accuracy: 0.6954\n","  Micro F1: 0.7028\n","  Macro F1: 0.7028\n","\n","100% 6/6 [12:25<00:00, 124.21s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6590, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.84743118286133\n","#############    Validation Set Stats\n","Total Validation Loss = 12.145112037658691\n","  Accuracy: 0.7191\n","  Micro F1: 0.7189\n","  Macro F1: 0.7163\n","\n"," 17% 1/6 [02:03<10:15, 123.02s/it]Loss = 0.0\n","Loss = tensor(0.5165, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.69716262817383\n","#############    Validation Set Stats\n","Total Validation Loss = 11.915624618530273\n","  Accuracy: 0.7332\n","  Micro F1: 0.7306\n","  Macro F1: 0.7299\n","\n"," 33% 2/6 [04:08<08:14, 123.61s/it]Loss = 0.0\n","Loss = tensor(0.4585, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.244598388671875\n","#############    Validation Set Stats\n","Total Validation Loss = 12.055830955505371\n","  Accuracy: 0.7346\n","  Micro F1: 0.7321\n","  Macro F1: 0.7275\n","\n"," 50% 3/6 [06:11<06:10, 123.65s/it]Loss = 0.0\n","Loss = tensor(0.3939, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.75657653808594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.345585823059082\n","  Accuracy: 0.7048\n","  Micro F1: 0.7013\n","  Macro F1: 0.7013\n","\n"," 67% 4/6 [08:16<04:07, 123.89s/it]Loss = 0.0\n","Loss = tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.172157287597656\n","#############    Validation Set Stats\n","Total Validation Loss = 14.328595161437988\n","  Accuracy: 0.7119\n","  Micro F1: 0.7086\n","  Macro F1: 0.7078\n","\n"," 83% 5/6 [10:20<02:03, 123.95s/it]Loss = 0.0\n","Loss = tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.026403427124023\n","#############    Validation Set Stats\n","Total Validation Loss = 16.008838653564453\n","  Accuracy: 0.6993\n","  Micro F1: 0.6984\n","  Macro F1: 0.6982\n","\n","100% 6/6 [12:24<00:00, 124.02s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7284\n","  Micro F1: 0.7291\n","  Macro F1: 0.7277\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Y3bf2wsJWcf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596338317073,"user_tz":-330,"elapsed":3798156,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"359c6c5d-8630-4719-c7b6-d11014065940"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-4 --num_labels 2"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2020-08-02 02:15:25.800512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6845, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.07052230834961\n","#############    Validation Set Stats\n","Total Validation Loss = 12.566619873046875\n","  Accuracy: 0.7183\n","  Micro F1: 0.7149\n","  Macro F1: 0.7148\n","\n"," 17% 1/6 [02:04<10:24, 124.97s/it]Loss = 0.0\n","Loss = tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.506282806396484\n","#############    Validation Set Stats\n","Total Validation Loss = 11.877270698547363\n","  Accuracy: 0.6965\n","  Micro F1: 0.6901\n","  Macro F1: 0.6824\n","\n"," 33% 2/6 [04:10<08:20, 125.12s/it]Loss = 0.0\n","Loss = tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.091129302978516\n","#############    Validation Set Stats\n","Total Validation Loss = 10.866483688354492\n","  Accuracy: 0.7580\n","  Micro F1: 0.7558\n","  Macro F1: 0.7543\n","\n"," 50% 3/6 [06:16<06:15, 125.32s/it]Loss = 0.0\n","Loss = tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.06467819213867\n","#############    Validation Set Stats\n","Total Validation Loss = 12.036688804626465\n","  Accuracy: 0.7396\n","  Micro F1: 0.7368\n","  Macro F1: 0.7362\n","\n"," 67% 4/6 [08:21<04:10, 125.21s/it]Loss = 0.0\n","Loss = tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.979270935058594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.434133529663086\n","  Accuracy: 0.7311\n","  Micro F1: 0.7281\n","  Macro F1: 0.7272\n","\n"," 83% 5/6 [10:27<02:05, 125.43s/it]Loss = 0.0\n","Loss = tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.731754302978516\n","#############    Validation Set Stats\n","Total Validation Loss = 14.033923149108887\n","  Accuracy: 0.7240\n","  Micro F1: 0.7208\n","  Macro F1: 0.7198\n","\n","100% 6/6 [12:33<00:00, 125.58s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6505, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.51970291137695\n","#############    Validation Set Stats\n","Total Validation Loss = 12.058036804199219\n","  Accuracy: 0.7126\n","  Micro F1: 0.7091\n","  Macro F1: 0.6954\n","\n"," 17% 1/6 [02:05<10:28, 125.75s/it]Loss = 0.0\n","Loss = tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.21999740600586\n","#############    Validation Set Stats\n","Total Validation Loss = 11.823359489440918\n","  Accuracy: 0.7211\n","  Micro F1: 0.7178\n","  Macro F1: 0.7175\n","\n"," 33% 2/6 [04:12<08:23, 125.97s/it]Loss = 0.0\n","Loss = tensor(0.4276, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.69017028808594\n","#############    Validation Set Stats\n","Total Validation Loss = 12.623650550842285\n","  Accuracy: 0.7206\n","  Micro F1: 0.7149\n","  Macro F1: 0.7116\n","\n"," 50% 3/6 [06:18<06:17, 125.94s/it]Loss = 0.0\n","Loss = tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.763538360595703\n","#############    Validation Set Stats\n","Total Validation Loss = 14.891526222229004\n","  Accuracy: 0.6889\n","  Micro F1: 0.6871\n","  Macro F1: 0.6852\n","\n"," 67% 4/6 [08:24<04:12, 126.01s/it]Loss = 0.0\n","Loss = tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.11808204650879\n","#############    Validation Set Stats\n","Total Validation Loss = 14.514896392822266\n","  Accuracy: 0.7031\n","  Micro F1: 0.7018\n","  Macro F1: 0.6990\n","\n"," 83% 5/6 [10:30<02:05, 125.95s/it]Loss = 0.0\n","Loss = tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.658823013305664\n","#############    Validation Set Stats\n","Total Validation Loss = 16.313764572143555\n","  Accuracy: 0.7074\n","  Micro F1: 0.7061\n","  Macro F1: 0.7061\n","\n","100% 6/6 [12:35<00:00, 125.91s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6772, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.07868957519531\n","#############    Validation Set Stats\n","Total Validation Loss = 13.211929321289062\n","  Accuracy: 0.6648\n","  Micro F1: 0.6623\n","  Macro F1: 0.6362\n","\n"," 17% 1/6 [02:05<10:26, 125.29s/it]Loss = 0.0\n","Loss = tensor(0.5360, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.57162857055664\n","#############    Validation Set Stats\n","Total Validation Loss = 11.777321815490723\n","  Accuracy: 0.7230\n","  Micro F1: 0.7222\n","  Macro F1: 0.7164\n","\n"," 33% 2/6 [04:11<08:21, 125.48s/it]Loss = 0.0\n","Loss = tensor(0.4572, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.72554016113281\n","#############    Validation Set Stats\n","Total Validation Loss = 13.304426193237305\n","  Accuracy: 0.6979\n","  Micro F1: 0.7061\n","  Macro F1: 0.7059\n","\n"," 50% 3/6 [06:17<06:17, 125.69s/it]Loss = 0.0\n","Loss = tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.538726806640625\n","#############    Validation Set Stats\n","Total Validation Loss = 13.843831062316895\n","  Accuracy: 0.6998\n","  Micro F1: 0.7032\n","  Macro F1: 0.6996\n","\n"," 67% 4/6 [08:23<04:11, 125.72s/it]Loss = 0.0\n","Loss = tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.71988868713379\n","#############    Validation Set Stats\n","Total Validation Loss = 16.086284637451172\n","  Accuracy: 0.6875\n","  Micro F1: 0.6930\n","  Macro F1: 0.6922\n","\n"," 83% 5/6 [10:28<02:05, 125.69s/it]Loss = 0.0\n","Loss = tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.274389266967773\n","#############    Validation Set Stats\n","Total Validation Loss = 17.004749298095703\n","  Accuracy: 0.6832\n","  Micro F1: 0.6886\n","  Macro F1: 0.6876\n","\n","100% 6/6 [12:34<00:00, 125.81s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6756, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.04195785522461\n","#############    Validation Set Stats\n","Total Validation Loss = 12.331266403198242\n","  Accuracy: 0.7364\n","  Micro F1: 0.7423\n","  Macro F1: 0.7393\n","\n"," 17% 1/6 [02:05<10:28, 125.67s/it]Loss = 0.0\n","Loss = tensor(0.5120, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.598506927490234\n","#############    Validation Set Stats\n","Total Validation Loss = 11.578054428100586\n","  Accuracy: 0.7195\n","  Micro F1: 0.7277\n","  Macro F1: 0.7277\n","\n"," 33% 2/6 [04:11<08:23, 125.78s/it]Loss = 0.0\n","Loss = tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.603363037109375\n","#############    Validation Set Stats\n","Total Validation Loss = 12.39517879486084\n","  Accuracy: 0.7110\n","  Micro F1: 0.7189\n","  Macro F1: 0.7179\n","\n"," 50% 3/6 [06:17<06:17, 125.79s/it]Loss = 0.0\n","Loss = tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.568265914916992\n","#############    Validation Set Stats\n","Total Validation Loss = 13.469334602355957\n","  Accuracy: 0.7153\n","  Micro F1: 0.7233\n","  Macro F1: 0.7233\n","\n"," 67% 4/6 [08:23<04:11, 125.90s/it]Loss = 0.0\n","Loss = tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.07005500793457\n","#############    Validation Set Stats\n","Total Validation Loss = 15.021113395690918\n","  Accuracy: 0.6925\n","  Micro F1: 0.6999\n","  Macro F1: 0.6992\n","\n"," 83% 5/6 [10:30<02:06, 126.09s/it]Loss = 0.0\n","Loss = tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 19.335647583007812\n","#############    Validation Set Stats\n","Total Validation Loss = 16.43012046813965\n","  Accuracy: 0.7053\n","  Micro F1: 0.7130\n","  Macro F1: 0.7122\n","\n","100% 6/6 [12:36<00:00, 126.02s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6780, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.89622497558594\n","#############    Validation Set Stats\n","Total Validation Loss = 12.405020713806152\n","  Accuracy: 0.7089\n","  Micro F1: 0.7028\n","  Macro F1: 0.7012\n","\n"," 17% 1/6 [02:04<10:21, 124.23s/it]Loss = 0.0\n","Loss = tensor(0.5196, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.90135192871094\n","#############    Validation Set Stats\n","Total Validation Loss = 11.571474075317383\n","  Accuracy: 0.7288\n","  Micro F1: 0.7233\n","  Macro F1: 0.7231\n","\n"," 33% 2/6 [04:09<08:18, 124.52s/it]Loss = 0.0\n","Loss = tensor(0.4701, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.21849822998047\n","#############    Validation Set Stats\n","Total Validation Loss = 12.558826446533203\n","  Accuracy: 0.7190\n","  Micro F1: 0.7160\n","  Macro F1: 0.7148\n","\n"," 50% 3/6 [06:14<06:13, 124.67s/it]Loss = 0.0\n","Loss = tensor(0.3884, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.74422836303711\n","#############    Validation Set Stats\n","Total Validation Loss = 13.582763671875\n","  Accuracy: 0.7149\n","  Micro F1: 0.7145\n","  Macro F1: 0.7145\n","\n"," 67% 4/6 [08:19<04:09, 124.92s/it]Loss = 0.0\n","Loss = tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.48040771484375\n","#############    Validation Set Stats\n","Total Validation Loss = 15.206561088562012\n","  Accuracy: 0.7005\n","  Micro F1: 0.6969\n","  Macro F1: 0.6941\n","\n"," 83% 5/6 [10:25<02:05, 125.21s/it]Loss = 0.0\n","Loss = tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.82120704650879\n","#############    Validation Set Stats\n","Total Validation Loss = 16.916461944580078\n","  Accuracy: 0.7008\n","  Micro F1: 0.7028\n","  Macro F1: 0.7023\n","\n","100% 6/6 [12:30<00:00, 125.15s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7335\n","  Micro F1: 0.7323\n","  Macro F1: 0.7301\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QGe-rfnDJX0p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596346974987,"user_tz":-330,"elapsed":3668830,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"c1544f05-ef18-40d1-dca6-e17fbbe2d1db"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-3 --num_labels 2 "],"execution_count":4,"outputs":[{"output_type":"stream","text":["2020-08-02 04:41:56.025983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100% 996k/996k [00:00<00:00, 2.17MB/s]\n","Downloading: 100% 625/625 [00:00<00:00, 377kB/s]\n","Downloading: 100% 714M/714M [00:14<00:00, 48.5MB/s]\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6713, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.489871978759766\n","#############    Validation Set Stats\n","Total Validation Loss = 12.698173522949219\n","  Accuracy: 0.7022\n","  Micro F1: 0.7032\n","  Macro F1: 0.6872\n","\n"," 17% 1/6 [01:59<09:57, 119.56s/it]Loss = 0.0\n","Loss = tensor(0.5436, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.1158332824707\n","#############    Validation Set Stats\n","Total Validation Loss = 11.589290618896484\n","  Accuracy: 0.7268\n","  Micro F1: 0.7237\n","  Macro F1: 0.7138\n","\n"," 33% 2/6 [04:00<07:59, 119.91s/it]Loss = 0.0\n","Loss = tensor(0.4542, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.745025634765625\n","#############    Validation Set Stats\n","Total Validation Loss = 11.682018280029297\n","  Accuracy: 0.7382\n","  Micro F1: 0.7354\n","  Macro F1: 0.7353\n","\n"," 50% 3/6 [06:00<06:00, 120.07s/it]Loss = 0.0\n","Loss = tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.428340911865234\n","#############    Validation Set Stats\n","Total Validation Loss = 12.18560791015625\n","  Accuracy: 0.7235\n","  Micro F1: 0.7178\n","  Macro F1: 0.7168\n","\n"," 67% 4/6 [08:00<04:00, 120.12s/it]Loss = 0.0\n","Loss = tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.668394088745117\n","#############    Validation Set Stats\n","Total Validation Loss = 13.364690780639648\n","  Accuracy: 0.7254\n","  Micro F1: 0.7222\n","  Macro F1: 0.7222\n","\n"," 83% 5/6 [10:01<02:00, 120.23s/it]Loss = 0.0\n","Loss = tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.890012741088867\n","#############    Validation Set Stats\n","Total Validation Loss = 14.122973442077637\n","  Accuracy: 0.7098\n","  Micro F1: 0.7061\n","  Macro F1: 0.7061\n","\n","100% 6/6 [12:02<00:00, 120.35s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6829, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.91472244262695\n","#############    Validation Set Stats\n","Total Validation Loss = 14.12691879272461\n","  Accuracy: 0.6473\n","  Micro F1: 0.6564\n","  Macro F1: 0.6563\n","\n"," 17% 1/6 [02:00<10:00, 120.17s/it]Loss = 0.0\n","Loss = tensor(0.5717, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.00891876220703\n","#############    Validation Set Stats\n","Total Validation Loss = 12.191397666931152\n","  Accuracy: 0.7173\n","  Micro F1: 0.7164\n","  Macro F1: 0.7111\n","\n"," 33% 2/6 [04:00<08:01, 120.25s/it]Loss = 0.0\n","Loss = tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.5924072265625\n","#############    Validation Set Stats\n","Total Validation Loss = 12.094447135925293\n","  Accuracy: 0.7301\n","  Micro F1: 0.7295\n","  Macro F1: 0.7290\n","\n"," 50% 3/6 [06:01<06:01, 120.38s/it]Loss = 0.0\n","Loss = tensor(0.4435, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.83778381347656\n","#############    Validation Set Stats\n","Total Validation Loss = 14.028221130371094\n","  Accuracy: 0.7027\n","  Micro F1: 0.6988\n","  Macro F1: 0.6985\n","\n"," 67% 4/6 [08:01<04:00, 120.39s/it]Loss = 0.0\n","Loss = tensor(0.3735, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.276126861572266\n","#############    Validation Set Stats\n","Total Validation Loss = 15.012791633605957\n","  Accuracy: 0.6875\n","  Micro F1: 0.6857\n","  Macro F1: 0.6850\n","\n"," 83% 5/6 [10:02<02:00, 120.46s/it]Loss = 0.0\n","Loss = tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.082672119140625\n","#############    Validation Set Stats\n","Total Validation Loss = 15.946999549865723\n","  Accuracy: 0.6941\n","  Micro F1: 0.6901\n","  Macro F1: 0.6901\n","\n","100% 6/6 [12:02<00:00, 120.46s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6613, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.459815979003906\n","#############    Validation Set Stats\n","Total Validation Loss = 12.109565734863281\n","  Accuracy: 0.7098\n","  Micro F1: 0.7135\n","  Macro F1: 0.7129\n","\n"," 17% 1/6 [02:00<10:01, 120.33s/it]Loss = 0.0\n","Loss = tensor(0.5194, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.479061126708984\n","#############    Validation Set Stats\n","Total Validation Loss = 12.117166519165039\n","  Accuracy: 0.7083\n","  Micro F1: 0.7120\n","  Macro F1: 0.7120\n","\n"," 33% 2/6 [04:00<08:01, 120.27s/it]Loss = 0.0\n","Loss = tensor(0.4439, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.7346305847168\n","#############    Validation Set Stats\n","Total Validation Loss = 12.548294067382812\n","  Accuracy: 0.6918\n","  Micro F1: 0.6974\n","  Macro F1: 0.6972\n","\n"," 50% 3/6 [06:00<06:00, 120.31s/it]Loss = 0.0\n","Loss = tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.84874153137207\n","#############    Validation Set Stats\n","Total Validation Loss = 13.87736701965332\n","  Accuracy: 0.6884\n","  Micro F1: 0.6915\n","  Macro F1: 0.6914\n","\n"," 67% 4/6 [08:01<04:00, 120.41s/it]Loss = 0.0\n","Loss = tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.330928802490234\n","#############    Validation Set Stats\n","Total Validation Loss = 15.128458023071289\n","  Accuracy: 0.6776\n","  Micro F1: 0.6827\n","  Macro F1: 0.6808\n","\n"," 83% 5/6 [10:01<02:00, 120.39s/it]Loss = 0.0\n","Loss = tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.027076721191406\n","#############    Validation Set Stats\n","Total Validation Loss = 16.798542022705078\n","  Accuracy: 0.6723\n","  Micro F1: 0.6798\n","  Macro F1: 0.6798\n","\n","100% 6/6 [12:02<00:00, 120.35s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6558, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.22917556762695\n","#############    Validation Set Stats\n","Total Validation Loss = 12.45293140411377\n","  Accuracy: 0.6924\n","  Micro F1: 0.6969\n","  Macro F1: 0.6743\n","\n"," 17% 1/6 [02:00<10:00, 120.16s/it]Loss = 0.0\n","Loss = tensor(0.5077, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.94807052612305\n","#############    Validation Set Stats\n","Total Validation Loss = 11.821935653686523\n","  Accuracy: 0.7266\n","  Micro F1: 0.7350\n","  Macro F1: 0.7315\n","\n"," 33% 2/6 [04:00<08:01, 120.25s/it]Loss = 0.0\n","Loss = tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.038516998291016\n","#############    Validation Set Stats\n","Total Validation Loss = 12.256245613098145\n","  Accuracy: 0.7209\n","  Micro F1: 0.7291\n","  Macro F1: 0.7279\n","\n"," 50% 3/6 [06:01<06:01, 120.39s/it]Loss = 0.0\n","Loss = tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.969467163085938\n","#############    Validation Set Stats\n","Total Validation Loss = 15.959070205688477\n","  Accuracy: 0.6574\n","  Micro F1: 0.6720\n","  Macro F1: 0.6674\n","\n"," 67% 4/6 [08:01<04:00, 120.39s/it]Loss = 0.0\n","Loss = tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.084552764892578\n","#############    Validation Set Stats\n","Total Validation Loss = 15.083100318908691\n","  Accuracy: 0.6956\n","  Micro F1: 0.7086\n","  Macro F1: 0.7080\n","\n"," 83% 5/6 [10:01<02:00, 120.35s/it]Loss = 0.0\n","Loss = tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 20.95408821105957\n","#############    Validation Set Stats\n","Total Validation Loss = 15.93830394744873\n","  Accuracy: 0.6871\n","  Micro F1: 0.6999\n","  Macro F1: 0.6998\n","\n","100% 6/6 [12:02<00:00, 120.40s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6457, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.7227783203125\n","#############    Validation Set Stats\n","Total Validation Loss = 11.89955997467041\n","  Accuracy: 0.7302\n","  Micro F1: 0.7247\n","  Macro F1: 0.7212\n","\n"," 17% 1/6 [02:00<10:02, 120.60s/it]Loss = 0.0\n","Loss = tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.419044494628906\n","#############    Validation Set Stats\n","Total Validation Loss = 11.976825714111328\n","  Accuracy: 0.7147\n","  Micro F1: 0.7116\n","  Macro F1: 0.7078\n","\n"," 33% 2/6 [04:00<08:02, 120.54s/it]Loss = 0.0\n","Loss = tensor(0.4394, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.28465270996094\n","#############    Validation Set Stats\n","Total Validation Loss = 13.240885734558105\n","  Accuracy: 0.7106\n","  Micro F1: 0.7101\n","  Macro F1: 0.7092\n","\n"," 50% 3/6 [06:01<06:01, 120.56s/it]Loss = 0.0\n","Loss = tensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.635019302368164\n","#############    Validation Set Stats\n","Total Validation Loss = 14.288735389709473\n","  Accuracy: 0.7049\n","  Micro F1: 0.7042\n","  Macro F1: 0.7041\n","\n"," 67% 4/6 [08:02<04:01, 120.52s/it]Loss = 0.0\n","Loss = tensor(0.3178, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.956951141357422\n","#############    Validation Set Stats\n","Total Validation Loss = 15.421783447265625\n","  Accuracy: 0.6936\n","  Micro F1: 0.6925\n","  Macro F1: 0.6923\n","\n"," 83% 5/6 [10:02<02:00, 120.41s/it]Loss = 0.0\n","Loss = tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.93877410888672\n","#############    Validation Set Stats\n","Total Validation Loss = 15.795428276062012\n","  Accuracy: 0.6893\n","  Micro F1: 0.6881\n","  Macro F1: 0.6881\n","\n","100% 6/6 [12:02<00:00, 120.43s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7270\n","  Micro F1: 0.7276\n","  Macro F1: 0.7260\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MXUKwUxhk5Qt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596350625740,"user_tz":-330,"elapsed":7319125,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"fd6472ab-2519-4c3c-fd83-899d73cb6a18"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-3 --num_labels 2 "],"execution_count":5,"outputs":[{"output_type":"stream","text":["2020-08-02 05:42:58.060892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6575, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.59801483154297\n","#############    Validation Set Stats\n","Total Validation Loss = 11.815478324890137\n","  Accuracy: 0.7311\n","  Micro F1: 0.7281\n","  Macro F1: 0.7281\n","\n"," 17% 1/6 [02:00<10:03, 120.78s/it]Loss = 0.0\n","Loss = tensor(0.5134, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.136199951171875\n","#############    Validation Set Stats\n","Total Validation Loss = 11.767925262451172\n","  Accuracy: 0.7453\n","  Micro F1: 0.7427\n","  Macro F1: 0.7424\n","\n"," 33% 2/6 [04:02<08:03, 120.95s/it]Loss = 0.0\n","Loss = tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.3509407043457\n","#############    Validation Set Stats\n","Total Validation Loss = 11.600709915161133\n","  Accuracy: 0.7382\n","  Micro F1: 0.7354\n","  Macro F1: 0.7351\n","\n"," 50% 3/6 [06:03<06:02, 120.99s/it]Loss = 0.0\n","Loss = tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.09782409667969\n","#############    Validation Set Stats\n","Total Validation Loss = 12.657078742980957\n","  Accuracy: 0.7268\n","  Micro F1: 0.7237\n","  Macro F1: 0.7215\n","\n"," 67% 4/6 [08:04<04:02, 121.09s/it]Loss = 0.0\n","Loss = tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.848346710205078\n","#############    Validation Set Stats\n","Total Validation Loss = 14.187692642211914\n","  Accuracy: 0.7088\n","  Micro F1: 0.7076\n","  Macro F1: 0.7043\n","\n"," 83% 5/6 [10:05<02:01, 121.09s/it]Loss = 0.0\n","Loss = tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.620309829711914\n","#############    Validation Set Stats\n","Total Validation Loss = 15.024633407592773\n","  Accuracy: 0.7169\n","  Micro F1: 0.7135\n","  Macro F1: 0.7127\n","\n","100% 6/6 [12:06<00:00, 121.09s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6742, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.620765686035156\n","#############    Validation Set Stats\n","Total Validation Loss = 12.57217788696289\n","  Accuracy: 0.7017\n","  Micro F1: 0.7003\n","  Macro F1: 0.6991\n","\n"," 17% 1/6 [02:00<10:04, 120.95s/it]Loss = 0.0\n","Loss = tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.02842712402344\n","#############    Validation Set Stats\n","Total Validation Loss = 11.859169006347656\n","  Accuracy: 0.7192\n","  Micro F1: 0.7135\n","  Macro F1: 0.7125\n","\n"," 33% 2/6 [04:02<08:03, 120.99s/it]Loss = 0.0\n","Loss = tensor(0.4107, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.98884201049805\n","#############    Validation Set Stats\n","Total Validation Loss = 13.678926467895508\n","  Accuracy: 0.6875\n","  Micro F1: 0.6857\n","  Macro F1: 0.6854\n","\n"," 50% 3/6 [06:02<06:02, 120.95s/it]Loss = 0.0\n","Loss = tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.766843795776367\n","#############    Validation Set Stats\n","Total Validation Loss = 13.684799194335938\n","  Accuracy: 0.7126\n","  Micro F1: 0.7091\n","  Macro F1: 0.7090\n","\n"," 67% 4/6 [08:04<04:02, 121.00s/it]Loss = 0.0\n","Loss = tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.614261627197266\n","#############    Validation Set Stats\n","Total Validation Loss = 14.256457328796387\n","  Accuracy: 0.7126\n","  Micro F1: 0.7091\n","  Macro F1: 0.7064\n","\n"," 83% 5/6 [10:05<02:01, 121.11s/it]Loss = 0.0\n","Loss = tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.64154815673828\n","#############    Validation Set Stats\n","Total Validation Loss = 15.83002758026123\n","  Accuracy: 0.7055\n","  Micro F1: 0.7018\n","  Macro F1: 0.7017\n","\n","100% 6/6 [12:06<00:00, 121.06s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6623, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.686553955078125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.310256004333496\n","  Accuracy: 0.6700\n","  Micro F1: 0.6798\n","  Macro F1: 0.6721\n","\n"," 17% 1/6 [02:01<10:05, 121.02s/it]Loss = 0.0\n","Loss = tensor(0.5288, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.15803527832031\n","#############    Validation Set Stats\n","Total Validation Loss = 12.794675827026367\n","  Accuracy: 0.7135\n","  Micro F1: 0.7222\n","  Macro F1: 0.7186\n","\n"," 33% 2/6 [04:01<08:04, 121.00s/it]Loss = 0.0\n","Loss = tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.73516845703125\n","#############    Validation Set Stats\n","Total Validation Loss = 12.468822479248047\n","  Accuracy: 0.7116\n","  Micro F1: 0.7178\n","  Macro F1: 0.7160\n","\n"," 50% 3/6 [06:03<06:03, 121.02s/it]Loss = 0.0\n","Loss = tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.586402893066406\n","#############    Validation Set Stats\n","Total Validation Loss = 15.01219654083252\n","  Accuracy: 0.6903\n","  Micro F1: 0.6959\n","  Macro F1: 0.6959\n","\n"," 67% 4/6 [08:03<04:02, 121.00s/it]Loss = 0.0\n","Loss = tensor(0.3022, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.174522399902344\n","#############    Validation Set Stats\n","Total Validation Loss = 16.627193450927734\n","  Accuracy: 0.6761\n","  Micro F1: 0.6813\n","  Macro F1: 0.6807\n","\n"," 83% 5/6 [10:05<02:01, 121.05s/it]Loss = 0.0\n","Loss = tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.867694854736328\n","#############    Validation Set Stats\n","Total Validation Loss = 17.276765823364258\n","  Accuracy: 0.6813\n","  Micro F1: 0.6842\n","  Macro F1: 0.6833\n","\n","100% 6/6 [12:06<00:00, 121.09s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6730, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.97843551635742\n","#############    Validation Set Stats\n","Total Validation Loss = 12.135457038879395\n","  Accuracy: 0.7264\n","  Micro F1: 0.7291\n","  Macro F1: 0.7263\n","\n"," 17% 1/6 [02:00<10:04, 120.92s/it]Loss = 0.0\n","Loss = tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.00550079345703\n","#############    Validation Set Stats\n","Total Validation Loss = 11.860118865966797\n","  Accuracy: 0.7194\n","  Micro F1: 0.7247\n","  Macro F1: 0.7245\n","\n"," 33% 2/6 [04:02<08:03, 120.98s/it]Loss = 0.0\n","Loss = tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.03931427001953\n","#############    Validation Set Stats\n","Total Validation Loss = 11.731865882873535\n","  Accuracy: 0.7308\n","  Micro F1: 0.7365\n","  Macro F1: 0.7354\n","\n"," 50% 3/6 [06:03<06:02, 120.99s/it]Loss = 0.0\n","Loss = tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.76181411743164\n","#############    Validation Set Stats\n","Total Validation Loss = 12.910176277160645\n","  Accuracy: 0.7279\n","  Micro F1: 0.7335\n","  Macro F1: 0.7325\n","\n"," 67% 4/6 [08:04<04:02, 121.02s/it]Loss = 0.0\n","Loss = tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.639177322387695\n","#############    Validation Set Stats\n","Total Validation Loss = 15.799542427062988\n","  Accuracy: 0.6896\n","  Micro F1: 0.6940\n","  Macro F1: 0.6940\n","\n"," 83% 5/6 [10:05<02:01, 121.01s/it]Loss = 0.0\n","Loss = tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.67281150817871\n","#############    Validation Set Stats\n","Total Validation Loss = 16.550989151000977\n","  Accuracy: 0.6954\n","  Micro F1: 0.7028\n","  Macro F1: 0.7028\n","\n","100% 6/6 [12:06<00:00, 121.04s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6590, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.84743118286133\n","#############    Validation Set Stats\n","Total Validation Loss = 12.145112037658691\n","  Accuracy: 0.7191\n","  Micro F1: 0.7189\n","  Macro F1: 0.7163\n","\n"," 17% 1/6 [02:00<10:04, 120.98s/it]Loss = 0.0\n","Loss = tensor(0.5165, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.69716262817383\n","#############    Validation Set Stats\n","Total Validation Loss = 11.915624618530273\n","  Accuracy: 0.7332\n","  Micro F1: 0.7306\n","  Macro F1: 0.7299\n","\n"," 33% 2/6 [04:02<08:04, 121.08s/it]Loss = 0.0\n","Loss = tensor(0.4585, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.244598388671875\n","#############    Validation Set Stats\n","Total Validation Loss = 12.055830955505371\n","  Accuracy: 0.7346\n","  Micro F1: 0.7321\n","  Macro F1: 0.7275\n","\n"," 50% 3/6 [06:03<06:03, 121.10s/it]Loss = 0.0\n","Loss = tensor(0.3939, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.75657653808594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.345585823059082\n","  Accuracy: 0.7048\n","  Micro F1: 0.7013\n","  Macro F1: 0.7013\n","\n"," 67% 4/6 [08:04<04:02, 121.16s/it]Loss = 0.0\n","Loss = tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.172157287597656\n","#############    Validation Set Stats\n","Total Validation Loss = 14.328595161437988\n","  Accuracy: 0.7119\n","  Micro F1: 0.7086\n","  Macro F1: 0.7078\n","\n"," 83% 5/6 [10:05<02:01, 121.16s/it]Loss = 0.0\n","Loss = tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.026403427124023\n","#############    Validation Set Stats\n","Total Validation Loss = 16.008838653564453\n","  Accuracy: 0.6993\n","  Micro F1: 0.6984\n","  Macro F1: 0.6982\n","\n","100% 6/6 [12:06<00:00, 121.13s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7284\n","  Micro F1: 0.7291\n","  Macro F1: 0.7277\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E8occyW1Jewb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596354315178,"user_tz":-330,"elapsed":11008088,"user":{"displayName":"Srijan Bansal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgA-ghRJQpZ_5fIVnl7Tn4cEdxvCnNwzbhhQ3-BvA=s64","userId":"15894314213587098430"}},"outputId":"29dc69dd-e984-42a7-8352-bbd9adedaf67"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-3 --num_labels 2 "],"execution_count":6,"outputs":[{"output_type":"stream","text":["2020-08-02 06:43:48.695272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6845, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.07052230834961\n","#############    Validation Set Stats\n","Total Validation Loss = 12.566619873046875\n","  Accuracy: 0.7183\n","  Micro F1: 0.7149\n","  Macro F1: 0.7148\n","\n"," 17% 1/6 [02:01<10:09, 121.85s/it]Loss = 0.0\n","Loss = tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.506282806396484\n","#############    Validation Set Stats\n","Total Validation Loss = 11.877270698547363\n","  Accuracy: 0.6965\n","  Micro F1: 0.6901\n","  Macro F1: 0.6824\n","\n"," 33% 2/6 [04:04<08:07, 121.98s/it]Loss = 0.0\n","Loss = tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.091129302978516\n","#############    Validation Set Stats\n","Total Validation Loss = 10.866483688354492\n","  Accuracy: 0.7580\n","  Micro F1: 0.7558\n","  Macro F1: 0.7543\n","\n"," 50% 3/6 [06:06<06:06, 122.14s/it]Loss = 0.0\n","Loss = tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.06467819213867\n","#############    Validation Set Stats\n","Total Validation Loss = 12.036688804626465\n","  Accuracy: 0.7396\n","  Micro F1: 0.7368\n","  Macro F1: 0.7362\n","\n"," 67% 4/6 [08:08<04:04, 122.18s/it]Loss = 0.0\n","Loss = tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.979270935058594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.434133529663086\n","  Accuracy: 0.7311\n","  Micro F1: 0.7281\n","  Macro F1: 0.7272\n","\n"," 83% 5/6 [10:11<02:02, 122.27s/it]Loss = 0.0\n","Loss = tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.731754302978516\n","#############    Validation Set Stats\n","Total Validation Loss = 14.033923149108887\n","  Accuracy: 0.7240\n","  Micro F1: 0.7208\n","  Macro F1: 0.7198\n","\n","100% 6/6 [12:14<00:00, 122.35s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6505, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.51970291137695\n","#############    Validation Set Stats\n","Total Validation Loss = 12.058036804199219\n","  Accuracy: 0.7126\n","  Micro F1: 0.7091\n","  Macro F1: 0.6954\n","\n"," 17% 1/6 [02:02<10:11, 122.22s/it]Loss = 0.0\n","Loss = tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.21999740600586\n","#############    Validation Set Stats\n","Total Validation Loss = 11.823359489440918\n","  Accuracy: 0.7211\n","  Micro F1: 0.7178\n","  Macro F1: 0.7175\n","\n"," 33% 2/6 [04:04<08:09, 122.35s/it]Loss = 0.0\n","Loss = tensor(0.4276, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.69017028808594\n","#############    Validation Set Stats\n","Total Validation Loss = 12.623650550842285\n","  Accuracy: 0.7206\n","  Micro F1: 0.7149\n","  Macro F1: 0.7116\n","\n"," 50% 3/6 [06:07<06:07, 122.37s/it]Loss = 0.0\n","Loss = tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.763538360595703\n","#############    Validation Set Stats\n","Total Validation Loss = 14.891526222229004\n","  Accuracy: 0.6889\n","  Micro F1: 0.6871\n","  Macro F1: 0.6852\n","\n"," 67% 4/6 [08:09<04:04, 122.46s/it]Loss = 0.0\n","Loss = tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.11808204650879\n","#############    Validation Set Stats\n","Total Validation Loss = 14.514896392822266\n","  Accuracy: 0.7031\n","  Micro F1: 0.7018\n","  Macro F1: 0.6990\n","\n"," 83% 5/6 [10:12<02:02, 122.46s/it]Loss = 0.0\n","Loss = tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.658823013305664\n","#############    Validation Set Stats\n","Total Validation Loss = 16.313764572143555\n","  Accuracy: 0.7074\n","  Micro F1: 0.7061\n","  Macro F1: 0.7061\n","\n","100% 6/6 [12:14<00:00, 122.44s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6772, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.07868957519531\n","#############    Validation Set Stats\n","Total Validation Loss = 13.211929321289062\n","  Accuracy: 0.6648\n","  Micro F1: 0.6623\n","  Macro F1: 0.6362\n","\n"," 17% 1/6 [02:01<10:09, 121.97s/it]Loss = 0.0\n","Loss = tensor(0.5360, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.57162857055664\n","#############    Validation Set Stats\n","Total Validation Loss = 11.777321815490723\n","  Accuracy: 0.7230\n","  Micro F1: 0.7222\n","  Macro F1: 0.7164\n","\n"," 33% 2/6 [04:04<08:08, 122.11s/it]Loss = 0.0\n","Loss = tensor(0.4572, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.72554016113281\n","#############    Validation Set Stats\n","Total Validation Loss = 13.304426193237305\n","  Accuracy: 0.6979\n","  Micro F1: 0.7061\n","  Macro F1: 0.7059\n","\n"," 50% 3/6 [06:07<06:06, 122.29s/it]Loss = 0.0\n","Loss = tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.538726806640625\n","#############    Validation Set Stats\n","Total Validation Loss = 13.843831062316895\n","  Accuracy: 0.6998\n","  Micro F1: 0.7032\n","  Macro F1: 0.6996\n","\n"," 67% 4/6 [08:09<04:04, 122.32s/it]Loss = 0.0\n","Loss = tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.71988868713379\n","#############    Validation Set Stats\n","Total Validation Loss = 16.086284637451172\n","  Accuracy: 0.6875\n","  Micro F1: 0.6930\n","  Macro F1: 0.6922\n","\n"," 83% 5/6 [10:11<02:02, 122.27s/it]Loss = 0.0\n","Loss = tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.274389266967773\n","#############    Validation Set Stats\n","Total Validation Loss = 17.004749298095703\n","  Accuracy: 0.6832\n","  Micro F1: 0.6886\n","  Macro F1: 0.6876\n","\n","100% 6/6 [12:14<00:00, 122.34s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6756, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.04195785522461\n","#############    Validation Set Stats\n","Total Validation Loss = 12.331266403198242\n","  Accuracy: 0.7364\n","  Micro F1: 0.7423\n","  Macro F1: 0.7393\n","\n"," 17% 1/6 [02:02<10:10, 122.05s/it]Loss = 0.0\n","Loss = tensor(0.5120, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.598506927490234\n","#############    Validation Set Stats\n","Total Validation Loss = 11.578054428100586\n","  Accuracy: 0.7195\n","  Micro F1: 0.7277\n","  Macro F1: 0.7277\n","\n"," 33% 2/6 [04:04<08:08, 122.16s/it]Loss = 0.0\n","Loss = tensor(0.4694, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.603363037109375\n","#############    Validation Set Stats\n","Total Validation Loss = 12.39517879486084\n","  Accuracy: 0.7110\n","  Micro F1: 0.7189\n","  Macro F1: 0.7179\n","\n"," 50% 3/6 [06:06<06:06, 122.19s/it]Loss = 0.0\n","Loss = tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.568265914916992\n","#############    Validation Set Stats\n","Total Validation Loss = 13.469334602355957\n","  Accuracy: 0.7153\n","  Micro F1: 0.7233\n","  Macro F1: 0.7233\n","\n"," 67% 4/6 [08:09<04:04, 122.28s/it]Loss = 0.0\n","Loss = tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.07005500793457\n","#############    Validation Set Stats\n","Total Validation Loss = 15.021113395690918\n","  Accuracy: 0.6925\n","  Micro F1: 0.6999\n","  Macro F1: 0.6992\n","\n"," 83% 5/6 [10:11<02:02, 122.41s/it]Loss = 0.0\n","Loss = tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 19.335647583007812\n","#############    Validation Set Stats\n","Total Validation Loss = 16.43012046813965\n","  Accuracy: 0.7053\n","  Micro F1: 0.7130\n","  Macro F1: 0.7122\n","\n","100% 6/6 [12:14<00:00, 122.40s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6780, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.89622497558594\n","#############    Validation Set Stats\n","Total Validation Loss = 12.405020713806152\n","  Accuracy: 0.7089\n","  Micro F1: 0.7028\n","  Macro F1: 0.7012\n","\n"," 17% 1/6 [02:02<10:10, 122.03s/it]Loss = 0.0\n","Loss = tensor(0.5196, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.90135192871094\n","#############    Validation Set Stats\n","Total Validation Loss = 11.571474075317383\n","  Accuracy: 0.7288\n","  Micro F1: 0.7233\n","  Macro F1: 0.7231\n","\n"," 33% 2/6 [04:04<08:08, 122.15s/it]Loss = 0.0\n","Loss = tensor(0.4701, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.21849822998047\n","#############    Validation Set Stats\n","Total Validation Loss = 12.558826446533203\n","  Accuracy: 0.7190\n","  Micro F1: 0.7160\n","  Macro F1: 0.7148\n","\n"," 50% 3/6 [06:06<06:06, 122.17s/it]Loss = 0.0\n","Loss = tensor(0.3884, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.74422836303711\n","#############    Validation Set Stats\n","Total Validation Loss = 13.582763671875\n","  Accuracy: 0.7149\n","  Micro F1: 0.7145\n","  Macro F1: 0.7145\n","\n"," 67% 4/6 [08:09<04:04, 122.25s/it]Loss = 0.0\n","Loss = tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.48040771484375\n","#############    Validation Set Stats\n","Total Validation Loss = 15.206561088562012\n","  Accuracy: 0.7005\n","  Micro F1: 0.6969\n","  Macro F1: 0.6941\n","\n"," 83% 5/6 [10:11<02:02, 122.40s/it]Loss = 0.0\n","Loss = tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.82120704650879\n","#############    Validation Set Stats\n","Total Validation Loss = 16.916461944580078\n","  Accuracy: 0.7008\n","  Micro F1: 0.7028\n","  Macro F1: 0.7023\n","\n","100% 6/6 [12:14<00:00, 122.39s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7335\n","  Micro F1: 0.7323\n","  Macro F1: 0.7301\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IaYovG5g5Tb5","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"JJZNBPBQN6sn","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HAN_BERT_CV.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPWDh1eN7KG75FG8RoaS+Xo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"fllY-TxkjyZq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1596224689343,"user_tz":-330,"elapsed":50413,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"f9b3c3e3-3af0-4b2a-a66b-54065ea4b46b"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount = True)\n","import os\n","root_path = 'gdrive/My Drive/Code_Switch/'\n","os.chdir(root_path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n0ZObXBPk8-F","colab_type":"code","colab":{}},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YVQT6s1wj9I_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596227377392,"user_tz":-330,"elapsed":2182731,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"7f590ff8-52cf-4101-d918-8a0e0230b6ad"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-4 --num_labels 2 "],"execution_count":6,"outputs":[{"output_type":"stream","text":["2020-07-31 19:53:17.185358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6799, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.154605865478516\n","#############    Validation Set Stats\n","Total Validation Loss = 12.422438621520996\n","  Accuracy: 0.7093\n","  Micro F1: 0.7032\n","  Macro F1: 0.6986\n","\n"," 17% 1/6 [01:05<05:28, 65.65s/it]Loss = 0.0\n","Loss = tensor(0.5230, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.5012092590332\n","#############    Validation Set Stats\n","Total Validation Loss = 11.062457084655762\n","  Accuracy: 0.7410\n","  Micro F1: 0.7383\n","  Macro F1: 0.7355\n","\n"," 33% 2/6 [02:18<04:30, 67.66s/it]Loss = 0.0\n","Loss = tensor(0.4372, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.34484100341797\n","#############    Validation Set Stats\n","Total Validation Loss = 11.968647956848145\n","  Accuracy: 0.7206\n","  Micro F1: 0.7149\n","  Macro F1: 0.7149\n","\n"," 50% 3/6 [03:30<03:26, 69.00s/it]Loss = 0.0\n","Loss = tensor(0.3749, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.35475540161133\n","#############    Validation Set Stats\n","Total Validation Loss = 12.200211524963379\n","  Accuracy: 0.7363\n","  Micro F1: 0.7310\n","  Macro F1: 0.7305\n","\n"," 67% 4/6 [04:42<02:20, 70.05s/it]Loss = 0.0\n","Loss = tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.878799438476562\n","#############    Validation Set Stats\n","Total Validation Loss = 13.836673736572266\n","  Accuracy: 0.7268\n","  Micro F1: 0.7237\n","  Macro F1: 0.7205\n","\n"," 83% 5/6 [05:55<01:10, 70.80s/it]Loss = 0.0\n","Loss = tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 20.91707992553711\n","#############    Validation Set Stats\n","Total Validation Loss = 15.908028602600098\n","  Accuracy: 0.7188\n","  Micro F1: 0.7178\n","  Macro F1: 0.7169\n","\n","100% 6/6 [07:07<00:00, 71.26s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.61672592163086\n","#############    Validation Set Stats\n","Total Validation Loss = 13.9168119430542\n","  Accuracy: 0.6738\n","  Micro F1: 0.6740\n","  Macro F1: 0.6698\n","\n"," 17% 1/6 [01:12<06:02, 72.50s/it]Loss = 0.0\n","Loss = tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.08104705810547\n","#############    Validation Set Stats\n","Total Validation Loss = 12.93846607208252\n","  Accuracy: 0.6842\n","  Micro F1: 0.6871\n","  Macro F1: 0.6860\n","\n"," 33% 2/6 [02:25<04:50, 72.56s/it]Loss = 0.0\n","Loss = tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.92951965332031\n","#############    Validation Set Stats\n","Total Validation Loss = 12.644731521606445\n","  Accuracy: 0.6979\n","  Micro F1: 0.6988\n","  Macro F1: 0.6988\n","\n"," 50% 3/6 [03:37<03:37, 72.54s/it]Loss = 0.0\n","Loss = tensor(0.3701, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.379661560058594\n","#############    Validation Set Stats\n","Total Validation Loss = 14.241660118103027\n","  Accuracy: 0.6960\n","  Micro F1: 0.6944\n","  Macro F1: 0.6940\n","\n"," 67% 4/6 [04:50<02:25, 72.53s/it]Loss = 0.0\n","Loss = tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.762659072875977\n","#############    Validation Set Stats\n","Total Validation Loss = 15.471677780151367\n","  Accuracy: 0.6918\n","  Micro F1: 0.6901\n","  Macro F1: 0.6899\n","\n"," 83% 5/6 [06:02<01:12, 72.53s/it]Loss = 0.0\n","Loss = tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.091445922851562\n","#############    Validation Set Stats\n","Total Validation Loss = 16.26504135131836\n","  Accuracy: 0.6960\n","  Micro F1: 0.6944\n","  Macro F1: 0.6944\n","\n","100% 6/6 [07:15<00:00, 72.53s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6795, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.2941780090332\n","#############    Validation Set Stats\n","Total Validation Loss = 13.24864387512207\n","  Accuracy: 0.6861\n","  Micro F1: 0.6915\n","  Macro F1: 0.6914\n","\n"," 17% 1/6 [01:12<06:01, 72.28s/it]Loss = 0.0\n","Loss = tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.10205841064453\n","#############    Validation Set Stats\n","Total Validation Loss = 11.74203109741211\n","  Accuracy: 0.7192\n","  Micro F1: 0.7208\n","  Macro F1: 0.7160\n","\n"," 33% 2/6 [02:24<04:49, 72.36s/it]Loss = 0.0\n","Loss = tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.54388427734375\n","#############    Validation Set Stats\n","Total Validation Loss = 12.331377983093262\n","  Accuracy: 0.7263\n","  Micro F1: 0.7281\n","  Macro F1: 0.7264\n","\n"," 50% 3/6 [03:37<03:37, 72.35s/it]Loss = 0.0\n","Loss = tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.774471282958984\n","#############    Validation Set Stats\n","Total Validation Loss = 13.651689529418945\n","  Accuracy: 0.7183\n","  Micro F1: 0.7222\n","  Macro F1: 0.7215\n","\n"," 67% 4/6 [04:49<02:24, 72.33s/it]Loss = 0.0\n","Loss = tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.980392456054688\n","#############    Validation Set Stats\n","Total Validation Loss = 15.517559051513672\n","  Accuracy: 0.6913\n","  Micro F1: 0.6944\n","  Macro F1: 0.6941\n","\n"," 83% 5/6 [06:01<01:12, 72.35s/it]Loss = 0.0\n","Loss = tensor(0.2413, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.33003807067871\n","#############    Validation Set Stats\n","Total Validation Loss = 18.014249801635742\n","  Accuracy: 0.6842\n","  Micro F1: 0.6871\n","  Macro F1: 0.6871\n","\n","100% 6/6 [07:14<00:00, 72.39s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6816, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.772789001464844\n","#############    Validation Set Stats\n","Total Validation Loss = 13.334600448608398\n","  Accuracy: 0.6457\n","  Micro F1: 0.6515\n","  Macro F1: 0.6382\n","\n"," 17% 1/6 [01:12<06:00, 72.17s/it]Loss = 0.0\n","Loss = tensor(0.5294, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.21747589111328\n","#############    Validation Set Stats\n","Total Validation Loss = 11.608903884887695\n","  Accuracy: 0.7308\n","  Micro F1: 0.7365\n","  Macro F1: 0.7347\n","\n"," 33% 2/6 [02:24<04:48, 72.21s/it]Loss = 0.0\n","Loss = tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.69773483276367\n","#############    Validation Set Stats\n","Total Validation Loss = 11.674592018127441\n","  Accuracy: 0.7351\n","  Micro F1: 0.7438\n","  Macro F1: 0.7436\n","\n"," 50% 3/6 [03:37<03:37, 72.35s/it]Loss = 0.0\n","Loss = tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.30247116088867\n","#############    Validation Set Stats\n","Total Validation Loss = 13.398392677307129\n","  Accuracy: 0.7151\n","  Micro F1: 0.7204\n","  Macro F1: 0.7193\n","\n"," 67% 4/6 [04:49<02:24, 72.32s/it]Loss = 0.0\n","Loss = tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.213069915771484\n","#############    Validation Set Stats\n","Total Validation Loss = 14.934039115905762\n","  Accuracy: 0.6756\n","  Micro F1: 0.6852\n","  Macro F1: 0.6852\n","\n"," 83% 5/6 [06:01<01:12, 72.37s/it]Loss = 0.0\n","Loss = tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.937946319580078\n","#############    Validation Set Stats\n","Total Validation Loss = 16.9411678314209\n","  Accuracy: 0.6827\n","  Micro F1: 0.6925\n","  Macro F1: 0.6925\n","\n","100% 6/6 [07:14<00:00, 72.39s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6711, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.16499710083008\n","#############    Validation Set Stats\n","Total Validation Loss = 12.623862266540527\n","  Accuracy: 0.7160\n","  Micro F1: 0.7101\n","  Macro F1: 0.6976\n","\n"," 17% 1/6 [01:11<05:59, 71.99s/it]Loss = 0.0\n","Loss = tensor(0.5225, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.94647979736328\n","#############    Validation Set Stats\n","Total Validation Loss = 11.576729774475098\n","  Accuracy: 0.7317\n","  Micro F1: 0.7262\n","  Macro F1: 0.7211\n","\n"," 33% 2/6 [02:24<04:48, 72.04s/it]Loss = 0.0\n","Loss = tensor(0.4463, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.03368377685547\n","#############    Validation Set Stats\n","Total Validation Loss = 13.15435791015625\n","  Accuracy: 0.7147\n","  Micro F1: 0.7116\n","  Macro F1: 0.7116\n","\n"," 50% 3/6 [03:36<03:36, 72.10s/it]Loss = 0.0\n","Loss = tensor(0.3870, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.297306060791016\n","#############    Validation Set Stats\n","Total Validation Loss = 14.20754337310791\n","  Accuracy: 0.7120\n","  Micro F1: 0.7116\n","  Macro F1: 0.7114\n","\n"," 67% 4/6 [04:48<02:24, 72.13s/it]Loss = 0.0\n","Loss = tensor(0.2948, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.77602195739746\n","#############    Validation Set Stats\n","Total Validation Loss = 16.593883514404297\n","  Accuracy: 0.6964\n","  Micro F1: 0.6955\n","  Macro F1: 0.6954\n","\n"," 83% 5/6 [06:00<01:12, 72.15s/it]Loss = 0.0\n","Loss = tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.24540901184082\n","#############    Validation Set Stats\n","Total Validation Loss = 18.319814682006836\n","  Accuracy: 0.6865\n","  Micro F1: 0.6852\n","  Macro F1: 0.6852\n","\n","100% 6/6 [07:13<00:00, 72.21s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7264\n","  Micro F1: 0.7270\n","  Macro F1: 0.7251\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Sy9rhwKZoxj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596229554457,"user_tz":-330,"elapsed":2162696,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"4215e408-11fe-4d7d-88f3-7a2482cd8f7b"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":7,"outputs":[{"output_type":"stream","text":["2020-07-31 20:29:54.558000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6927, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 60.11385726928711\n","#############    Validation Set Stats\n","Total Validation Loss = 14.13551139831543\n","  Accuracy: 0.6742\n","  Micro F1: 0.6696\n","  Macro F1: 0.6681\n","\n"," 17% 1/6 [01:11<05:58, 71.71s/it]Loss = 0.0\n","Loss = tensor(0.5806, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.1750602722168\n","#############    Validation Set Stats\n","Total Validation Loss = 12.575576782226562\n","  Accuracy: 0.7093\n","  Micro F1: 0.7032\n","  Macro F1: 0.6963\n","\n"," 33% 2/6 [02:23<04:46, 71.60s/it]Loss = 0.0\n","Loss = tensor(0.5104, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.21357727050781\n","#############    Validation Set Stats\n","Total Validation Loss = 11.424667358398438\n","  Accuracy: 0.7424\n","  Micro F1: 0.7398\n","  Macro F1: 0.7392\n","\n"," 50% 3/6 [03:34<03:34, 71.53s/it]Loss = 0.0\n","Loss = tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.49586868286133\n","#############    Validation Set Stats\n","Total Validation Loss = 11.16911792755127\n","  Accuracy: 0.7325\n","  Micro F1: 0.7295\n","  Macro F1: 0.7268\n","\n"," 67% 4/6 [04:45<02:23, 71.51s/it]Loss = 0.0\n","Loss = tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.06714630126953\n","#############    Validation Set Stats\n","Total Validation Loss = 13.602727890014648\n","  Accuracy: 0.7069\n","  Micro F1: 0.7032\n","  Macro F1: 0.7023\n","\n"," 83% 5/6 [05:57<01:11, 71.40s/it]Loss = 0.0\n","Loss = tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.6646671295166\n","#############    Validation Set Stats\n","Total Validation Loss = 13.471746444702148\n","  Accuracy: 0.7140\n","  Micro F1: 0.7105\n","  Macro F1: 0.7105\n","\n","100% 6/6 [07:08<00:00, 71.43s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6517, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.78345489501953\n","#############    Validation Set Stats\n","Total Validation Loss = 12.697848320007324\n","  Accuracy: 0.7003\n","  Micro F1: 0.6988\n","  Macro F1: 0.6872\n","\n"," 17% 1/6 [01:11<05:57, 71.52s/it]Loss = 0.0\n","Loss = tensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.55791091918945\n","#############    Validation Set Stats\n","Total Validation Loss = 12.480472564697266\n","  Accuracy: 0.7121\n","  Micro F1: 0.7135\n","  Macro F1: 0.7134\n","\n"," 33% 2/6 [02:23<04:46, 71.52s/it]Loss = 0.0\n","Loss = tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.464874267578125\n","#############    Validation Set Stats\n","Total Validation Loss = 12.85472583770752\n","  Accuracy: 0.7060\n","  Micro F1: 0.7047\n","  Macro F1: 0.7041\n","\n"," 50% 3/6 [03:34<03:34, 71.54s/it]Loss = 0.0\n","Loss = tensor(0.3687, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.442264556884766\n","#############    Validation Set Stats\n","Total Validation Loss = 13.743255615234375\n","  Accuracy: 0.7169\n","  Micro F1: 0.7135\n","  Macro F1: 0.7099\n","\n"," 67% 4/6 [04:46<02:23, 71.59s/it]Loss = 0.0\n","Loss = tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.39714813232422\n","#############    Validation Set Stats\n","Total Validation Loss = 15.04397201538086\n","  Accuracy: 0.7178\n","  Micro F1: 0.7193\n","  Macro F1: 0.7192\n","\n"," 83% 5/6 [05:57<01:11, 71.58s/it]Loss = 0.0\n","Loss = tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.45703125\n","#############    Validation Set Stats\n","Total Validation Loss = 16.330509185791016\n","  Accuracy: 0.7159\n","  Micro F1: 0.7149\n","  Macro F1: 0.7149\n","\n","100% 6/6 [07:09<00:00, 71.55s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6745, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.953067779541016\n","#############    Validation Set Stats\n","Total Validation Loss = 12.443193435668945\n","  Accuracy: 0.6941\n","  Micro F1: 0.6974\n","  Macro F1: 0.6873\n","\n"," 17% 1/6 [01:11<05:56, 71.21s/it]Loss = 0.0\n","Loss = tensor(0.5247, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.17050552368164\n","#############    Validation Set Stats\n","Total Validation Loss = 12.108100891113281\n","  Accuracy: 0.7012\n","  Micro F1: 0.7047\n","  Macro F1: 0.7043\n","\n"," 33% 2/6 [02:22<04:45, 71.38s/it]Loss = 0.0\n","Loss = tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.525535583496094\n","#############    Validation Set Stats\n","Total Validation Loss = 12.414168357849121\n","  Accuracy: 0.7041\n","  Micro F1: 0.7076\n","  Macro F1: 0.7076\n","\n"," 50% 3/6 [03:34<03:34, 71.35s/it]Loss = 0.0\n","Loss = tensor(0.4078, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.91325378417969\n","#############    Validation Set Stats\n","Total Validation Loss = 12.848352432250977\n","  Accuracy: 0.6974\n","  Micro F1: 0.7032\n","  Macro F1: 0.7023\n","\n"," 67% 4/6 [04:45<02:22, 71.32s/it]Loss = 0.0\n","Loss = tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.662139892578125\n","#############    Validation Set Stats\n","Total Validation Loss = 15.395668983459473\n","  Accuracy: 0.6832\n","  Micro F1: 0.6886\n","  Macro F1: 0.6886\n","\n"," 83% 5/6 [05:56<01:11, 71.35s/it]Loss = 0.0\n","Loss = tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.14362335205078\n","#############    Validation Set Stats\n","Total Validation Loss = 15.973508834838867\n","  Accuracy: 0.6899\n","  Micro F1: 0.6930\n","  Macro F1: 0.6929\n","\n","100% 6/6 [07:08<00:00, 71.39s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6775, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.133697509765625\n","#############    Validation Set Stats\n","Total Validation Loss = 12.427855491638184\n","  Accuracy: 0.7079\n","  Micro F1: 0.7101\n","  Macro F1: 0.7095\n","\n"," 17% 1/6 [01:11<05:58, 71.67s/it]Loss = 0.0\n","Loss = tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.69642639160156\n","#############    Validation Set Stats\n","Total Validation Loss = 11.489816665649414\n","  Accuracy: 0.7450\n","  Micro F1: 0.7511\n","  Macro F1: 0.7468\n","\n"," 33% 2/6 [02:23<04:46, 71.67s/it]Loss = 0.0\n","Loss = tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.63151931762695\n","#############    Validation Set Stats\n","Total Validation Loss = 12.156450271606445\n","  Accuracy: 0.7224\n","  Micro F1: 0.7306\n","  Macro F1: 0.7299\n","\n"," 50% 3/6 [03:34<03:34, 71.57s/it]Loss = 0.0\n","Loss = tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.2946662902832\n","#############    Validation Set Stats\n","Total Validation Loss = 15.064912796020508\n","  Accuracy: 0.6712\n","  Micro F1: 0.6779\n","  Macro F1: 0.6771\n","\n"," 67% 4/6 [04:46<02:23, 71.52s/it]Loss = 0.0\n","Loss = tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.62848663330078\n","#############    Validation Set Stats\n","Total Validation Loss = 15.720465660095215\n","  Accuracy: 0.6897\n","  Micro F1: 0.6969\n","  Macro F1: 0.6959\n","\n"," 83% 5/6 [05:57<01:11, 71.47s/it]Loss = 0.0\n","Loss = tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.007118225097656\n","#############    Validation Set Stats\n","Total Validation Loss = 17.363460540771484\n","  Accuracy: 0.6841\n","  Micro F1: 0.6940\n","  Macro F1: 0.6936\n","\n","100% 6/6 [07:08<00:00, 71.48s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6642, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.21311569213867\n","#############    Validation Set Stats\n","Total Validation Loss = 12.849982261657715\n","  Accuracy: 0.7034\n","  Micro F1: 0.6999\n","  Macro F1: 0.6981\n","\n"," 17% 1/6 [01:11<05:56, 71.31s/it]Loss = 0.0\n","Loss = tensor(0.4963, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.55853271484375\n","#############    Validation Set Stats\n","Total Validation Loss = 11.562957763671875\n","  Accuracy: 0.7288\n","  Micro F1: 0.7233\n","  Macro F1: 0.7115\n","\n"," 33% 2/6 [02:22<04:45, 71.38s/it]Loss = 0.0\n","Loss = tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.04348373413086\n","#############    Validation Set Stats\n","Total Validation Loss = 13.851580619812012\n","  Accuracy: 0.7136\n","  Micro F1: 0.7160\n","  Macro F1: 0.7148\n","\n"," 50% 3/6 [03:34<03:34, 71.48s/it]Loss = 0.0\n","Loss = tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.839656829833984\n","#############    Validation Set Stats\n","Total Validation Loss = 14.376194953918457\n","  Accuracy: 0.7021\n","  Micro F1: 0.7013\n","  Macro F1: 0.7002\n","\n"," 67% 4/6 [04:46<02:22, 71.49s/it]Loss = 0.0\n","Loss = tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.82890510559082\n","#############    Validation Set Stats\n","Total Validation Loss = 14.704243659973145\n","  Accuracy: 0.7177\n","  Micro F1: 0.7174\n","  Macro F1: 0.7174\n","\n"," 83% 5/6 [05:57<01:11, 71.44s/it]Loss = 0.0\n","Loss = tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.395095825195312\n","#############    Validation Set Stats\n","Total Validation Loss = 17.395416259765625\n","  Accuracy: 0.7049\n","  Micro F1: 0.7042\n","  Macro F1: 0.7039\n","\n","100% 6/6 [07:08<00:00, 71.45s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7254\n","  Micro F1: 0.7270\n","  Macro F1: 0.7260\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ncf4SxnFZpl_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596231702747,"user_tz":-330,"elapsed":4310976,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"691c9940-57d6-4daa-94d9-dea0a8a14a3e"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-4 --num_labels 2 "],"execution_count":8,"outputs":[{"output_type":"stream","text":["2020-07-31 21:05:55.858142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6672, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.76812744140625\n","#############    Validation Set Stats\n","Total Validation Loss = 12.127388000488281\n","  Accuracy: 0.7112\n","  Micro F1: 0.7076\n","  Macro F1: 0.6944\n","\n"," 17% 1/6 [01:08<05:43, 68.62s/it]Loss = 0.0\n","Loss = tensor(0.5320, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.10560989379883\n","#############    Validation Set Stats\n","Total Validation Loss = 11.710667610168457\n","  Accuracy: 0.7363\n","  Micro F1: 0.7310\n","  Macro F1: 0.7294\n","\n"," 33% 2/6 [02:18<04:36, 69.04s/it]Loss = 0.0\n","Loss = tensor(0.4992, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.80266571044922\n","#############    Validation Set Stats\n","Total Validation Loss = 12.12240219116211\n","  Accuracy: 0.7396\n","  Micro F1: 0.7368\n","  Macro F1: 0.7368\n","\n"," 50% 3/6 [03:29<03:28, 69.54s/it]Loss = 0.0\n","Loss = tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.447914123535156\n","#############    Validation Set Stats\n","Total Validation Loss = 11.960848808288574\n","  Accuracy: 0.7514\n","  Micro F1: 0.7515\n","  Macro F1: 0.7512\n","\n"," 67% 4/6 [04:40<02:20, 70.00s/it]Loss = 0.0\n","Loss = tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.534034729003906\n","#############    Validation Set Stats\n","Total Validation Loss = 13.341543197631836\n","  Accuracy: 0.7306\n","  Micro F1: 0.7251\n","  Macro F1: 0.7251\n","\n"," 83% 5/6 [05:51<01:10, 70.31s/it]Loss = 0.0\n","Loss = tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.860441207885742\n","#############    Validation Set Stats\n","Total Validation Loss = 13.277978897094727\n","  Accuracy: 0.7348\n","  Micro F1: 0.7295\n","  Macro F1: 0.7294\n","\n","100% 6/6 [07:02<00:00, 70.41s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6645, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.242637634277344\n","#############    Validation Set Stats\n","Total Validation Loss = 13.907381057739258\n","  Accuracy: 0.6510\n","  Micro F1: 0.6433\n","  Macro F1: 0.6364\n","\n"," 17% 1/6 [01:11<05:56, 71.31s/it]Loss = 0.0\n","Loss = tensor(0.5250, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.01045608520508\n","#############    Validation Set Stats\n","Total Validation Loss = 12.349815368652344\n","  Accuracy: 0.7140\n","  Micro F1: 0.7105\n","  Macro F1: 0.7061\n","\n"," 33% 2/6 [02:22<04:45, 71.27s/it]Loss = 0.0\n","Loss = tensor(0.4619, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.83784866333008\n","#############    Validation Set Stats\n","Total Validation Loss = 12.53787612915039\n","  Accuracy: 0.7244\n","  Micro F1: 0.7237\n","  Macro F1: 0.7154\n","\n"," 50% 3/6 [03:33<03:33, 71.25s/it]Loss = 0.0\n","Loss = tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.57625961303711\n","#############    Validation Set Stats\n","Total Validation Loss = 13.11416244506836\n","  Accuracy: 0.7107\n","  Micro F1: 0.7120\n","  Macro F1: 0.7104\n","\n"," 67% 4/6 [04:44<02:22, 71.26s/it]Loss = 0.0\n","Loss = tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.48736572265625\n","#############    Validation Set Stats\n","Total Validation Loss = 14.576720237731934\n","  Accuracy: 0.7022\n","  Micro F1: 0.7032\n","  Macro F1: 0.7027\n","\n"," 83% 5/6 [05:56<01:11, 71.26s/it]Loss = 0.0\n","Loss = tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.79090690612793\n","#############    Validation Set Stats\n","Total Validation Loss = 15.74881649017334\n","  Accuracy: 0.7126\n","  Micro F1: 0.7164\n","  Macro F1: 0.7164\n","\n","100% 6/6 [07:07<00:00, 71.24s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6807, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.16707229614258\n","#############    Validation Set Stats\n","Total Validation Loss = 13.16029167175293\n","  Accuracy: 0.6979\n","  Micro F1: 0.6988\n","  Macro F1: 0.6988\n","\n"," 17% 1/6 [01:11<05:55, 71.12s/it]Loss = 0.0\n","Loss = tensor(0.5330, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.022544860839844\n","#############    Validation Set Stats\n","Total Validation Loss = 11.945733070373535\n","  Accuracy: 0.7183\n","  Micro F1: 0.7222\n","  Macro F1: 0.7221\n","\n"," 33% 2/6 [02:22<04:44, 71.20s/it]Loss = 0.0\n","Loss = tensor(0.4753, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.851036071777344\n","#############    Validation Set Stats\n","Total Validation Loss = 12.022228240966797\n","  Accuracy: 0.7183\n","  Micro F1: 0.7222\n","  Macro F1: 0.7166\n","\n"," 50% 3/6 [03:33<03:33, 71.28s/it]Loss = 0.0\n","Loss = tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.70269775390625\n","#############    Validation Set Stats\n","Total Validation Loss = 13.459033966064453\n","  Accuracy: 0.6899\n","  Micro F1: 0.6930\n","  Macro F1: 0.6927\n","\n"," 67% 4/6 [04:45<02:22, 71.26s/it]Loss = 0.0\n","Loss = tensor(0.3775, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.703914642333984\n","#############    Validation Set Stats\n","Total Validation Loss = 14.767806053161621\n","  Accuracy: 0.6785\n","  Micro F1: 0.6813\n","  Macro F1: 0.6808\n","\n"," 83% 5/6 [05:56<01:11, 71.24s/it]Loss = 0.0\n","Loss = tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.67723846435547\n","#############    Validation Set Stats\n","Total Validation Loss = 14.679373741149902\n","  Accuracy: 0.6998\n","  Micro F1: 0.7032\n","  Macro F1: 0.7022\n","\n","100% 6/6 [07:07<00:00, 71.25s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6502, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.078346252441406\n","#############    Validation Set Stats\n","Total Validation Loss = 12.32812786102295\n","  Accuracy: 0.7191\n","  Micro F1: 0.7189\n","  Macro F1: 0.7168\n","\n"," 17% 1/6 [01:11<05:56, 71.21s/it]Loss = 0.0\n","Loss = tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.07017135620117\n","#############    Validation Set Stats\n","Total Validation Loss = 11.384892463684082\n","  Accuracy: 0.7322\n","  Micro F1: 0.7379\n","  Macro F1: 0.7331\n","\n"," 33% 2/6 [02:22<04:44, 71.24s/it]Loss = 0.0\n","Loss = tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.548553466796875\n","#############    Validation Set Stats\n","Total Validation Loss = 12.867254257202148\n","  Accuracy: 0.7110\n","  Micro F1: 0.7189\n","  Macro F1: 0.7168\n","\n"," 50% 3/6 [03:33<03:33, 71.30s/it]Loss = 0.0\n","Loss = tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.81969451904297\n","#############    Validation Set Stats\n","Total Validation Loss = 12.425250053405762\n","  Accuracy: 0.7266\n","  Micro F1: 0.7350\n","  Macro F1: 0.7336\n","\n"," 67% 4/6 [04:45<02:22, 71.33s/it]Loss = 0.0\n","Loss = tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.860265731811523\n","#############    Validation Set Stats\n","Total Validation Loss = 14.477811813354492\n","  Accuracy: 0.7111\n","  Micro F1: 0.7218\n","  Macro F1: 0.7218\n","\n"," 83% 5/6 [05:56<01:11, 71.27s/it]Loss = 0.0\n","Loss = tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.922744750976562\n","#############    Validation Set Stats\n","Total Validation Loss = 14.970410346984863\n","  Accuracy: 0.7111\n","  Micro F1: 0.7218\n","  Macro F1: 0.7218\n","\n","100% 6/6 [07:07<00:00, 71.29s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6639, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.64510726928711\n","#############    Validation Set Stats\n","Total Validation Loss = 12.720428466796875\n","  Accuracy: 0.6933\n","  Micro F1: 0.6867\n","  Macro F1: 0.6815\n","\n"," 17% 1/6 [01:11<05:56, 71.25s/it]Loss = 0.0\n","Loss = tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.43467330932617\n","#############    Validation Set Stats\n","Total Validation Loss = 11.568838119506836\n","  Accuracy: 0.7302\n","  Micro F1: 0.7247\n","  Macro F1: 0.7164\n","\n"," 33% 2/6 [02:22<04:44, 71.25s/it]Loss = 0.0\n","Loss = tensor(0.4693, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.899654388427734\n","#############    Validation Set Stats\n","Total Validation Loss = 11.884429931640625\n","  Accuracy: 0.7302\n","  Micro F1: 0.7247\n","  Macro F1: 0.7188\n","\n"," 50% 3/6 [03:33<03:33, 71.25s/it]Loss = 0.0\n","Loss = tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.108802795410156\n","#############    Validation Set Stats\n","Total Validation Loss = 13.57178020477295\n","  Accuracy: 0.7177\n","  Micro F1: 0.7174\n","  Macro F1: 0.7166\n","\n"," 67% 4/6 [04:45<02:22, 71.26s/it]Loss = 0.0\n","Loss = tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.97342300415039\n","#############    Validation Set Stats\n","Total Validation Loss = 15.570008277893066\n","  Accuracy: 0.6978\n","  Micro F1: 0.6969\n","  Macro F1: 0.6968\n","\n"," 83% 5/6 [05:56<01:11, 71.24s/it]Loss = 0.0\n","Loss = tensor(0.2861, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.26910400390625\n","#############    Validation Set Stats\n","Total Validation Loss = 15.833806037902832\n","  Accuracy: 0.6950\n","  Micro F1: 0.6940\n","  Macro F1: 0.6937\n","\n","100% 6/6 [07:07<00:00, 71.23s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7278\n","  Micro F1: 0.7300\n","  Macro F1: 0.7284\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R8rgKQtSZp5G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596233880323,"user_tz":-330,"elapsed":749676,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"82208b67-85fb-4b1b-a9b2-871b5dc91482"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-3 --num_labels 2 "],"execution_count":9,"outputs":[{"output_type":"stream","text":["2020-07-31 21:41:44.196552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6799, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.154605865478516\n","#############    Validation Set Stats\n","Total Validation Loss = 12.422438621520996\n","  Accuracy: 0.7093\n","  Micro F1: 0.7032\n","  Macro F1: 0.6986\n","\n"," 17% 1/6 [01:09<05:46, 69.35s/it]Loss = 0.0\n","Loss = tensor(0.5230, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.5012092590332\n","#############    Validation Set Stats\n","Total Validation Loss = 11.062457084655762\n","  Accuracy: 0.7410\n","  Micro F1: 0.7383\n","  Macro F1: 0.7355\n","\n"," 33% 2/6 [02:20<04:39, 69.77s/it]Loss = 0.0\n","Loss = tensor(0.4372, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.34484100341797\n","#############    Validation Set Stats\n","Total Validation Loss = 11.968647956848145\n","  Accuracy: 0.7206\n","  Micro F1: 0.7149\n","  Macro F1: 0.7149\n","\n"," 50% 3/6 [03:31<03:30, 70.25s/it]Loss = 0.0\n","Loss = tensor(0.3749, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.35475540161133\n","#############    Validation Set Stats\n","Total Validation Loss = 12.200211524963379\n","  Accuracy: 0.7363\n","  Micro F1: 0.7310\n","  Macro F1: 0.7305\n","\n"," 67% 4/6 [04:43<02:21, 70.69s/it]Loss = 0.0\n","Loss = tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.878799438476562\n","#############    Validation Set Stats\n","Total Validation Loss = 13.836673736572266\n","  Accuracy: 0.7268\n","  Micro F1: 0.7237\n","  Macro F1: 0.7205\n","\n"," 83% 5/6 [05:54<01:10, 70.99s/it]Loss = 0.0\n","Loss = tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 20.91707992553711\n","#############    Validation Set Stats\n","Total Validation Loss = 15.908028602600098\n","  Accuracy: 0.7188\n","  Micro F1: 0.7178\n","  Macro F1: 0.7169\n","\n","100% 6/6 [07:06<00:00, 71.14s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.61672592163086\n","#############    Validation Set Stats\n","Total Validation Loss = 13.9168119430542\n","  Accuracy: 0.6738\n","  Micro F1: 0.6740\n","  Macro F1: 0.6698\n","\n"," 17% 1/6 [01:11<05:59, 71.82s/it]Loss = 0.0\n","Loss = tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.08104705810547\n","#############    Validation Set Stats\n","Total Validation Loss = 12.93846607208252\n","  Accuracy: 0.6842\n","  Micro F1: 0.6871\n","  Macro F1: 0.6860\n","\n"," 33% 2/6 [02:23<04:47, 71.86s/it]Loss = 0.0\n","Loss = tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.92951965332031\n","#############    Validation Set Stats\n","Total Validation Loss = 12.644731521606445\n","  Accuracy: 0.6979\n","  Micro F1: 0.6988\n","  Macro F1: 0.6988\n","\n"," 50% 3/6 [03:36<03:36, 72.01s/it]Loss = 0.0\n","Loss = tensor(0.3701, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.379661560058594\n","#############    Validation Set Stats\n","Total Validation Loss = 14.241660118103027\n","  Accuracy: 0.6960\n","  Micro F1: 0.6944\n","  Macro F1: 0.6940\n","\n"," 67% 4/6 [04:48<02:24, 72.11s/it]Loss = 0.0\n","Loss = tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.762659072875977\n","#############    Validation Set Stats\n","Total Validation Loss = 15.471677780151367\n","  Accuracy: 0.6918\n","  Micro F1: 0.6901\n","  Macro F1: 0.6899\n","\n"," 83% 5/6 [06:00<01:12, 72.13s/it]Loss = 0.0\n","Loss = tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.091445922851562\n","#############    Validation Set Stats\n","Total Validation Loss = 16.26504135131836\n","  Accuracy: 0.6960\n","  Micro F1: 0.6944\n","  Macro F1: 0.6944\n","\n","100% 6/6 [07:12<00:00, 72.14s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6795, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.2941780090332\n","#############    Validation Set Stats\n","Total Validation Loss = 13.24864387512207\n","  Accuracy: 0.6861\n","  Micro F1: 0.6915\n","  Macro F1: 0.6914\n","\n"," 17% 1/6 [01:12<06:00, 72.19s/it]Loss = 0.0\n","Loss = tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.10205841064453\n","#############    Validation Set Stats\n","Total Validation Loss = 11.74203109741211\n","  Accuracy: 0.7192\n","  Micro F1: 0.7208\n","  Macro F1: 0.7160\n","\n"," 33% 2/6 [02:24<04:48, 72.19s/it]Loss = 0.0\n","Loss = tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.54388427734375\n","#############    Validation Set Stats\n","Total Validation Loss = 12.331377983093262\n","  Accuracy: 0.7263\n","  Micro F1: 0.7281\n","  Macro F1: 0.7264\n","\n"," 50% 3/6 [03:36<03:36, 72.18s/it]Loss = 0.0\n","Loss = tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.774471282958984\n","#############    Validation Set Stats\n","Total Validation Loss = 13.651689529418945\n","  Accuracy: 0.7183\n","  Micro F1: 0.7222\n","  Macro F1: 0.7215\n","\n"," 67% 4/6 [04:48<02:24, 72.22s/it]Loss = 0.0\n","Loss = tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.980392456054688\n","#############    Validation Set Stats\n","Total Validation Loss = 15.517559051513672\n","  Accuracy: 0.6913\n","  Micro F1: 0.6944\n","  Macro F1: 0.6941\n","\n"," 83% 5/6 [06:01<01:12, 72.24s/it]Loss = 0.0\n","Loss = tensor(0.2413, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.33003807067871\n","#############    Validation Set Stats\n","Total Validation Loss = 18.014249801635742\n","  Accuracy: 0.6842\n","  Micro F1: 0.6871\n","  Macro F1: 0.6871\n","\n","100% 6/6 [07:13<00:00, 72.23s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6816, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.772789001464844\n","#############    Validation Set Stats\n","Total Validation Loss = 13.334600448608398\n","  Accuracy: 0.6457\n","  Micro F1: 0.6515\n","  Macro F1: 0.6382\n","\n"," 17% 1/6 [01:12<06:00, 72.00s/it]Loss = 0.0\n","Loss = tensor(0.5294, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.21747589111328\n","#############    Validation Set Stats\n","Total Validation Loss = 11.608903884887695\n","  Accuracy: 0.7308\n","  Micro F1: 0.7365\n","  Macro F1: 0.7347\n","\n"," 33% 2/6 [02:24<04:48, 72.07s/it]Loss = 0.0\n","Loss = tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.69773483276367\n","#############    Validation Set Stats\n","Total Validation Loss = 11.674592018127441\n","  Accuracy: 0.7351\n","  Micro F1: 0.7438\n","  Macro F1: 0.7436\n","\n"," 50% 3/6 [03:36<03:36, 72.12s/it]Loss = 0.0\n","Loss = tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.30247116088867\n","#############    Validation Set Stats\n","Total Validation Loss = 13.398392677307129\n","  Accuracy: 0.7151\n","  Micro F1: 0.7204\n","  Macro F1: 0.7193\n","\n"," 67% 4/6 [04:48<02:24, 72.15s/it]Loss = 0.0\n","Loss = tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.213069915771484\n","#############    Validation Set Stats\n","Total Validation Loss = 14.934039115905762\n","  Accuracy: 0.6756\n","  Micro F1: 0.6852\n","  Macro F1: 0.6852\n","\n"," 83% 5/6 [06:01<01:12, 72.23s/it]Loss = 0.0\n","Loss = tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.937946319580078\n","#############    Validation Set Stats\n","Total Validation Loss = 16.9411678314209\n","  Accuracy: 0.6827\n","  Micro F1: 0.6925\n","  Macro F1: 0.6925\n","\n","100% 6/6 [07:13<00:00, 72.20s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6711, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.16499710083008\n","#############    Validation Set Stats\n","Total Validation Loss = 12.623862266540527\n","  Accuracy: 0.7160\n","  Micro F1: 0.7101\n","  Macro F1: 0.6976\n","\n"," 17% 1/6 [01:11<05:58, 71.73s/it]Loss = 0.0\n","Loss = tensor(0.5225, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.94647979736328\n","#############    Validation Set Stats\n","Total Validation Loss = 11.576729774475098\n","  Accuracy: 0.7317\n","  Micro F1: 0.7262\n","  Macro F1: 0.7211\n","\n"," 33% 2/6 [02:23<04:47, 71.76s/it]Loss = 0.0\n","Loss = tensor(0.4463, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.03368377685547\n","#############    Validation Set Stats\n","Total Validation Loss = 13.15435791015625\n","  Accuracy: 0.7147\n","  Micro F1: 0.7116\n","  Macro F1: 0.7116\n","\n"," 50% 3/6 [03:35<03:35, 71.79s/it]Loss = 0.0\n","\n","Total Train Loss = 32.297306060791016\n","#############    Validation Set Stats\n","Total Validation Loss = 14.20754337310791\n","  Accuracy: 0.7120\n","  Micro F1: 0.7116\n","  Macro F1: 0.7114\n","\n"," 67% 4/6 [04:47<02:23, 71.78s/it]Loss = 0.0\n","Loss = tensor(0.2948, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.77602195739746\n","#############    Validation Set Stats\n","Total Validation Loss = 16.593883514404297\n","  Accuracy: 0.6964\n","  Micro F1: 0.6955\n","  Macro F1: 0.6954\n","\n"," 83% 5/6 [05:58<01:11, 71.76s/it]Loss = 0.0\n","Loss = tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 21.24540901184082\n","#############    Validation Set Stats\n","Total Validation Loss = 18.319814682006836\n","  Accuracy: 0.6865\n","  Micro F1: 0.6852\n","  Macro F1: 0.6852\n","\n","100% 6/6 [07:10<00:00, 71.76s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7264\n","  Micro F1: 0.7270\n","  Macro F1: 0.7251\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T411DpQCZqMl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596236032682,"user_tz":-330,"elapsed":2152372,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"5a59f5e3-615a-4d94-fd90-7f7ef195e871"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-3 --num_labels 2 "],"execution_count":10,"outputs":[{"output_type":"stream","text":["2020-07-31 22:18:05.624664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6927, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 60.11385726928711\n","#############    Validation Set Stats\n","Total Validation Loss = 14.13551139831543\n","  Accuracy: 0.6742\n","  Micro F1: 0.6696\n","  Macro F1: 0.6681\n","\n"," 17% 1/6 [01:07<05:39, 67.82s/it]Loss = 0.0\n","Loss = tensor(0.5806, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.1750602722168\n","#############    Validation Set Stats\n","Total Validation Loss = 12.575576782226562\n","  Accuracy: 0.7093\n","  Micro F1: 0.7032\n","  Macro F1: 0.6963\n","\n"," 33% 2/6 [02:16<04:32, 68.16s/it]Loss = 0.0\n","Loss = tensor(0.5104, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.21357727050781\n","#############    Validation Set Stats\n","Total Validation Loss = 11.424667358398438\n","  Accuracy: 0.7424\n","  Micro F1: 0.7398\n","  Macro F1: 0.7392\n","\n"," 50% 3/6 [03:26<03:25, 68.55s/it]Loss = 0.0\n","Loss = tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.49586868286133\n","#############    Validation Set Stats\n","Total Validation Loss = 11.16911792755127\n","  Accuracy: 0.7325\n","  Micro F1: 0.7295\n","  Macro F1: 0.7268\n","\n"," 67% 4/6 [04:36<02:17, 68.95s/it]Loss = 0.0\n","Loss = tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.06714630126953\n","#############    Validation Set Stats\n","Total Validation Loss = 13.602727890014648\n","  Accuracy: 0.7069\n","  Micro F1: 0.7032\n","  Macro F1: 0.7023\n","\n"," 83% 5/6 [05:46<01:09, 69.31s/it]Loss = 0.0\n","Loss = tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.6646671295166\n","#############    Validation Set Stats\n","Total Validation Loss = 13.471746444702148\n","  Accuracy: 0.7140\n","  Micro F1: 0.7105\n","  Macro F1: 0.7105\n","\n","100% 6/6 [06:56<00:00, 69.43s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6517, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.78345489501953\n","#############    Validation Set Stats\n","Total Validation Loss = 12.697848320007324\n","  Accuracy: 0.7003\n","  Micro F1: 0.6988\n","  Macro F1: 0.6872\n","\n"," 17% 1/6 [01:10<05:51, 70.36s/it]Loss = 0.0\n","Loss = tensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.55791091918945\n","#############    Validation Set Stats\n","Total Validation Loss = 12.480472564697266\n","  Accuracy: 0.7121\n","  Micro F1: 0.7135\n","  Macro F1: 0.7134\n","\n"," 33% 2/6 [02:21<04:42, 70.65s/it]Loss = 0.0\n","Loss = tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.464874267578125\n","#############    Validation Set Stats\n","Total Validation Loss = 12.85472583770752\n","  Accuracy: 0.7060\n","  Micro F1: 0.7047\n","  Macro F1: 0.7041\n","\n"," 50% 3/6 [03:32<03:32, 70.81s/it]Loss = 0.0\n","Loss = tensor(0.3687, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.442264556884766\n","#############    Validation Set Stats\n","Total Validation Loss = 13.743255615234375\n","  Accuracy: 0.7169\n","  Micro F1: 0.7135\n","  Macro F1: 0.7099\n","\n"," 67% 4/6 [04:44<02:21, 70.98s/it]Loss = 0.0\n","Loss = tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.39714813232422\n","#############    Validation Set Stats\n","Loss = tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.45703125\n","#############    Validation Set Stats\n","Total Validation Loss = 16.330509185791016\n","  Accuracy: 0.7159\n","  Micro F1: 0.7149\n","  Macro F1: 0.7149\n","\n","100% 6/6 [07:06<00:00, 71.15s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6745, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.953067779541016\n","#############    Validation Set Stats\n","Total Validation Loss = 12.443193435668945\n","  Accuracy: 0.6941\n","  Micro F1: 0.6974\n","  Macro F1: 0.6873\n","\n"," 17% 1/6 [01:11<05:55, 71.13s/it]Loss = 0.0\n","Loss = tensor(0.5247, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.17050552368164\n","#############    Validation Set Stats\n","Total Validation Loss = 12.108100891113281\n","  Accuracy: 0.7012\n","  Micro F1: 0.7047\n","  Macro F1: 0.7043\n","\n"," 33% 2/6 [02:22<04:44, 71.16s/it]Loss = 0.0\n","Loss = tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.525535583496094\n","#############    Validation Set Stats\n","Total Validation Loss = 12.414168357849121\n","  Accuracy: 0.7041\n","  Micro F1: 0.7076\n","  Macro F1: 0.7076\n","\n"," 50% 3/6 [03:33<03:33, 71.21s/it]Loss = 0.0\n","Loss = tensor(0.4078, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.91325378417969\n","#############    Validation Set Stats\n","Loss = tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.662139892578125\n","#############    Validation Set Stats\n","Total Validation Loss = 15.395668983459473\n","  Accuracy: 0.6832\n","  Micro F1: 0.6886\n","  Macro F1: 0.6886\n","\n"," 83% 5/6 [05:56<01:11, 71.28s/it]Loss = 0.0\n","Loss = tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.14362335205078\n","#############    Validation Set Stats\n","Total Validation Loss = 15.973508834838867\n","  Accuracy: 0.6899\n","  Micro F1: 0.6930\n","  Macro F1: 0.6929\n","\n","100% 6/6 [07:07<00:00, 71.29s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6775, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.133697509765625\n","#############    Validation Set Stats\n","Total Validation Loss = 12.427855491638184\n","  Accuracy: 0.7079\n","  Micro F1: 0.7101\n","  Macro F1: 0.7095\n","\n"," 17% 1/6 [01:11<05:56, 71.25s/it]Loss = 0.0\n","Loss = tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.69642639160156\n","#############    Validation Set Stats\n","Total Validation Loss = 11.489816665649414\n","  Accuracy: 0.7450\n","  Micro F1: 0.7511\n","  Macro F1: 0.7468\n","\n"," 33% 2/6 [02:22<04:45, 71.32s/it]Loss = 0.0\n","Loss = tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.63151931762695\n","#############    Validation Set Stats\n","Loss = tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.2946662902832\n","#############    Validation Set Stats\n","Total Validation Loss = 15.064912796020508\n","  Accuracy: 0.6712\n","  Micro F1: 0.6779\n","  Macro F1: 0.6771\n","\n"," 67% 4/6 [04:45<02:22, 71.41s/it]Loss = 0.0\n","Loss = tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.62848663330078\n","#############    Validation Set Stats\n","Total Validation Loss = 15.720465660095215\n","  Accuracy: 0.6897\n","  Micro F1: 0.6969\n","  Macro F1: 0.6959\n","\n"," 83% 5/6 [05:57<01:11, 71.43s/it]Loss = 0.0\n","Loss = tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.007118225097656\n","#############    Validation Set Stats\n","Total Validation Loss = 17.363460540771484\n","  Accuracy: 0.6841\n","  Micro F1: 0.6940\n","  Macro F1: 0.6936\n","\n","100% 6/6 [07:08<00:00, 71.42s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6642, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.21311569213867\n","#############    Validation Set Stats\n","Total Validation Loss = 12.849982261657715\n","  Accuracy: 0.7034\n","  Micro F1: 0.6999\n","  Macro F1: 0.6981\n","\n"," 17% 1/6 [01:11<05:56, 71.24s/it]Loss = 0.0\n","Loss = tensor(0.4963, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.55853271484375\n","#############    Validation Set Stats\n","Loss = tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.04348373413086\n","#############    Validation Set Stats\n","Total Validation Loss = 13.851580619812012\n","  Accuracy: 0.7136\n","  Micro F1: 0.7160\n","  Macro F1: 0.7148\n","\n"," 50% 3/6 [03:33<03:33, 71.31s/it]Loss = 0.0\n","Loss = tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.839656829833984\n","#############    Validation Set Stats\n","Total Validation Loss = 14.376194953918457\n","  Accuracy: 0.7021\n","  Micro F1: 0.7013\n","  Macro F1: 0.7002\n","\n"," 67% 4/6 [04:45<02:22, 71.31s/it]Loss = 0.0\n","Loss = tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.82890510559082\n","#############    Validation Set Stats\n","Total Validation Loss = 14.704243659973145\n","  Accuracy: 0.7177\n","  Micro F1: 0.7174\n","  Macro F1: 0.7174\n","\n"," 83% 5/6 [05:56<01:11, 71.31s/it]Loss = 0.0\n","Loss = tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.395095825195312\n","#############    Validation Set Stats\n","Total Validation Loss = 17.395416259765625\n","  Accuracy: 0.7049\n","  Micro F1: 0.7042\n","  Macro F1: 0.7039\n","\n","100% 6/6 [07:07<00:00, 71.32s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7254\n","  Micro F1: 0.7270\n","  Macro F1: 0.7260\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DAubQpmQZqWZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596238192395,"user_tz":-330,"elapsed":2159744,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"24eab422-4c7d-4539-f100-5206e5992eea"},"source":["!python bert_han_cross_val.py -f Datasets/Humour/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-3 --num_labels 2 "],"execution_count":11,"outputs":[{"output_type":"stream","text":["2020-07-31 22:53:57.792440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6672, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.76812744140625\n","#############    Validation Set Stats\n","Total Validation Loss = 12.127388000488281\n","  Accuracy: 0.7112\n","  Micro F1: 0.7076\n","  Macro F1: 0.6944\n","\n"," 17% 1/6 [01:11<05:58, 71.68s/it]Loss = 0.0\n","Loss = tensor(0.5320, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.10560989379883\n","#############    Validation Set Stats\n","Total Validation Loss = 11.710667610168457\n","  Accuracy: 0.7363\n","  Micro F1: 0.7310\n","  Macro F1: 0.7294\n","\n"," 33% 2/6 [02:22<04:46, 71.52s/it]Loss = 0.0\n","Loss = tensor(0.4992, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.80266571044922\n","#############    Validation Set Stats\n","Total Validation Loss = 12.12240219116211\n","  Accuracy: 0.7396\n","  Micro F1: 0.7368\n","  Macro F1: 0.7368\n","\n"," 50% 3/6 [03:33<03:34, 71.39s/it]Loss = 0.0\n","Loss = tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.447914123535156\n","#############    Validation Set Stats\n","Total Validation Loss = 11.960848808288574\n","  Accuracy: 0.7514\n","  Micro F1: 0.7515\n","  Macro F1: 0.7512\n","\n"," 67% 4/6 [04:45<02:22, 71.34s/it]Loss = 0.0\n","Loss = tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.534034729003906\n","#############    Validation Set Stats\n","Total Validation Loss = 13.341543197631836\n","  Accuracy: 0.7306\n","  Micro F1: 0.7251\n","  Macro F1: 0.7251\n","\n"," 83% 5/6 [05:56<01:11, 71.29s/it]Loss = 0.0\n","Loss = tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.860441207885742\n","#############    Validation Set Stats\n","Total Validation Loss = 13.277978897094727\n","  Accuracy: 0.7348\n","  Micro F1: 0.7295\n","  Macro F1: 0.7294\n","\n","100% 6/6 [07:07<00:00, 71.26s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6645, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.242637634277344\n","#############    Validation Set Stats\n","Total Validation Loss = 13.907381057739258\n","  Accuracy: 0.6510\n","  Micro F1: 0.6433\n","  Macro F1: 0.6364\n","\n"," 17% 1/6 [01:11<05:56, 71.30s/it]Loss = 0.0\n","Loss = tensor(0.5250, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.01045608520508\n","#############    Validation Set Stats\n","Total Validation Loss = 12.349815368652344\n","  Accuracy: 0.7140\n","  Micro F1: 0.7105\n","  Macro F1: 0.7061\n","\n"," 33% 2/6 [02:22<04:45, 71.26s/it]Loss = 0.0\n","Loss = tensor(0.4619, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.83784866333008\n","#############    Validation Set Stats\n","Total Validation Loss = 12.53787612915039\n","  Accuracy: 0.7244\n","  Micro F1: 0.7237\n","  Macro F1: 0.7154\n","\n"," 50% 3/6 [03:33<03:33, 71.16s/it]Loss = 0.0\n","Loss = tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.57625961303711\n","#############    Validation Set Stats\n","Total Validation Loss = 13.11416244506836\n","  Accuracy: 0.7107\n","  Micro F1: 0.7120\n","  Macro F1: 0.7104\n","\n"," 67% 4/6 [04:44<02:22, 71.15s/it]Loss = 0.0\n","Loss = tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n","Total Validation Loss = 14.576720237731934\n","  Accuracy: 0.7022\n","  Micro F1: 0.7032\n","  Macro F1: 0.7027\n","\n"," 83% 5/6 [05:55<01:11, 71.16s/it]Loss = 0.0\n","Loss = tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.79090690612793\n","#############    Validation Set Stats\n","Total Validation Loss = 15.74881649017334\n","  Accuracy: 0.7126\n","  Micro F1: 0.7164\n","  Macro F1: 0.7164\n","\n","100% 6/6 [07:06<00:00, 71.14s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6807, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.16707229614258\n","#############    Validation Set Stats\n","Total Validation Loss = 13.16029167175293\n","  Accuracy: 0.6979\n","  Micro F1: 0.6988\n","  Macro F1: 0.6988\n","\n"," 17% 1/6 [01:10<05:54, 70.98s/it]Loss = 0.0\n","Loss = tensor(0.5330, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.022544860839844\n","#############    Validation Set Stats\n","Total Validation Loss = 11.945733070373535\n","  Accuracy: 0.7183\n","  Micro F1: 0.7222\n","  Macro F1: 0.7221\n","\n"," 33% 2/6 [02:22<04:44, 71.05s/it]Loss = 0.0\n","Loss = tensor(0.4753, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.851036071777344\n","#############    Validation Set Stats\n","Total Validation Loss = 12.022228240966797\n","  Accuracy: 0.7183\n","  Micro F1: 0.7222\n","  Macro F1: 0.7166\n","\n"," 50% 3/6 [03:33<03:33, 71.09s/it]Loss = 0.0\n","Loss = tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.70269775390625\n","#############    Validation Set Stats\n","Loss = tensor(0.3775, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.703914642333984\n","#############    Validation Set Stats\n","Total Validation Loss = 14.767806053161621\n","  Accuracy: 0.6785\n","  Micro F1: 0.6813\n","  Macro F1: 0.6808\n","\n"," 83% 5/6 [05:55<01:11, 71.13s/it]Loss = 0.0\n","Loss = tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 27.67723846435547\n","#############    Validation Set Stats\n","Total Validation Loss = 14.679373741149902\n","  Accuracy: 0.6998\n","  Micro F1: 0.7032\n","  Macro F1: 0.7022\n","\n","100% 6/6 [07:06<00:00, 71.11s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6502, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.078346252441406\n","#############    Validation Set Stats\n","Total Validation Loss = 12.32812786102295\n","  Accuracy: 0.7191\n","  Micro F1: 0.7189\n","  Macro F1: 0.7168\n","\n"," 17% 1/6 [01:11<05:56, 71.28s/it]Loss = 0.0\n","Loss = tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.07017135620117\n","#############    Validation Set Stats\n","Total Validation Loss = 11.384892463684082\n","  Accuracy: 0.7322\n","  Micro F1: 0.7379\n","  Macro F1: 0.7331\n","\n"," 33% 2/6 [02:22<04:45, 71.27s/it]Loss = 0.0\n","Loss = tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.548553466796875\n","#############    Validation Set Stats\n","Loss = tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.81969451904297\n","#############    Validation Set Stats\n","Total Validation Loss = 12.425250053405762\n","  Accuracy: 0.7266\n","  Micro F1: 0.7350\n","  Macro F1: 0.7336\n","\n"," 67% 4/6 [04:45<02:22, 71.29s/it]Loss = 0.0\n","Loss = tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 26.860265731811523\n","#############    Validation Set Stats\n","Total Validation Loss = 14.477811813354492\n","  Accuracy: 0.7111\n","  Micro F1: 0.7218\n","  Macro F1: 0.7218\n","\n"," 83% 5/6 [05:56<01:11, 71.28s/it]Loss = 0.0\n","Loss = tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 22.922744750976562\n","#############    Validation Set Stats\n","Total Validation Loss = 14.970410346984863\n","  Accuracy: 0.7111\n","  Micro F1: 0.7218\n","  Macro F1: 0.7218\n","\n","100% 6/6 [07:07<00:00, 71.27s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6639, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.64510726928711\n","#############    Validation Set Stats\n","Total Validation Loss = 12.720428466796875\n","  Accuracy: 0.6933\n","  Micro F1: 0.6867\n","  Macro F1: 0.6815\n","\n"," 17% 1/6 [01:10<05:54, 70.99s/it]Loss = 0.0\n","Loss = tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.43467330932617\n","#############    Validation Set Stats\n","Loss = tensor(0.4693, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.899654388427734\n","#############    Validation Set Stats\n","Total Validation Loss = 11.884429931640625\n","  Accuracy: 0.7302\n","  Micro F1: 0.7247\n","  Macro F1: 0.7188\n","\n"," 50% 3/6 [03:33<03:33, 71.07s/it]Loss = 0.0\n","Loss = tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.108802795410156\n","#############    Validation Set Stats\n","Total Validation Loss = 13.57178020477295\n","  Accuracy: 0.7177\n","  Micro F1: 0.7174\n","  Macro F1: 0.7166\n","\n"," 67% 4/6 [04:44<02:22, 71.03s/it]Loss = 0.0\n","Loss = tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.97342300415039\n","#############    Validation Set Stats\n","Total Validation Loss = 15.570008277893066\n","  Accuracy: 0.6978\n","  Micro F1: 0.6969\n","  Macro F1: 0.6968\n","\n"," 83% 5/6 [05:55<01:11, 71.07s/it]Loss = 0.0\n","Loss = tensor(0.2861, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.26910400390625\n","#############    Validation Set Stats\n","Total Validation Loss = 15.833806037902832\n","  Accuracy: 0.6950\n","  Micro F1: 0.6940\n","  Macro F1: 0.6937\n","\n","100% 6/6 [07:06<00:00, 71.10s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7278\n","  Micro F1: 0.7300\n","  Macro F1: 0.7284\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FdWgYv06ceLV","colab_type":"text"},"source":["# Humour 9"]},{"cell_type":"code","metadata":{"id":"Lexg3MuUAMNU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596240223812,"user_tz":-330,"elapsed":2031433,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"14738c9b-5609-4a2e-b046-0a47cbfb1fb4"},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-4 --num_labels 2 "],"execution_count":12,"outputs":[{"output_type":"stream","text":["2020-07-31 23:29:58.165244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6725, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.21240997314453\n","#############    Validation Set Stats\n","Total Validation Loss = 13.834304809570312\n","  Accuracy: 0.6600\n","  Micro F1: 0.6550\n","  Macro F1: 0.6547\n","\n"," 17% 1/6 [01:07<05:36, 67.34s/it]Loss = 0.0\n","Loss = tensor(0.5736, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.55217742919922\n","#############    Validation Set Stats\n","Total Validation Loss = 11.656864166259766\n","  Accuracy: 0.7244\n","  Micro F1: 0.7237\n","  Macro F1: 0.7165\n","\n"," 33% 2/6 [02:14<04:28, 67.17s/it]Loss = 0.0\n","Loss = tensor(0.5052, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.08338928222656\n","#############    Validation Set Stats\n","Total Validation Loss = 11.634552001953125\n","  Accuracy: 0.7382\n","  Micro F1: 0.7354\n","  Macro F1: 0.7343\n","\n"," 50% 3/6 [03:20<03:21, 67.05s/it]Loss = 0.0\n","Loss = tensor(0.4382, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.378753662109375\n","#############    Validation Set Stats\n","Total Validation Loss = 11.382159233093262\n","  Accuracy: 0.7509\n","  Micro F1: 0.7485\n","  Macro F1: 0.7454\n","\n"," 67% 4/6 [04:27<02:14, 67.05s/it]Loss = 0.0\n","\n","Total Train Loss = 32.3868293762207\n","#############    Validation Set Stats\n","Total Validation Loss = 14.544873237609863\n","  Accuracy: 0.7154\n","  Micro F1: 0.7120\n","  Macro F1: 0.7109\n","\n"," 83% 5/6 [05:34<01:06, 66.97s/it]Loss = 0.0\n","Loss = tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.24976348876953\n","#############    Validation Set Stats\n","Total Validation Loss = 13.757195472717285\n","  Accuracy: 0.7353\n","  Micro F1: 0.7325\n","  Macro F1: 0.7322\n","\n","100% 6/6 [06:41<00:00, 66.91s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6583, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.38279342651367\n","#############    Validation Set Stats\n","Total Validation Loss = 12.552661895751953\n","  Accuracy: 0.6984\n","  Micro F1: 0.6944\n","  Macro F1: 0.6775\n","\n"," 17% 1/6 [01:06<05:34, 66.81s/it]Loss = 0.0\n","Loss = tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.9461555480957\n","#############    Validation Set Stats\n","Total Validation Loss = 12.017804145812988\n","  Accuracy: 0.7211\n","  Micro F1: 0.7178\n","  Macro F1: 0.7081\n","\n"," 33% 2/6 [02:13<04:27, 66.83s/it]Loss = 0.0\n","Loss = tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.70566940307617\n","#############    Validation Set Stats\n","Total Validation Loss = 13.235764503479004\n","  Accuracy: 0.7017\n","  Micro F1: 0.7003\n","  Macro F1: 0.6998\n","\n"," 50% 3/6 [03:20<03:20, 66.82s/it]Loss = 0.0\n","Loss = tensor(0.4091, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.73756408691406\n","#############    Validation Set Stats\n","Total Validation Loss = 14.500051498413086\n","  Accuracy: 0.6946\n","  Micro F1: 0.6930\n","  Macro F1: 0.6922\n","\n"," 67% 4/6 [04:27<02:13, 66.81s/it]Loss = 0.0\n","Loss = tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.359275817871094\n","#############    Validation Set Stats\n","Loss = tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.5674991607666\n","#############    Validation Set Stats\n","Total Validation Loss = 15.017193794250488\n","  Accuracy: 0.7069\n","  Micro F1: 0.7032\n","  Macro F1: 0.7029\n","\n","100% 6/6 [06:40<00:00, 66.81s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6675, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.13566207885742\n","#############    Validation Set Stats\n","Total Validation Loss = 13.979752540588379\n","  Accuracy: 0.6425\n","  Micro F1: 0.6491\n","  Macro F1: 0.6488\n","\n"," 17% 1/6 [01:06<05:32, 66.60s/it]Loss = 0.0\n","Loss = tensor(0.5692, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.33298873901367\n","#############    Validation Set Stats\n","Total Validation Loss = 12.658279418945312\n","  Accuracy: 0.6927\n","  Micro F1: 0.6959\n","  Macro F1: 0.6921\n","\n"," 33% 2/6 [02:13<04:26, 66.63s/it]Loss = 0.0\n","Loss = tensor(0.4667, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.31559753417969\n","#############    Validation Set Stats\n","Total Validation Loss = 12.3289155960083\n","  Accuracy: 0.6828\n","  Micro F1: 0.6857\n","  Macro F1: 0.6853\n","\n"," 50% 3/6 [03:20<03:20, 66.71s/it]Loss = 0.0\n","Loss = tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.68547439575195\n","#############    Validation Set Stats\n","Total Validation Loss = 13.678548812866211\n","  Accuracy: 0.6951\n","  Micro F1: 0.6959\n","  Macro F1: 0.6917\n","\n"," 67% 4/6 [04:26<02:13, 66.72s/it]Loss = 0.0\n","Loss = tensor(0.3376, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.119037628173828\n","#############    Validation Set Stats\n","Total Validation Loss = 15.506330490112305\n","  Accuracy: 0.6747\n","  Micro F1: 0.6725\n","  Macro F1: 0.6715\n","\n"," 83% 5/6 [05:33<01:06, 66.76s/it]Loss = 0.0\n","\n","Total Train Loss = 26.27959442138672\n","#############    Validation Set Stats\n","Total Validation Loss = 17.277557373046875\n","  Accuracy: 0.6572\n","  Micro F1: 0.6594\n","  Macro F1: 0.6589\n","\n","100% 6/6 [06:40<00:00, 66.79s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6800, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 59.20562744140625\n","#############    Validation Set Stats\n","Total Validation Loss = 14.115479469299316\n","  Accuracy: 0.6542\n","  Micro F1: 0.6603\n","  Macro F1: 0.6603\n","\n"," 17% 1/6 [01:06<05:33, 66.67s/it]Loss = 0.0\n","Loss = tensor(0.6055, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.129425048828125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.182781219482422\n","  Accuracy: 0.7079\n","  Micro F1: 0.7101\n","  Macro F1: 0.6972\n","\n"," 33% 2/6 [02:13<04:26, 66.69s/it]Loss = 0.0\n","Loss = tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.4703369140625\n","#############    Validation Set Stats\n","Total Validation Loss = 12.031826972961426\n","  Accuracy: 0.7350\n","  Micro F1: 0.7408\n","  Macro F1: 0.7404\n","\n"," 50% 3/6 [03:20<03:20, 66.71s/it]Loss = 0.0\n","Loss = tensor(0.4603, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.77255630493164\n","#############    Validation Set Stats\n","Total Validation Loss = 12.267556190490723\n","  Accuracy: 0.7138\n","  Micro F1: 0.7218\n","  Macro F1: 0.7218\n","\n"," 67% 4/6 [04:27<02:13, 66.75s/it]Loss = 0.0\n","Loss = tensor(0.4391, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.05979919433594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.251108169555664\n","  Accuracy: 0.7251\n","  Micro F1: 0.7306\n","  Macro F1: 0.7286\n","\n"," 83% 5/6 [05:33<01:06, 66.82s/it]Loss = 0.0\n","Loss = tensor(0.3743, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.862037658691406\n","#############    Validation Set Stats\n","Loss = tensor(0.6717, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.00883483886719\n","#############    Validation Set Stats\n","Total Validation Loss = 12.577924728393555\n","  Accuracy: 0.7034\n","  Micro F1: 0.6999\n","  Macro F1: 0.6930\n","\n"," 17% 1/6 [01:06<05:33, 66.76s/it]Loss = 0.0\n","Loss = tensor(0.5341, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.596824645996094\n","#############    Validation Set Stats\n","Total Validation Loss = 12.260992050170898\n","  Accuracy: 0.7175\n","  Micro F1: 0.7116\n","  Macro F1: 0.7080\n","\n"," 33% 2/6 [02:13<04:27, 66.80s/it]Loss = 0.0\n","Loss = tensor(0.4806, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.9786262512207\n","#############    Validation Set Stats\n","Total Validation Loss = 12.61209774017334\n","  Accuracy: 0.7022\n","  Micro F1: 0.7042\n","  Macro F1: 0.7008\n","\n"," 50% 3/6 [03:20<03:20, 66.82s/it]Loss = 0.0\n","Loss = tensor(0.4093, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.07849884033203\n","#############    Validation Set Stats\n","Total Validation Loss = 13.233345031738281\n","  Accuracy: 0.7217\n","  Micro F1: 0.7160\n","  Macro F1: 0.7144\n","\n"," 67% 4/6 [04:27<02:13, 66.83s/it]Loss = 0.0\n","Loss = tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.366483688354492\n","#############    Validation Set Stats\n","Total Validation Loss = 15.367794036865234\n","  Accuracy: 0.7064\n","  Micro F1: 0.7057\n","  Macro F1: 0.7040\n","\n"," 83% 5/6 [05:34<01:06, 66.89s/it]Loss = 0.0\n","Loss = tensor(0.2820, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 24.86997413635254\n","#############    Validation Set Stats\n","Total Validation Loss = 15.010663032531738\n","  Accuracy: 0.7177\n","  Micro F1: 0.7174\n","  Macro F1: 0.7174\n","\n","100% 6/6 [06:41<00:00, 66.90s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.7235\n","  Micro F1: 0.7241\n","  Macro F1: 0.7207\n","===================================================\n","==================F1 SCORES====================\n","0.7453947368421052\n","0.7080872386015111\n","0.6921052631578948\n","0.7404129223435436\n","0.7173625449999893\n","===================================================\n","==================ACC SCORES====================\n","0.7509469696969696\n","0.7211174242424243\n","0.6927083333333334\n","0.7350206611570248\n","0.7177169421487603\n","===================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kQIpJjUdcu5U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f2d9217e-4dc1-4efd-d639-1350ab9b1dfb"},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-01 00:03:49.023346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6798, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 59.37385177612305\n","#############    Validation Set Stats\n","Total Validation Loss = 14.75652027130127\n","  Accuracy: 0.6170\n","  Micro F1: 0.6155\n","  Macro F1: 0.6151\n","\n"," 17% 1/6 [01:07<05:35, 67.08s/it]Loss = 0.0\n","Loss = tensor(0.6304, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.232818603515625\n","#############    Validation Set Stats\n","Total Validation Loss = 11.12852668762207\n","  Accuracy: 0.7424\n","  Micro F1: 0.7398\n","  Macro F1: 0.7358\n","\n"," 33% 2/6 [02:13<04:27, 66.97s/it]Loss = 0.0\n","Loss = tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.7225341796875\n","#############    Validation Set Stats\n","Total Validation Loss = 11.353678703308105\n","  Accuracy: 0.7287\n","  Micro F1: 0.7281\n","  Macro F1: 0.7265\n","\n"," 50% 3/6 [03:20<03:20, 66.90s/it]Loss = 0.0\n","Loss = tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.03534698486328\n","#############    Validation Set Stats\n","Total Validation Loss = 12.030091285705566\n","  Accuracy: 0.7273\n","  Micro F1: 0.7266\n","  Macro F1: 0.7266\n","\n"," 67% 4/6 [04:27<02:13, 66.95s/it]Loss = 0.0\n","Loss = tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.766754150390625\n","#############    Validation Set Stats\n","Total Validation Loss = 13.785805702209473\n","  Accuracy: 0.6932\n","  Micro F1: 0.6915\n","  Macro F1: 0.6885\n","\n"," 83% 5/6 [05:34<01:06, 66.90s/it]Loss = 0.0\n","Loss = tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.118173599243164\n","#############    Validation Set Stats\n","Total Validation Loss = 14.331928253173828\n","  Accuracy: 0.7060\n","  Micro F1: 0.7047\n","  Macro F1: 0.7047\n","\n","100% 6/6 [06:41<00:00, 66.88s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6759, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.57538986206055\n","#############    Validation Set Stats\n","Loss = tensor(0.6555, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.80656051635742\n","#############    Validation Set Stats\n","Total Validation Loss = 15.562822341918945\n","  Accuracy: 0.5331\n","  Micro F1: 0.5292\n","  Macro F1: 0.4312\n","\n"," 33% 2/6 [02:13<04:27, 66.75s/it]Loss = 0.0\n","Loss = tensor(0.5700, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.2562370300293\n","#############    Validation Set Stats\n","Total Validation Loss = 12.107294082641602\n","  Accuracy: 0.7225\n","  Micro F1: 0.7193\n","  Macro F1: 0.7171\n","\n"," 50% 3/6 [03:20<03:20, 66.76s/it]Loss = 0.0\n","Loss = tensor(0.4681, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.725486755371094\n","#############    Validation Set Stats\n","Total Validation Loss = 12.23685359954834\n","  Accuracy: 0.7296\n","  Micro F1: 0.7266\n","  Macro F1: 0.7231\n","\n"," 67% 4/6 [04:27<02:13, 66.78s/it]Loss = 0.0\n","Loss = tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.258522033691406\n","#############    Validation Set Stats\n","Total Validation Loss = 13.51045036315918\n","  Accuracy: 0.7150\n","  Micro F1: 0.7091\n","  Macro F1: 0.7086\n","\n"," 83% 5/6 [05:34<01:06, 66.81s/it]Loss = 0.0\n","Loss = tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.31845474243164\n","#############    Validation Set Stats\n","Total Validation Loss = 14.048912048339844\n","  Accuracy: 0.7140\n","  Micro F1: 0.7105\n","  Macro F1: 0.7105\n","\n","100% 6/6 [06:40<00:00, 66.79s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.80136489868164\n","#############    Validation Set Stats\n","Total Validation Loss = 12.450217247009277\n","  Accuracy: 0.6951\n","  Micro F1: 0.6959\n","  Macro F1: 0.6866\n","\n"," 17% 1/6 [01:06<05:32, 66.43s/it]Loss = 0.0\n","\n","Total Train Loss = 46.053550720214844\n","#############    Validation Set Stats\n","Total Validation Loss = 11.780167579650879\n","  Accuracy: 0.7126\n","  Micro F1: 0.7164\n","  Macro F1: 0.7118\n","\n"," 33% 2/6 [02:13<04:26, 66.51s/it]Loss = 0.0\n","Loss = tensor(0.4553, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.1473274230957\n","#############    Validation Set Stats\n","Total Validation Loss = 12.538527488708496\n","  Accuracy: 0.7027\n","  Micro F1: 0.7061\n","  Macro F1: 0.7060\n","\n"," 50% 3/6 [03:19<03:19, 66.59s/it]Loss = 0.0\n","Loss = tensor(0.3954, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.95750045776367\n","#############    Validation Set Stats\n","Total Validation Loss = 13.643207550048828\n","  Accuracy: 0.7098\n","  Micro F1: 0.7135\n","  Macro F1: 0.7115\n","\n"," 67% 4/6 [04:26<02:13, 66.63s/it]Loss = 0.0\n","Loss = tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.98842430114746\n","#############    Validation Set Stats\n","Total Validation Loss = 14.915224075317383\n","  Accuracy: 0.6894\n","  Micro F1: 0.6974\n","  Macro F1: 0.6963\n","\n"," 83% 5/6 [05:33<01:06, 66.64s/it]Loss = 0.0\n","Loss = tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 23.869123458862305\n","#############    Validation Set Stats\n","Total Validation Loss = 16.938777923583984\n","  Accuracy: 0.6738\n","  Micro F1: 0.6813\n","  Macro F1: 0.6812\n","\n","100% 6/6 [06:40<00:00, 66.68s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6709, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.55050277709961\n","#############    Validation Set Stats\n","Total Validation Loss = 12.739127159118652\n","  Accuracy: 0.7137\n","  Micro F1: 0.7189\n","  Macro F1: 0.7115\n","\n"," 17% 1/6 [01:06<05:34, 66.82s/it]Loss = 0.0\n","Loss = tensor(0.5357, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.8844108581543\n","#############    Validation Set Stats\n","Loss = tensor(0.4786, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.887054443359375\n","#############    Validation Set Stats\n","Total Validation Loss = 12.194961547851562\n","  Accuracy: 0.7278\n","  Micro F1: 0.7306\n","  Macro F1: 0.7304\n","\n"," 50% 3/6 [03:20<03:20, 66.80s/it]Loss = 0.0\n","Loss = tensor(0.4088, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.147804260253906\n","#############    Validation Set Stats\n","Total Validation Loss = 13.03600025177002\n","  Accuracy: 0.7082\n","  Micro F1: 0.7160\n","  Macro F1: 0.7160\n","\n"," 67% 4/6 [04:27<02:13, 66.81s/it]Loss = 0.0\n","Loss = tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.15233039855957\n","#############    Validation Set Stats\n","Total Validation Loss = 13.850431442260742\n","  Accuracy: 0.7137\n","  Micro F1: 0.7189\n","  Macro F1: 0.7145\n","\n"," 83% 5/6 [05:34<01:06, 66.85s/it]Loss = 0.0\n","Loss = tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 25.40732192993164\n","#############    Validation Set Stats\n","Total Validation Loss = 15.399703025817871\n","  Accuracy: 0.6925\n","  Micro F1: 0.6999\n","  Macro F1: 0.6996\n","\n","100% 6/6 [06:40<00:00, 66.83s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6748, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 58.75839614868164\n","#############    Validation Set Stats\n","Total Validation Loss = 14.844951629638672\n","  Accuracy: 0.5885\n","  Micro F1: 0.5842\n","  Macro F1: 0.5156\n","\n"," 17% 1/6 [01:06<05:33, 66.64s/it]Loss = 0.0\n","Loss = tensor(0.6402, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.725128173828125\n","#############    Validation Set Stats\n","Total Validation Loss = 12.317107200622559\n","  Accuracy: 0.7248\n","  Micro F1: 0.7247\n","  Macro F1: 0.7245\n","\n"," 33% 2/6 [02:13<04:26, 66.69s/it]Loss = 0.0\n","\n","Total Train Loss = 44.38477325439453\n","#############    Validation Set Stats\n","Total Validation Loss = 11.434782028198242\n","  Accuracy: 0.7346\n","  Micro F1: 0.7321\n","  Macro F1: 0.7277\n","\n"," 50% 3/6 [03:20<03:20, 66.71s/it]Loss = 0.0\n","Loss = tensor(0.4861, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.27975082397461\n","#############    Validation Set Stats\n","Total Validation Loss = 12.618888854980469\n","  Accuracy: 0.7361\n","  Micro F1: 0.7335\n","  Macro F1: 0.7334\n","\n"," 67% 4/6 [04:26<02:13, 66.73s/it]Loss = 0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iO9Cq_i2cvMf","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11qTApsRcvYK","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2S7OjjUncvic","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Ckf5-pkcvp6","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H-o2YlTScxBO","colab_type":"text"},"source":["# Humour No"]},{"cell_type":"code","metadata":{"id":"MXUKwUxhk5Qt","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame.pkl --feature_dim 0 --hidden_size 200 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDJ701VNc9nd","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame.pkl --feature_dim 0 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sduGmXMc9yH","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame.pkl --feature_dim 0 --hidden_size 50 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UOCKnraFc97C","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame.pkl --feature_dim 0 --hidden_size 200 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdmlNdG6c-HE","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame.pkl --feature_dim 0 --hidden_size 100 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vVypBoBUc-QW","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Humour/data_frame.pkl --feature_dim 0 --hidden_size 50 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lgEwNWtFc-xH","colab_type":"text"},"source":["# Hate 22"]},{"cell_type":"code","metadata":{"id":"qTi0A69WANgF","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rCI7_IqYdBRa","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RgLmf25fdBaz","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nqwBLXX4dBhw","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PS5HY8nndBpU","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJoQeIwsdBvq","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j4jElPNgdD0c","colab_type":"text"},"source":["# Hate 9"]},{"cell_type":"code","metadata":{"id":"lMo0wptBAN8e","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9eHQh_pwdHzT","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WKXV8s8wdH7x","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F9Azvzb8dIC_","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNAOQs5gdIJ7","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8FGt4xvgdIU8","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jnEykUrWdIwl","colab_type":"text"},"source":["# Hate No"]},{"cell_type":"code","metadata":{"id":"7vcBHxK4AOKE","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame.pkl --feature_dim 0 --hidden_size 200 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Psm2eILMdKyg","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame.pkl --feature_dim 0 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HkaH2C2dK4x","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame.pkl --feature_dim 0 --hidden_size 50 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6O_f-3o5dK_W","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame.pkl --feature_dim 0 --hidden_size 200 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cCJn8YK-dLHf","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame.pkl --feature_dim 0 --hidden_size 100 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4vI4y2UdLRa","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Hate/data_frame.pkl --feature_dim 0 --hidden_size 50 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2vt8QESpdMe3","colab_type":"text"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"58KmNZClkGpj","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Sarcasm/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t4b96mUmkHsN","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Sarcasm/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cMJ4fgwLkKRo","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Sarcasm/data_frame.pkl --feature_dim 0 --hidden_size 0 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLFlUykokYBV","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Sentiment/data_frame_22.pkl --feature_dim 22 --hidden_size 0 --learning_rate 1e-3 --num_labels 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NNA9DJJqks64","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Sentiment/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-4 --num_labels 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fji72UEuktXH","colab_type":"code","colab":{}},"source":["!python bert_cross_val.py -f Datasets/Sentiment/data_frame.pkl --feature_dim 0 --hidden_size 0 --learning_rate 1e-3 --num_labels 3"],"execution_count":null,"outputs":[]}]}
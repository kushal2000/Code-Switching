{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Run_CV.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"fllY-TxkjyZq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596445570077,"user_tz":-330,"elapsed":24301,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"286365f8-a3a0-47ff-9a48-708af33fbf0c"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount = True)\n","import os\n","root_path = 'gdrive/My Drive/Code_Switch/'\n","os.chdir(root_path)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n0ZObXBPk8-F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1596445580313,"user_tz":-330,"elapsed":18051,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"1b04ee04-99a1-404c-a17c-d9fce9474ccc"},"source":["!pip install transformers"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 7.1MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 37.3MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 41.3MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 35.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b26589406283b20ed58a6bb6b41247b9ff806565580575eaaa78cda61d3fb51e\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F-i_0T3dJaxc","colab_type":"text"},"source":["## SARCASM 22"]},{"cell_type":"code","metadata":{"id":"YVQT6s1wj9I_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596222159120,"user_tz":-330,"elapsed":844739,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"16be1fd6-3b45-4f66-fc0d-6a87d62691f5"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-4 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 18:48:36.997626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 20.303829193115234\n","#############    Validation Set Stats\n","Total Validation Loss = 4.295444011688232\n","  Accuracy: 0.7646\n","  Micro F1: 0.7709\n","  Macro F1: 0.7360\n","\n"," 17% 1/6 [00:24<02:04, 24.93s/it]Loss = 0.0\n","\n","Total Train Loss = 14.816313743591309\n","#############    Validation Set Stats\n","Total Validation Loss = 3.813413381576538\n","  Accuracy: 0.8459\n","  Micro F1: 0.8436\n","  Macro F1: 0.8358\n","\n"," 33% 2/6 [00:50<01:40, 25.12s/it]Loss = 0.0\n","\n","Total Train Loss = 13.787817001342773\n","#############    Validation Set Stats\n","Total Validation Loss = 3.765519857406616\n","  Accuracy: 0.8470\n","  Micro F1: 0.8473\n","  Macro F1: 0.8364\n","\n"," 50% 3/6 [01:16<01:16, 25.46s/it]Loss = 0.0\n","\n","Total Train Loss = 13.006905555725098\n","#############    Validation Set Stats\n","Total Validation Loss = 3.608063220977783\n","  Accuracy: 0.8459\n","  Micro F1: 0.8436\n","  Macro F1: 0.8364\n","\n"," 67% 4/6 [01:42<00:51, 25.66s/it]Loss = 0.0\n","\n","Total Train Loss = 12.119806289672852\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5384087562561035\n","  Accuracy: 0.8494\n","  Micro F1: 0.8473\n","  Macro F1: 0.8409\n","\n"," 83% 5/6 [02:09<00:25, 25.94s/it]Loss = 0.0\n","\n","Total Train Loss = 11.9032621383667\n","#############    Validation Set Stats\n","Total Validation Loss = 3.538914918899536\n","  Accuracy: 0.8494\n","  Micro F1: 0.8473\n","  Macro F1: 0.8404\n","\n","100% 6/6 [02:36<00:00, 26.04s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 21.01597023010254\n","#############    Validation Set Stats\n","Total Validation Loss = 4.231658935546875\n","  Accuracy: 0.7869\n","  Micro F1: 0.7818\n","  Macro F1: 0.7429\n","\n"," 17% 1/6 [00:26<02:14, 26.94s/it]Loss = 0.0\n","\n","Total Train Loss = 15.35892105102539\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7286314964294434\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8605\n","\n"," 33% 2/6 [00:54<01:48, 27.00s/it]Loss = 0.0\n","\n","Total Train Loss = 13.81030559539795\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5975914001464844\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8550\n","\n"," 50% 3/6 [01:21<01:21, 27.10s/it]Loss = 0.0\n","\n","Total Train Loss = 13.101997375488281\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3656158447265625\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8668\n","\n"," 67% 4/6 [01:48<00:54, 27.22s/it]Loss = 0.0\n","\n","Total Train Loss = 12.689152717590332\n","#############    Validation Set Stats\n","Total Validation Loss = 3.315274715423584\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8753\n","\n"," 83% 5/6 [02:16<00:27, 27.31s/it]Loss = 0.0\n","\n","Total Train Loss = 12.375319480895996\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3042397499084473\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8731\n","\n","100% 6/6 [02:44<00:00, 27.33s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 21.920242309570312\n","#############    Validation Set Stats\n","Total Validation Loss = 4.71085262298584\n","  Accuracy: 0.6524\n","  Micro F1: 0.6509\n","  Macro F1: 0.3943\n","\n"," 17% 1/6 [00:27<02:18, 27.70s/it]Loss = 0.0\n","\n","Total Train Loss = 16.137943267822266\n","#############    Validation Set Stats\n","Total Validation Loss = 3.6846022605895996\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8659\n","\n"," 33% 2/6 [00:55<01:50, 27.72s/it]Loss = 0.0\n","\n","Total Train Loss = 14.206299781799316\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7134764194488525\n","  Accuracy: 0.8679\n","  Micro F1: 0.8691\n","  Macro F1: 0.8567\n","\n"," 50% 3/6 [01:23<01:23, 27.84s/it]Loss = 0.0\n","\n","Total Train Loss = 13.605538368225098\n","#############    Validation Set Stats\n","Total Validation Loss = 3.560805082321167\n","  Accuracy: 0.8783\n","  Micro F1: 0.8800\n","  Macro F1: 0.8701\n","\n"," 67% 4/6 [01:52<00:56, 28.06s/it]Loss = 0.0\n","\n","Total Train Loss = 12.964058876037598\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5361087322235107\n","  Accuracy: 0.8748\n","  Micro F1: 0.8764\n","  Macro F1: 0.8664\n","\n"," 83% 5/6 [02:20<00:28, 28.10s/it]Loss = 0.0\n","\n","Total Train Loss = 12.740516662597656\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5528576374053955\n","  Accuracy: 0.8655\n","  Micro F1: 0.8691\n","  Macro F1: 0.8586\n","\n","100% 6/6 [02:48<00:00, 28.09s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 19.730409622192383\n","#############    Validation Set Stats\n","Total Validation Loss = 4.210118293762207\n","  Accuracy: 0.7590\n","  Micro F1: 0.7600\n","  Macro F1: 0.7000\n","\n"," 17% 1/6 [00:28<02:21, 28.29s/it]Loss = 0.0\n","\n","Total Train Loss = 14.884743690490723\n","#############    Validation Set Stats\n","Total Validation Loss = 3.6798548698425293\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8567\n","\n"," 33% 2/6 [00:56<01:53, 28.29s/it]Loss = 0.0\n","\n","Total Train Loss = 13.95226764678955\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7307114601135254\n","  Accuracy: 0.8529\n","  Micro F1: 0.8509\n","  Macro F1: 0.8406\n","\n"," 50% 3/6 [01:25<01:24, 28.33s/it]Loss = 0.0\n","\n","Total Train Loss = 12.860054016113281\n","#############    Validation Set Stats\n","Total Validation Loss = 3.458986759185791\n","  Accuracy: 0.8679\n","  Micro F1: 0.8691\n","  Macro F1: 0.8592\n","\n"," 67% 4/6 [01:53<00:56, 28.36s/it]Loss = 0.0\n","\n","Total Train Loss = 12.446329116821289\n","#############    Validation Set Stats\n","Total Validation Loss = 3.251619577407837\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8768\n","\n"," 83% 5/6 [02:21<00:28, 28.36s/it]Loss = 0.0\n","\n","Total Train Loss = 11.75379753112793\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2881109714508057\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8722\n","\n","100% 6/6 [02:50<00:00, 28.35s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 21.275442123413086\n","#############    Validation Set Stats\n","Total Validation Loss = 4.1825852394104\n","  Accuracy: 0.7971\n","  Micro F1: 0.8000\n","  Macro F1: 0.7651\n","\n"," 17% 1/6 [00:28<02:21, 28.29s/it]Loss = 0.0\n","\n","Total Train Loss = 15.166093826293945\n","#############    Validation Set Stats\n","Total Validation Loss = 3.801708936691284\n","  Accuracy: 0.8355\n","  Micro F1: 0.8327\n","  Macro F1: 0.8132\n","\n"," 33% 2/6 [00:56<01:53, 28.29s/it]Loss = 0.0\n","\n","Total Train Loss = 13.529451370239258\n","#############    Validation Set Stats\n","Total Validation Loss = 3.408168315887451\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8451\n","\n"," 50% 3/6 [01:24<01:24, 28.30s/it]Loss = 0.0\n","\n","Total Train Loss = 12.66604995727539\n","#############    Validation Set Stats\n","Total Validation Loss = 2.967233180999756\n","  Accuracy: 0.9039\n","  Micro F1: 0.9018\n","  Macro F1: 0.8972\n","\n"," 67% 4/6 [01:53<00:56, 28.30s/it]Loss = 0.0\n","\n","Total Train Loss = 12.138510704040527\n","#############    Validation Set Stats\n","Total Validation Loss = 2.887744665145874\n","  Accuracy: 0.9039\n","  Micro F1: 0.9018\n","  Macro F1: 0.8976\n","\n"," 83% 5/6 [02:21<00:28, 28.29s/it]Loss = 0.0\n","\n","Total Train Loss = 11.649313926696777\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1984784603118896\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8717\n","\n","100% 6/6 [02:49<00:00, 28.28s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8800\n","  Micro F1: 0.8793\n","  Macro F1: 0.8721\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r6GIr9rIJHDX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596223027025,"user_tz":-330,"elapsed":1653503,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"79aaf608-1670-47a5-ba55-0ad7d82be524"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 19:02:40.839206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 19.912019729614258\n","#############    Validation Set Stats\n","Total Validation Loss = 3.9742841720581055\n","  Accuracy: 0.8425\n","  Micro F1: 0.8400\n","  Macro F1: 0.8333\n","\n"," 17% 1/6 [00:27<02:17, 27.45s/it]Loss = 0.0\n","\n","Total Train Loss = 13.383003234863281\n","#############    Validation Set Stats\n","Total Validation Loss = 3.6188242435455322\n","  Accuracy: 0.8459\n","  Micro F1: 0.8436\n","  Macro F1: 0.8369\n","\n"," 33% 2/6 [00:55<01:50, 27.52s/it]Loss = 0.0\n","\n","Total Train Loss = 12.007590293884277\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5690865516662598\n","  Accuracy: 0.8425\n","  Micro F1: 0.8400\n","  Macro F1: 0.8323\n","\n"," 50% 3/6 [01:23<01:23, 27.80s/it]Loss = 0.0\n","\n","Total Train Loss = 10.789369583129883\n","#############    Validation Set Stats\n","Total Validation Loss = 3.378702402114868\n","  Accuracy: 0.8540\n","  Micro F1: 0.8545\n","  Macro F1: 0.8442\n","\n"," 67% 4/6 [01:52<00:56, 28.12s/it]Loss = 0.0\n","\n","Total Train Loss = 10.326577186584473\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3909835815429688\n","  Accuracy: 0.8540\n","  Micro F1: 0.8545\n","  Macro F1: 0.8475\n","\n"," 83% 5/6 [02:20<00:28, 28.17s/it]Loss = 0.0\n","\n","Total Train Loss = 9.759912490844727\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3236043453216553\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8516\n","\n","100% 6/6 [02:49<00:00, 28.20s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.85822868347168\n","#############    Validation Set Stats\n","Total Validation Loss = 4.07906436920166\n","  Accuracy: 0.8377\n","  Micro F1: 0.8400\n","  Macro F1: 0.8317\n","\n"," 17% 1/6 [00:28<02:22, 28.57s/it]Loss = 0.0\n","\n","Total Train Loss = 14.872674942016602\n","#############    Validation Set Stats\n","Total Validation Loss = 3.715238332748413\n","  Accuracy: 0.8332\n","  Micro F1: 0.8327\n","  Macro F1: 0.8285\n","\n"," 33% 2/6 [00:56<01:54, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 13.22939682006836\n","#############    Validation Set Stats\n","Total Validation Loss = 3.422147750854492\n","  Accuracy: 0.8436\n","  Micro F1: 0.8436\n","  Macro F1: 0.8387\n","\n"," 50% 3/6 [01:25<01:25, 28.48s/it]Loss = 0.0\n","\n","Total Train Loss = 12.16989517211914\n","#############    Validation Set Stats\n","Total Validation Loss = 3.08152174949646\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8744\n","\n"," 67% 4/6 [01:53<00:56, 28.50s/it]Loss = 0.0\n","\n","Total Train Loss = 11.894349098205566\n","#############    Validation Set Stats\n","Total Validation Loss = 3.111406087875366\n","  Accuracy: 0.8876\n","  Micro F1: 0.8873\n","  Macro F1: 0.8785\n","\n"," 83% 5/6 [02:22<00:28, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 11.409903526306152\n","#############    Validation Set Stats\n","Total Validation Loss = 3.01346755027771\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8708\n","\n","100% 6/6 [02:50<00:00, 28.48s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.720735549926758\n","#############    Validation Set Stats\n","Total Validation Loss = 3.975306987762451\n","  Accuracy: 0.8366\n","  Micro F1: 0.8364\n","  Macro F1: 0.8177\n","\n"," 17% 1/6 [00:28<02:22, 28.42s/it]Loss = 0.0\n","\n","Total Train Loss = 14.27840518951416\n","#############    Validation Set Stats\n","Total Validation Loss = 3.8891444206237793\n","  Accuracy: 0.8423\n","  Micro F1: 0.8473\n","  Macro F1: 0.8235\n","\n"," 33% 2/6 [00:56<01:53, 28.44s/it]Loss = 0.0\n","\n","Total Train Loss = 12.718188285827637\n","#############    Validation Set Stats\n","Total Validation Loss = 3.446516990661621\n","  Accuracy: 0.8516\n","  Micro F1: 0.8545\n","  Macro F1: 0.8448\n","\n"," 50% 3/6 [01:25<01:25, 28.48s/it]Loss = 0.0\n","\n","Total Train Loss = 12.058405876159668\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4909815788269043\n","  Accuracy: 0.8551\n","  Micro F1: 0.8582\n","  Macro F1: 0.8484\n","\n"," 67% 4/6 [01:53<00:56, 28.49s/it]Loss = 0.0\n","\n","Total Train Loss = 11.264669418334961\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5628957748413086\n","  Accuracy: 0.8644\n","  Micro F1: 0.8655\n","  Macro F1: 0.8516\n","\n"," 83% 5/6 [02:22<00:28, 28.48s/it]Loss = 0.0\n","\n","Total Train Loss = 11.187750816345215\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4835567474365234\n","  Accuracy: 0.8586\n","  Micro F1: 0.8618\n","  Macro F1: 0.8519\n","\n","100% 6/6 [02:50<00:00, 28.50s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.703842163085938\n","#############    Validation Set Stats\n","Total Validation Loss = 4.006166934967041\n","  Accuracy: 0.8505\n","  Micro F1: 0.8509\n","  Macro F1: 0.8449\n","\n"," 17% 1/6 [00:28<02:22, 28.51s/it]Loss = 0.0\n","\n","Total Train Loss = 14.002596855163574\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3682241439819336\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8708\n","\n"," 33% 2/6 [00:56<01:53, 28.48s/it]Loss = 0.0\n","\n","Total Train Loss = 12.507633209228516\n","#############    Validation Set Stats\n","Total Validation Loss = 3.223629951477051\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8672\n","\n"," 50% 3/6 [01:25<01:25, 28.48s/it]Loss = 0.0\n","\n","Total Train Loss = 12.185431480407715\n","#############    Validation Set Stats\n","Total Validation Loss = 3.235806941986084\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8556\n","\n"," 67% 4/6 [01:53<00:56, 28.48s/it]Loss = 0.0\n","\n","Total Train Loss = 11.083614349365234\n","#############    Validation Set Stats\n","Total Validation Loss = 3.021696090698242\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8717\n","\n"," 83% 5/6 [02:22<00:28, 28.50s/it]Loss = 0.0\n","\n","Total Train Loss = 10.493607521057129\n","#############    Validation Set Stats\n","Total Validation Loss = 3.205838918685913\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8580\n","\n","100% 6/6 [02:50<00:00, 28.49s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 19.970928192138672\n","#############    Validation Set Stats\n","Total Validation Loss = 3.550323486328125\n","  Accuracy: 0.8783\n","  Micro F1: 0.8800\n","  Macro F1: 0.8759\n","\n"," 17% 1/6 [00:28<02:22, 28.45s/it]Loss = 0.0\n","\n","Total Train Loss = 13.685529708862305\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1849894523620605\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8670\n","\n"," 33% 2/6 [00:56<01:53, 28.46s/it]Loss = 0.0\n","\n","Total Train Loss = 12.476109504699707\n","#############    Validation Set Stats\n","Total Validation Loss = 2.701974630355835\n","  Accuracy: 0.9073\n","  Micro F1: 0.9055\n","  Macro F1: 0.9009\n","\n"," 50% 3/6 [01:25<01:25, 28.47s/it]Loss = 0.0\n","\n","Total Train Loss = 11.365702629089355\n","#############    Validation Set Stats\n","Total Validation Loss = 2.716043472290039\n","  Accuracy: 0.8911\n","  Micro F1: 0.8909\n","  Macro F1: 0.8849\n","\n"," 67% 4/6 [01:53<00:56, 28.45s/it]Loss = 0.0\n","\n","Total Train Loss = 10.698238372802734\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6446449756622314\n","  Accuracy: 0.9050\n","  Micro F1: 0.9055\n","  Macro F1: 0.9009\n","\n"," 83% 5/6 [02:22<00:28, 28.46s/it]Loss = 0.0\n","\n","Total Train Loss = 10.069293975830078\n","#############    Validation Set Stats\n","Total Validation Loss = 2.649653434753418\n","  Accuracy: 0.9015\n","  Micro F1: 0.9018\n","  Macro F1: 0.8969\n","\n","100% 6/6 [02:50<00:00, 28.48s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8788\n","  Micro F1: 0.8785\n","  Macro F1: 0.8709\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8u9RYHGiJG4p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596223906047,"user_tz":-330,"elapsed":2532124,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"e661ef42-f22d-4b5e-9ec7-b4b9291499dc"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 19:17:08.777779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 21.661773681640625\n","#############    Validation Set Stats\n","Total Validation Loss = 4.532019138336182\n","  Accuracy: 0.7473\n","  Micro F1: 0.7527\n","  Macro F1: 0.6934\n","\n"," 17% 1/6 [00:28<02:24, 28.92s/it]Loss = 0.0\n","\n","Total Train Loss = 14.47394847869873\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7197458744049072\n","  Accuracy: 0.8286\n","  Micro F1: 0.8255\n","  Macro F1: 0.8202\n","\n"," 33% 2/6 [00:58<01:56, 29.09s/it]Loss = 0.0\n","\n","Total Train Loss = 12.32607364654541\n","#############    Validation Set Stats\n","Total Validation Loss = 3.6861281394958496\n","  Accuracy: 0.8251\n","  Micro F1: 0.8218\n","  Macro F1: 0.8167\n","\n"," 50% 3/6 [01:26<01:26, 28.84s/it]Loss = 0.0\n","\n","Total Train Loss = 11.652177810668945\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4315273761749268\n","  Accuracy: 0.8494\n","  Micro F1: 0.8473\n","  Macro F1: 0.8409\n","\n"," 67% 4/6 [01:55<00:57, 28.81s/it]Loss = 0.0\n","\n","Total Train Loss = 11.061298370361328\n","#############    Validation Set Stats\n","Total Validation Loss = 3.374004602432251\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8470\n","\n"," 83% 5/6 [02:24<00:28, 28.85s/it]Loss = 0.0\n","\n","Total Train Loss = 10.630035400390625\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3920347690582275\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8475\n","\n","100% 6/6 [02:52<00:00, 28.82s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.19235610961914\n","#############    Validation Set Stats\n","Total Validation Loss = 3.744251251220703\n","  Accuracy: 0.8470\n","  Micro F1: 0.8473\n","  Macro F1: 0.8427\n","\n"," 17% 1/6 [00:28<02:23, 28.75s/it]Loss = 0.0\n","\n","Total Train Loss = 13.468188285827637\n","#############    Validation Set Stats\n","Total Validation Loss = 3.201735734939575\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8676\n","\n"," 33% 2/6 [00:57<01:55, 28.79s/it]Loss = 0.0\n","\n","Total Train Loss = 12.489411354064941\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1570348739624023\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8601\n","\n"," 50% 3/6 [01:26<01:26, 28.75s/it]Loss = 0.0\n","\n","Total Train Loss = 12.018073081970215\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9317822456359863\n","  Accuracy: 0.8876\n","  Micro F1: 0.8873\n","  Macro F1: 0.8816\n","\n"," 67% 4/6 [01:54<00:57, 28.73s/it]Loss = 0.0\n","\n","Total Train Loss = 11.175898551940918\n","#############    Validation Set Stats\n","Total Validation Loss = 3.0445480346679688\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8748\n","\n"," 83% 5/6 [02:23<00:28, 28.70s/it]Loss = 0.0\n","\n","Total Train Loss = 10.778114318847656\n","#############    Validation Set Stats\n","Total Validation Loss = 3.083772659301758\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8681\n","\n","100% 6/6 [02:52<00:00, 28.72s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 19.707366943359375\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5235188007354736\n","  Accuracy: 0.8540\n","  Micro F1: 0.8545\n","  Macro F1: 0.8392\n","\n"," 17% 1/6 [00:28<02:24, 28.84s/it]Loss = 0.0\n","\n","Total Train Loss = 13.04975414276123\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4797182083129883\n","  Accuracy: 0.8540\n","  Micro F1: 0.8545\n","  Macro F1: 0.8448\n","\n"," 33% 2/6 [00:57<01:55, 28.85s/it]Loss = 0.0\n","\n","Total Train Loss = 11.491463661193848\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5383455753326416\n","  Accuracy: 0.8540\n","  Micro F1: 0.8545\n","  Macro F1: 0.8422\n","\n"," 50% 3/6 [01:26<01:26, 28.82s/it]Loss = 0.0\n","\n","Total Train Loss = 10.838138580322266\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3767223358154297\n","  Accuracy: 0.8575\n","  Micro F1: 0.8582\n","  Macro F1: 0.8477\n","\n"," 67% 4/6 [01:55<00:57, 28.78s/it]Loss = 0.0\n","\n","Total Train Loss = 10.005511283874512\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3626346588134766\n","  Accuracy: 0.8575\n","  Micro F1: 0.8582\n","  Macro F1: 0.8471\n","\n"," 83% 5/6 [02:23<00:28, 28.74s/it]Loss = 0.0\n","\n","Total Train Loss = 9.658036231994629\n","#############    Validation Set Stats\n","Total Validation Loss = 3.447817802429199\n","  Accuracy: 0.8609\n","  Micro F1: 0.8618\n","  Macro F1: 0.8507\n","\n","100% 6/6 [02:52<00:00, 28.76s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 18.950496673583984\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5635263919830322\n","  Accuracy: 0.8529\n","  Micro F1: 0.8509\n","  Macro F1: 0.8435\n","\n"," 17% 1/6 [00:28<02:24, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 13.090038299560547\n","#############    Validation Set Stats\n","Total Validation Loss = 3.174771547317505\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8618\n","\n"," 33% 2/6 [00:57<01:55, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 11.932695388793945\n","#############    Validation Set Stats\n","Total Validation Loss = 3.145911931991577\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8601\n","\n"," 50% 3/6 [01:26<01:26, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 11.148838996887207\n","#############    Validation Set Stats\n","Total Validation Loss = 3.122562885284424\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8547\n","\n"," 67% 4/6 [01:55<00:57, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 10.626428604125977\n","#############    Validation Set Stats\n","Total Validation Loss = 3.0303289890289307\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8731\n","\n"," 83% 5/6 [02:23<00:28, 28.79s/it]Loss = 0.0\n","\n","Total Train Loss = 10.175358772277832\n","#############    Validation Set Stats\n","Total Validation Loss = 3.139923095703125\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8525\n","\n","100% 6/6 [02:52<00:00, 28.78s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 22.82175636291504\n","#############    Validation Set Stats\n","Total Validation Loss = 5.4445953369140625\n","  Accuracy: 0.6524\n","  Micro F1: 0.6509\n","  Macro F1: 0.3943\n","\n"," 17% 1/6 [00:28<02:23, 28.61s/it]Loss = 0.0\n","\n","Total Train Loss = 16.12005043029785\n","#############    Validation Set Stats\n","Total Validation Loss = 3.21842622756958\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8513\n","\n"," 33% 2/6 [00:57<01:54, 28.65s/it]Loss = 0.0\n","\n","Total Train Loss = 12.61785888671875\n","#############    Validation Set Stats\n","Total Validation Loss = 3.910057544708252\n","  Accuracy: 0.8204\n","  Micro F1: 0.8218\n","  Macro F1: 0.8004\n","\n"," 50% 3/6 [01:26<01:26, 28.68s/it]Loss = 0.0\n","\n","Total Train Loss = 12.576397895812988\n","#############    Validation Set Stats\n","Total Validation Loss = 3.0750350952148438\n","  Accuracy: 0.8865\n","  Micro F1: 0.8836\n","  Macro F1: 0.8748\n","\n"," 67% 4/6 [01:54<00:57, 28.70s/it]Loss = 0.0\n","\n","Total Train Loss = 11.90080451965332\n","#############    Validation Set Stats\n","Total Validation Loss = 2.7227818965911865\n","  Accuracy: 0.9039\n","  Micro F1: 0.9018\n","  Macro F1: 0.8972\n","\n"," 83% 5/6 [02:23<00:28, 28.73s/it]Loss = 0.0\n","\n","Total Train Loss = 11.21789836883545\n","#############    Validation Set Stats\n","Total Validation Loss = 2.705552577972412\n","  Accuracy: 0.9073\n","  Micro F1: 0.9055\n","  Macro F1: 0.9012\n","\n","100% 6/6 [02:52<00:00, 28.72s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8786\n","  Micro F1: 0.8778\n","  Macro F1: 0.8708\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U0blPJjcJDHZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596224772205,"user_tz":-330,"elapsed":3397860,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"77ab105a-a5a3-406a-8e64-322dfc63369e"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 19:31:48.748809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 20.303829193115234\n","#############    Validation Set Stats\n","Total Validation Loss = 4.295444011688232\n","  Accuracy: 0.7646\n","  Micro F1: 0.7709\n","  Macro F1: 0.7360\n","\n"," 17% 1/6 [00:28<02:21, 28.37s/it]Loss = 0.0\n","\n","Total Train Loss = 14.816313743591309\n","#############    Validation Set Stats\n","Total Validation Loss = 3.813413381576538\n","  Accuracy: 0.8459\n","  Micro F1: 0.8436\n","  Macro F1: 0.8358\n","\n"," 33% 2/6 [00:57<01:54, 28.56s/it]Loss = 0.0\n","\n","Total Train Loss = 13.787817001342773\n","#############    Validation Set Stats\n","Total Validation Loss = 3.765519857406616\n","  Accuracy: 0.8470\n","  Micro F1: 0.8473\n","  Macro F1: 0.8364\n","\n"," 50% 3/6 [01:25<01:25, 28.38s/it]Loss = 0.0\n","\n","Total Train Loss = 13.006905555725098\n","#############    Validation Set Stats\n","Total Validation Loss = 3.608063220977783\n","  Accuracy: 0.8459\n","  Micro F1: 0.8436\n","  Macro F1: 0.8364\n","\n"," 67% 4/6 [01:53<00:56, 28.35s/it]Loss = 0.0\n","\n","Total Train Loss = 12.119806289672852\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5384087562561035\n","  Accuracy: 0.8494\n","  Micro F1: 0.8473\n","  Macro F1: 0.8409\n","\n"," 83% 5/6 [02:22<00:28, 28.41s/it]Loss = 0.0\n","\n","Total Train Loss = 11.9032621383667\n","#############    Validation Set Stats\n","Total Validation Loss = 3.538914918899536\n","  Accuracy: 0.8494\n","  Micro F1: 0.8473\n","  Macro F1: 0.8404\n","\n","100% 6/6 [02:50<00:00, 28.38s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 21.01597023010254\n","#############    Validation Set Stats\n","Total Validation Loss = 4.231658935546875\n","  Accuracy: 0.7869\n","  Micro F1: 0.7818\n","  Macro F1: 0.7429\n","\n"," 17% 1/6 [00:28<02:21, 28.23s/it]Loss = 0.0\n","\n","Total Train Loss = 15.35892105102539\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7286314964294434\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8605\n","\n"," 33% 2/6 [00:56<01:53, 28.30s/it]Loss = 0.0\n","\n","Total Train Loss = 13.81030559539795\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5975914001464844\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8550\n","\n"," 50% 3/6 [01:24<01:24, 28.29s/it]Loss = 0.0\n","\n","Total Train Loss = 13.101997375488281\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3656158447265625\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8668\n","\n"," 67% 4/6 [01:53<00:56, 28.26s/it]Loss = 0.0\n","\n","Total Train Loss = 12.689152717590332\n","#############    Validation Set Stats\n","Total Validation Loss = 3.315274715423584\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8753\n","\n"," 83% 5/6 [02:21<00:28, 28.23s/it]Loss = 0.0\n","\n","Total Train Loss = 12.375319480895996\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3042397499084473\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8731\n","\n","100% 6/6 [02:49<00:00, 28.25s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 21.920242309570312\n","#############    Validation Set Stats\n","Total Validation Loss = 4.71085262298584\n","  Accuracy: 0.6524\n","  Micro F1: 0.6509\n","  Macro F1: 0.3943\n","\n"," 17% 1/6 [00:28<02:21, 28.38s/it]Loss = 0.0\n","\n","Total Train Loss = 16.137943267822266\n","#############    Validation Set Stats\n","Total Validation Loss = 3.6846022605895996\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8659\n","\n"," 33% 2/6 [00:56<01:53, 28.39s/it]Loss = 0.0\n","\n","Total Train Loss = 14.206299781799316\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7134764194488525\n","  Accuracy: 0.8679\n","  Micro F1: 0.8691\n","  Macro F1: 0.8567\n","\n"," 50% 3/6 [01:25<01:25, 28.35s/it]Loss = 0.0\n","\n","Total Train Loss = 13.605538368225098\n","#############    Validation Set Stats\n","Total Validation Loss = 3.560805082321167\n","  Accuracy: 0.8783\n","  Micro F1: 0.8800\n","  Macro F1: 0.8701\n","\n"," 67% 4/6 [01:53<00:56, 28.30s/it]Loss = 0.0\n","\n","Total Train Loss = 12.964058876037598\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5361087322235107\n","  Accuracy: 0.8748\n","  Micro F1: 0.8764\n","  Macro F1: 0.8664\n","\n"," 83% 5/6 [02:21<00:28, 28.28s/it]Loss = 0.0\n","\n","Total Train Loss = 12.740516662597656\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5528576374053955\n","  Accuracy: 0.8655\n","  Micro F1: 0.8691\n","  Macro F1: 0.8586\n","\n","100% 6/6 [02:49<00:00, 28.31s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 19.730409622192383\n","#############    Validation Set Stats\n","Total Validation Loss = 4.210118293762207\n","  Accuracy: 0.7590\n","  Micro F1: 0.7600\n","  Macro F1: 0.7000\n","\n"," 17% 1/6 [00:28<02:21, 28.24s/it]Loss = 0.0\n","\n","Total Train Loss = 14.884743690490723\n","#############    Validation Set Stats\n","Total Validation Loss = 3.6798548698425293\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8567\n","\n"," 33% 2/6 [00:56<01:52, 28.24s/it]Loss = 0.0\n","\n","Total Train Loss = 13.95226764678955\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7307114601135254\n","  Accuracy: 0.8529\n","  Micro F1: 0.8509\n","  Macro F1: 0.8406\n","\n"," 50% 3/6 [01:24<01:24, 28.27s/it]Loss = 0.0\n","\n","Total Train Loss = 12.860054016113281\n","#############    Validation Set Stats\n","Total Validation Loss = 3.458986759185791\n","  Accuracy: 0.8679\n","  Micro F1: 0.8691\n","  Macro F1: 0.8592\n","\n"," 67% 4/6 [01:53<00:56, 28.31s/it]Loss = 0.0\n","\n","Total Train Loss = 12.446329116821289\n","#############    Validation Set Stats\n","Total Validation Loss = 3.251619577407837\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8768\n","\n"," 83% 5/6 [02:21<00:28, 28.33s/it]Loss = 0.0\n","\n","Total Train Loss = 11.75379753112793\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2881109714508057\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8722\n","\n","100% 6/6 [02:49<00:00, 28.31s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 21.275442123413086\n","#############    Validation Set Stats\n","Total Validation Loss = 4.1825852394104\n","  Accuracy: 0.7971\n","  Micro F1: 0.8000\n","  Macro F1: 0.7651\n","\n"," 17% 1/6 [00:28<02:21, 28.27s/it]Loss = 0.0\n","\n","Total Train Loss = 15.166093826293945\n","#############    Validation Set Stats\n","Total Validation Loss = 3.801708936691284\n","  Accuracy: 0.8355\n","  Micro F1: 0.8327\n","  Macro F1: 0.8132\n","\n"," 33% 2/6 [00:56<01:53, 28.28s/it]Loss = 0.0\n","\n","Total Train Loss = 13.529451370239258\n","#############    Validation Set Stats\n","Total Validation Loss = 3.408168315887451\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8451\n","\n"," 50% 3/6 [01:24<01:24, 28.32s/it]Loss = 0.0\n","\n","Total Train Loss = 12.66604995727539\n","#############    Validation Set Stats\n","Total Validation Loss = 2.967233180999756\n","  Accuracy: 0.9039\n","  Micro F1: 0.9018\n","  Macro F1: 0.8972\n","\n"," 67% 4/6 [01:53<00:56, 28.33s/it]Loss = 0.0\n","\n","Total Train Loss = 12.138510704040527\n","#############    Validation Set Stats\n","Total Validation Loss = 2.887744665145874\n","  Accuracy: 0.9039\n","  Micro F1: 0.9018\n","  Macro F1: 0.8976\n","\n"," 83% 5/6 [02:21<00:28, 28.34s/it]Loss = 0.0\n","\n","Total Train Loss = 11.649313926696777\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1984784603118896\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8717\n","\n","100% 6/6 [02:49<00:00, 28.33s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8800\n","  Micro F1: 0.8793\n","  Macro F1: 0.8721\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"47o4WtA-JMqE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596225641070,"user_tz":-330,"elapsed":4266302,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"7af61e87-0ea4-4d82-b03d-c3909c9a92b0"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 19:46:13.912292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 19.912019729614258\n","#############    Validation Set Stats\n","Total Validation Loss = 3.9742841720581055\n","  Accuracy: 0.8425\n","  Micro F1: 0.8400\n","  Macro F1: 0.8333\n","\n"," 17% 1/6 [00:28<02:23, 28.61s/it]Loss = 0.0\n","\n","Total Train Loss = 13.383003234863281\n","#############    Validation Set Stats\n","Total Validation Loss = 3.6188242435455322\n","  Accuracy: 0.8459\n","  Micro F1: 0.8436\n","  Macro F1: 0.8369\n","\n"," 33% 2/6 [00:57<01:55, 28.79s/it]Loss = 0.0\n","\n","Total Train Loss = 12.007590293884277\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5690865516662598\n","  Accuracy: 0.8425\n","  Micro F1: 0.8400\n","  Macro F1: 0.8323\n","\n"," 50% 3/6 [01:25<01:25, 28.55s/it]Loss = 0.0\n","\n","Total Train Loss = 10.789369583129883\n","#############    Validation Set Stats\n","Total Validation Loss = 3.378702402114868\n","  Accuracy: 0.8540\n","  Micro F1: 0.8545\n","  Macro F1: 0.8442\n","\n"," 67% 4/6 [01:54<00:57, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 10.326577186584473\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3909835815429688\n","  Accuracy: 0.8540\n","  Micro F1: 0.8545\n","  Macro F1: 0.8475\n","\n"," 83% 5/6 [02:23<00:28, 28.60s/it]Loss = 0.0\n","\n","Total Train Loss = 9.759912490844727\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3236043453216553\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8516\n","\n","100% 6/6 [02:51<00:00, 28.56s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.85822868347168\n","#############    Validation Set Stats\n","Total Validation Loss = 4.07906436920166\n","  Accuracy: 0.8377\n","  Micro F1: 0.8400\n","  Macro F1: 0.8317\n","\n"," 17% 1/6 [00:28<02:21, 28.31s/it]Loss = 0.0\n","\n","Total Train Loss = 14.872674942016602\n","#############    Validation Set Stats\n","Total Validation Loss = 3.715238332748413\n","  Accuracy: 0.8332\n","  Micro F1: 0.8327\n","  Macro F1: 0.8285\n","\n"," 33% 2/6 [00:56<01:53, 28.35s/it]Loss = 0.0\n","\n","Total Train Loss = 13.22939682006836\n","#############    Validation Set Stats\n","Total Validation Loss = 3.422147750854492\n","  Accuracy: 0.8436\n","  Micro F1: 0.8436\n","  Macro F1: 0.8387\n","\n"," 50% 3/6 [01:25<01:25, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 12.16989517211914\n","#############    Validation Set Stats\n","Total Validation Loss = 3.08152174949646\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8744\n","\n"," 67% 4/6 [01:53<00:56, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 11.894349098205566\n","#############    Validation Set Stats\n","Total Validation Loss = 3.111406087875366\n","  Accuracy: 0.8876\n","  Micro F1: 0.8873\n","  Macro F1: 0.8785\n","\n"," 83% 5/6 [02:22<00:28, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 11.409903526306152\n","#############    Validation Set Stats\n","Total Validation Loss = 3.01346755027771\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8708\n","\n","100% 6/6 [02:50<00:00, 28.41s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.720735549926758\n","#############    Validation Set Stats\n","Total Validation Loss = 3.975306987762451\n","  Accuracy: 0.8366\n","  Micro F1: 0.8364\n","  Macro F1: 0.8177\n","\n"," 17% 1/6 [00:28<02:21, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 14.27840518951416\n","#############    Validation Set Stats\n","Total Validation Loss = 3.8891444206237793\n","  Accuracy: 0.8423\n","  Micro F1: 0.8473\n","  Macro F1: 0.8235\n","\n"," 33% 2/6 [00:56<01:53, 28.42s/it]Loss = 0.0\n","\n","Total Train Loss = 12.718188285827637\n","#############    Validation Set Stats\n","Total Validation Loss = 3.446516990661621\n","  Accuracy: 0.8516\n","  Micro F1: 0.8545\n","  Macro F1: 0.8448\n","\n"," 50% 3/6 [01:25<01:25, 28.43s/it]Loss = 0.0\n","\n","Total Train Loss = 12.058405876159668\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4909815788269043\n","  Accuracy: 0.8551\n","  Micro F1: 0.8582\n","  Macro F1: 0.8484\n","\n"," 67% 4/6 [01:53<00:56, 28.42s/it]Loss = 0.0\n","\n","Total Train Loss = 11.264669418334961\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5628957748413086\n","  Accuracy: 0.8644\n","  Micro F1: 0.8655\n","  Macro F1: 0.8516\n","\n"," 83% 5/6 [02:22<00:28, 28.42s/it]Loss = 0.0\n","\n","Total Train Loss = 11.187750816345215\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4835567474365234\n","  Accuracy: 0.8586\n","  Micro F1: 0.8618\n","  Macro F1: 0.8519\n","\n","100% 6/6 [02:50<00:00, 28.43s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.703842163085938\n","#############    Validation Set Stats\n","Total Validation Loss = 4.006166934967041\n","  Accuracy: 0.8505\n","  Micro F1: 0.8509\n","  Macro F1: 0.8449\n","\n"," 17% 1/6 [00:28<02:22, 28.43s/it]Loss = 0.0\n","\n","Total Train Loss = 14.002596855163574\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3682241439819336\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8708\n","\n"," 33% 2/6 [00:56<01:53, 28.41s/it]Loss = 0.0\n","\n","Total Train Loss = 12.507633209228516\n","#############    Validation Set Stats\n","Total Validation Loss = 3.223629951477051\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8672\n","\n"," 50% 3/6 [01:25<01:25, 28.42s/it]Loss = 0.0\n","\n","Total Train Loss = 12.185431480407715\n","#############    Validation Set Stats\n","Total Validation Loss = 3.235806941986084\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8556\n","\n"," 67% 4/6 [01:53<00:56, 28.42s/it]Loss = 0.0\n","\n","Total Train Loss = 11.083614349365234\n","#############    Validation Set Stats\n","Total Validation Loss = 3.021696090698242\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8717\n","\n"," 83% 5/6 [02:22<00:28, 28.43s/it]Loss = 0.0\n","\n","Total Train Loss = 10.493607521057129\n","#############    Validation Set Stats\n","Total Validation Loss = 3.205838918685913\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8580\n","\n","100% 6/6 [02:50<00:00, 28.43s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 19.970928192138672\n","#############    Validation Set Stats\n","Total Validation Loss = 3.550323486328125\n","  Accuracy: 0.8783\n","  Micro F1: 0.8800\n","  Macro F1: 0.8759\n","\n"," 17% 1/6 [00:28<02:22, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 13.685529708862305\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1849894523620605\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8670\n","\n"," 33% 2/6 [00:56<01:53, 28.42s/it]Loss = 0.0\n","\n","Total Train Loss = 12.476109504699707\n","#############    Validation Set Stats\n","Total Validation Loss = 2.701974630355835\n","  Accuracy: 0.9073\n","  Micro F1: 0.9055\n","  Macro F1: 0.9009\n","\n"," 50% 3/6 [01:25<01:25, 28.45s/it]Loss = 0.0\n","\n","Total Train Loss = 11.365702629089355\n","#############    Validation Set Stats\n","Total Validation Loss = 2.716043472290039\n","  Accuracy: 0.8911\n","  Micro F1: 0.8909\n","  Macro F1: 0.8849\n","\n"," 67% 4/6 [01:53<00:56, 28.45s/it]Loss = 0.0\n","\n","Total Train Loss = 10.698238372802734\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6446449756622314\n","  Accuracy: 0.9050\n","  Micro F1: 0.9055\n","  Macro F1: 0.9009\n","\n"," 83% 5/6 [02:22<00:28, 28.46s/it]Loss = 0.0\n","\n","Total Train Loss = 10.069293975830078\n","#############    Validation Set Stats\n","Total Validation Loss = 2.649653434753418\n","  Accuracy: 0.9015\n","  Micro F1: 0.9018\n","  Macro F1: 0.8969\n","\n","100% 6/6 [02:50<00:00, 28.47s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8788\n","  Micro F1: 0.8785\n","  Macro F1: 0.8709\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f-mKmADiJM1C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596226519711,"user_tz":-330,"elapsed":5144567,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"2d0d404f-8dc1-416e-8799-8628c6c7b504"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 20:00:43.109796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 19.078081130981445\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5947203636169434\n","  Accuracy: 0.8216\n","  Micro F1: 0.8182\n","  Macro F1: 0.8132\n","\n"," 17% 1/6 [00:28<02:24, 28.89s/it]Loss = 0.0\n","\n","Total Train Loss = 11.714570999145508\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3664121627807617\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8480\n","\n"," 33% 2/6 [00:58<01:56, 29.05s/it]Loss = 0.0\n","\n","Total Train Loss = 10.16114616394043\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5209202766418457\n","  Accuracy: 0.8494\n","  Micro F1: 0.8473\n","  Macro F1: 0.8409\n","\n"," 50% 3/6 [01:26<01:26, 28.82s/it]Loss = 0.0\n","\n","Total Train Loss = 9.848302841186523\n","#############    Validation Set Stats\n","Total Validation Loss = 3.417557954788208\n","  Accuracy: 0.8494\n","  Micro F1: 0.8473\n","  Macro F1: 0.8399\n","\n"," 67% 4/6 [01:55<00:57, 28.78s/it]Loss = 0.0\n","\n","Total Train Loss = 8.784936904907227\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2881791591644287\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8531\n","\n"," 83% 5/6 [02:24<00:28, 28.84s/it]Loss = 0.0\n","\n","Total Train Loss = 8.313872337341309\n","#############    Validation Set Stats\n","Total Validation Loss = 3.385601282119751\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8547\n","\n","100% 6/6 [02:52<00:00, 28.82s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 19.35471534729004\n","#############    Validation Set Stats\n","Total Validation Loss = 3.239070415496826\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8582\n","\n"," 17% 1/6 [00:28<02:23, 28.68s/it]Loss = 0.0\n","\n","Total Train Loss = 11.681906700134277\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8902132511138916\n","  Accuracy: 0.8796\n","  Micro F1: 0.8764\n","  Macro F1: 0.8670\n","\n"," 33% 2/6 [00:57<01:54, 28.72s/it]Loss = 0.0\n","\n","Total Train Loss = 9.920493125915527\n","#############    Validation Set Stats\n","Total Validation Loss = 3.384981155395508\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8545\n","\n"," 50% 3/6 [01:26<01:26, 28.74s/it]Loss = 0.0\n","\n","Total Train Loss = 9.09666633605957\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1866872310638428\n","  Accuracy: 0.8796\n","  Micro F1: 0.8764\n","  Macro F1: 0.8652\n","\n"," 67% 4/6 [01:55<00:57, 28.75s/it]Loss = 0.0\n","\n","Total Train Loss = 8.041708946228027\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3108644485473633\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8457\n","\n"," 83% 5/6 [02:23<00:28, 28.73s/it]Loss = 0.0\n","\n","Total Train Loss = 8.399660110473633\n","#############    Validation Set Stats\n","Total Validation Loss = 2.956576347351074\n","  Accuracy: 0.8830\n","  Micro F1: 0.8800\n","  Macro F1: 0.8717\n","\n","100% 6/6 [02:52<00:00, 28.74s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 19.737802505493164\n","#############    Validation Set Stats\n","Total Validation Loss = 3.0263590812683105\n","  Accuracy: 0.8759\n","  Micro F1: 0.8800\n","  Macro F1: 0.8706\n","\n"," 17% 1/6 [00:28<02:23, 28.67s/it]Loss = 0.0\n","\n","Total Train Loss = 11.332145690917969\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2076544761657715\n","  Accuracy: 0.8551\n","  Micro F1: 0.8582\n","  Macro F1: 0.8458\n","\n"," 33% 2/6 [00:57<01:54, 28.67s/it]Loss = 0.0\n","\n","Total Train Loss = 10.443572998046875\n","#############    Validation Set Stats\n","Total Validation Loss = 3.225893020629883\n","  Accuracy: 0.8690\n","  Micro F1: 0.8727\n","  Macro F1: 0.8628\n","\n"," 50% 3/6 [01:26<01:26, 28.67s/it]Loss = 0.0\n","\n","Total Train Loss = 9.291914939880371\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5405287742614746\n","  Accuracy: 0.8783\n","  Micro F1: 0.8800\n","  Macro F1: 0.8677\n","\n"," 67% 4/6 [01:54<00:57, 28.66s/it]Loss = 0.0\n","\n","Total Train Loss = 8.744743347167969\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5670154094696045\n","  Accuracy: 0.8679\n","  Micro F1: 0.8691\n","  Macro F1: 0.8553\n","\n"," 83% 5/6 [02:23<00:28, 28.67s/it]Loss = 0.0\n","\n","Total Train Loss = 8.58786392211914\n","#############    Validation Set Stats\n","Total Validation Loss = 3.483663558959961\n","  Accuracy: 0.8655\n","  Micro F1: 0.8691\n","  Macro F1: 0.8580\n","\n","100% 6/6 [02:51<00:00, 28.67s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 17.615249633789062\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2286391258239746\n","  Accuracy: 0.8575\n","  Micro F1: 0.8582\n","  Macro F1: 0.8525\n","\n"," 17% 1/6 [00:28<02:23, 28.70s/it]Loss = 0.0\n","\n","Total Train Loss = 12.31558609008789\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9705209732055664\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8572\n","\n"," 33% 2/6 [00:57<01:54, 28.71s/it]Loss = 0.0\n","\n","Total Train Loss = 10.821163177490234\n","#############    Validation Set Stats\n","Total Validation Loss = 3.298753023147583\n","  Accuracy: 0.8529\n","  Micro F1: 0.8509\n","  Macro F1: 0.8449\n","\n"," 50% 3/6 [01:26<01:26, 28.70s/it]Loss = 0.0\n","\n","Total Train Loss = 10.441545486450195\n","#############    Validation Set Stats\n","Total Validation Loss = 2.980332374572754\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8561\n","\n"," 67% 4/6 [01:54<00:57, 28.71s/it]Loss = 0.0\n","\n","Total Train Loss = 9.727874755859375\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8365118503570557\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8636\n","\n"," 83% 5/6 [02:23<00:28, 28.73s/it]Loss = 0.0\n","\n","Total Train Loss = 9.03143310546875\n","#############    Validation Set Stats\n","Total Validation Loss = 2.863476514816284\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8681\n","\n","100% 6/6 [02:52<00:00, 28.74s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 18.4222469329834\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6126344203948975\n","  Accuracy: 0.8876\n","  Micro F1: 0.8873\n","  Macro F1: 0.8828\n","\n"," 17% 1/6 [00:28<02:23, 28.78s/it]Loss = 0.0\n","\n","Total Train Loss = 11.905460357666016\n","#############    Validation Set Stats\n","Total Validation Loss = 2.4036333560943604\n","  Accuracy: 0.9004\n","  Micro F1: 0.8982\n","  Macro F1: 0.8929\n","\n"," 33% 2/6 [00:57<01:55, 28.82s/it]Loss = 0.0\n","\n","Total Train Loss = 10.716535568237305\n","#############    Validation Set Stats\n","Total Validation Loss = 2.644460439682007\n","  Accuracy: 0.8657\n","  Micro F1: 0.8618\n","  Macro F1: 0.8501\n","\n"," 50% 3/6 [01:26<01:26, 28.81s/it]Loss = 0.0\n","\n","Total Train Loss = 9.614067077636719\n","#############    Validation Set Stats\n","Total Validation Loss = 2.486542224884033\n","  Accuracy: 0.8980\n","  Micro F1: 0.8982\n","  Macro F1: 0.8939\n","\n"," 67% 4/6 [01:55<00:57, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 8.7244291305542\n","#############    Validation Set Stats\n","Total Validation Loss = 2.532649040222168\n","  Accuracy: 0.8980\n","  Micro F1: 0.8982\n","  Macro F1: 0.8936\n","\n"," 83% 5/6 [02:24<00:28, 28.79s/it]Loss = 0.0\n","\n","Total Train Loss = 8.110099792480469\n","#############    Validation Set Stats\n","Total Validation Loss = 2.648137331008911\n","  Accuracy: 0.8876\n","  Micro F1: 0.8873\n","  Macro F1: 0.8808\n","\n","100% 6/6 [02:52<00:00, 28.79s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8795\n","  Micro F1: 0.8793\n","  Macro F1: 0.8718\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CpCuOyewJaDz","colab_type":"text"},"source":["## SARCASM 9"]},{"cell_type":"code","metadata":{"id":"Lexg3MuUAMNU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596227386956,"user_tz":-330,"elapsed":6007478,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"e2c55ed0-c50c-41a5-d142-cc1a8734e0ec"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 20:15:21.874898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 18.502077102661133\n","#############    Validation Set Stats\n","Total Validation Loss = 3.437851667404175\n","  Accuracy: 0.8425\n","  Micro F1: 0.8400\n","  Macro F1: 0.8343\n","\n"," 17% 1/6 [00:28<02:22, 28.45s/it]Loss = 0.0\n","\n","Total Train Loss = 11.006739616394043\n","#############    Validation Set Stats\n","Total Validation Loss = 3.673125743865967\n","  Accuracy: 0.8216\n","  Micro F1: 0.8182\n","  Macro F1: 0.8127\n","\n"," 33% 2/6 [00:57<01:54, 28.62s/it]Loss = 0.0\n","\n","Total Train Loss = 9.929386138916016\n","#############    Validation Set Stats\n","Total Validation Loss = 3.242872476577759\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8561\n","\n"," 50% 3/6 [01:25<01:25, 28.44s/it]Loss = 0.0\n","\n","Total Train Loss = 8.906576156616211\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2194039821624756\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8511\n","\n"," 67% 4/6 [01:53<00:56, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 8.116094589233398\n","#############    Validation Set Stats\n","Total Validation Loss = 3.439842939376831\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8484\n","\n"," 83% 5/6 [02:22<00:28, 28.39s/it]Loss = 0.0\n","\n","Total Train Loss = 7.210669994354248\n","#############    Validation Set Stats\n","Total Validation Loss = 3.455974578857422\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8489\n","\n","100% 6/6 [02:50<00:00, 28.43s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 18.27443504333496\n","#############    Validation Set Stats\n","Total Validation Loss = 3.329777717590332\n","  Accuracy: 0.8366\n","  Micro F1: 0.8364\n","  Macro F1: 0.8317\n","\n"," 17% 1/6 [00:28<02:22, 28.47s/it]Loss = 0.0\n","\n","Total Train Loss = 11.083032608032227\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6227316856384277\n","  Accuracy: 0.8852\n","  Micro F1: 0.8873\n","  Macro F1: 0.8790\n","\n"," 33% 2/6 [00:56<01:53, 28.47s/it]Loss = 0.0\n","\n","Total Train Loss = 10.372940063476562\n","#############    Validation Set Stats\n","Total Validation Loss = 2.721947193145752\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8758\n","\n"," 50% 3/6 [01:25<01:25, 28.45s/it]Loss = 0.0\n","\n","Total Train Loss = 9.07850456237793\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8349485397338867\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8639\n","\n"," 67% 4/6 [01:53<00:56, 28.46s/it]Loss = 0.0\n","\n","Total Train Loss = 7.9363017082214355\n","#############    Validation Set Stats\n","Total Validation Loss = 3.187697172164917\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8487\n","\n"," 83% 5/6 [02:22<00:28, 28.43s/it]Loss = 0.0\n","\n","Total Train Loss = 7.5115227699279785\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9611358642578125\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8639\n","\n","100% 6/6 [02:50<00:00, 28.42s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 18.083066940307617\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9577865600585938\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8681\n","\n"," 17% 1/6 [00:28<02:21, 28.39s/it]Loss = 0.0\n","\n","Total Train Loss = 10.998738288879395\n","#############    Validation Set Stats\n","Total Validation Loss = 2.834597110748291\n","  Accuracy: 0.8852\n","  Micro F1: 0.8873\n","  Macro F1: 0.8785\n","\n"," 33% 2/6 [00:56<01:53, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 10.025826454162598\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2422943115234375\n","  Accuracy: 0.8516\n","  Micro F1: 0.8545\n","  Macro F1: 0.8407\n","\n"," 50% 3/6 [01:25<01:25, 28.39s/it]Loss = 0.0\n","\n","Total Train Loss = 9.043807029724121\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2411272525787354\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8720\n","\n"," 67% 4/6 [01:53<00:56, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 8.22640323638916\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2763102054595947\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8560\n","\n"," 83% 5/6 [02:21<00:28, 28.38s/it]Loss = 0.0\n","\n","Total Train Loss = 7.642149448394775\n","#############    Validation Set Stats\n","Total Validation Loss = 3.472486972808838\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8553\n","\n","100% 6/6 [02:50<00:00, 28.37s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 17.586700439453125\n","#############    Validation Set Stats\n","Total Validation Loss = 3.181138515472412\n","  Accuracy: 0.8505\n","  Micro F1: 0.8509\n","  Macro F1: 0.8458\n","\n"," 17% 1/6 [00:28<02:21, 28.29s/it]Loss = 0.0\n","\n","Total Train Loss = 11.488263130187988\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8422060012817383\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8628\n","\n"," 33% 2/6 [00:56<01:53, 28.30s/it]Loss = 0.0\n","\n","Total Train Loss = 10.63123607635498\n","#############    Validation Set Stats\n","Total Validation Loss = 2.847332715988159\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8664\n","\n"," 50% 3/6 [01:25<01:24, 28.33s/it]Loss = 0.0\n","\n","Total Train Loss = 9.584266662597656\n","#############    Validation Set Stats\n","Total Validation Loss = 2.7590315341949463\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8740\n","\n"," 67% 4/6 [01:53<00:56, 28.35s/it]Loss = 0.0\n","\n","Total Train Loss = 9.231642723083496\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8842694759368896\n","  Accuracy: 0.8726\n","  Micro F1: 0.8691\n","  Macro F1: 0.8580\n","\n"," 83% 5/6 [02:21<00:28, 28.34s/it]Loss = 0.0\n","\n","Total Train Loss = 8.589256286621094\n","#############    Validation Set Stats\n","Total Validation Loss = 2.7482924461364746\n","  Accuracy: 0.8830\n","  Micro F1: 0.8800\n","  Macro F1: 0.8722\n","\n","100% 6/6 [02:50<00:00, 28.33s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.26251983642578\n","#############    Validation Set Stats\n","Total Validation Loss = 3.377877950668335\n","  Accuracy: 0.8679\n","  Micro F1: 0.8691\n","  Macro F1: 0.8644\n","\n"," 17% 1/6 [00:28<02:21, 28.35s/it]Loss = 0.0\n","\n","Total Train Loss = 12.895676612854004\n","#############    Validation Set Stats\n","Total Validation Loss = 2.7659599781036377\n","  Accuracy: 0.8748\n","  Micro F1: 0.8764\n","  Macro F1: 0.8723\n","\n"," 33% 2/6 [00:56<01:53, 28.36s/it]Loss = 0.0\n","\n","Total Train Loss = 11.603611946105957\n","#############    Validation Set Stats\n","Total Validation Loss = 2.5675816535949707\n","  Accuracy: 0.8911\n","  Micro F1: 0.8909\n","  Macro F1: 0.8867\n","\n"," 50% 3/6 [01:25<01:25, 28.35s/it]Loss = 0.0\n","\n","Total Train Loss = 11.338549613952637\n","#############    Validation Set Stats\n","Total Validation Loss = 2.612504243850708\n","  Accuracy: 0.8852\n","  Micro F1: 0.8873\n","  Macro F1: 0.8831\n","\n"," 67% 4/6 [01:53<00:56, 28.33s/it]Loss = 0.0\n","\n","Total Train Loss = 10.44556713104248\n","#############    Validation Set Stats\n","Total Validation Loss = 2.492810010910034\n","  Accuracy: 0.8980\n","  Micro F1: 0.8982\n","  Macro F1: 0.8939\n","\n"," 83% 5/6 [02:21<00:28, 28.33s/it]Loss = 0.0\n","\n","Total Train Loss = 10.061443328857422\n","#############    Validation Set Stats\n","Total Validation Loss = 2.451385498046875\n","  Accuracy: 0.8935\n","  Micro F1: 0.8909\n","  Macro F1: 0.8849\n","\n","100% 6/6 [02:50<00:00, 28.34s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8832\n","  Micro F1: 0.8836\n","  Macro F1: 0.8763\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iQtZJ0AmJWBC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596228257348,"user_tz":-330,"elapsed":6877628,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"3d8008e6-03c3-4452-cd7d-6e5b1bb6ac33"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-4 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 20:29:48.728686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 18.871234893798828\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4857592582702637\n","  Accuracy: 0.8332\n","  Micro F1: 0.8327\n","  Macro F1: 0.8252\n","\n"," 17% 1/6 [00:28<02:23, 28.71s/it]Loss = 0.0\n","\n","Total Train Loss = 10.806347846984863\n","#############    Validation Set Stats\n","Total Validation Loss = 3.350984573364258\n","  Accuracy: 0.8529\n","  Micro F1: 0.8509\n","  Macro F1: 0.8449\n","\n"," 33% 2/6 [00:57<01:55, 28.86s/it]Loss = 0.0\n","\n","Total Train Loss = 9.71997356414795\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1640830039978027\n","  Accuracy: 0.8644\n","  Micro F1: 0.8655\n","  Macro F1: 0.8556\n","\n"," 50% 3/6 [01:25<01:25, 28.60s/it]Loss = 0.0\n","\n","Total Train Loss = 8.561989784240723\n","#############    Validation Set Stats\n","Total Validation Loss = 3.157729387283325\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8587\n","\n"," 67% 4/6 [01:54<00:57, 28.57s/it]Loss = 0.0\n","\n","Total Train Loss = 7.556265354156494\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1256375312805176\n","  Accuracy: 0.8713\n","  Micro F1: 0.8727\n","  Macro F1: 0.8649\n","\n"," 83% 5/6 [02:23<00:28, 28.64s/it]Loss = 0.0\n","\n","Total Train Loss = 7.336317539215088\n","#############    Validation Set Stats\n","Total Validation Loss = 3.176811695098877\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8654\n","\n","100% 6/6 [02:51<00:00, 28.61s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 18.45658302307129\n","#############    Validation Set Stats\n","Total Validation Loss = 3.59073543548584\n","  Accuracy: 0.8436\n","  Micro F1: 0.8436\n","  Macro F1: 0.8391\n","\n"," 17% 1/6 [00:28<02:22, 28.41s/it]Loss = 0.0\n","\n","Total Train Loss = 11.793654441833496\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9622206687927246\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8708\n","\n"," 33% 2/6 [00:56<01:53, 28.45s/it]Loss = 0.0\n","\n","Total Train Loss = 10.83062744140625\n","#############    Validation Set Stats\n","Total Validation Loss = 2.812530517578125\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8780\n","\n"," 50% 3/6 [01:25<01:25, 28.48s/it]Loss = 0.0\n","\n","Total Train Loss = 9.298851013183594\n","#############    Validation Set Stats\n","Total Validation Loss = 2.691371440887451\n","  Accuracy: 0.8946\n","  Micro F1: 0.8945\n","  Macro F1: 0.8877\n","\n"," 67% 4/6 [01:54<00:56, 28.49s/it]Loss = 0.0\n","\n","Total Train Loss = 7.857472896575928\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8865931034088135\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8748\n","\n"," 83% 5/6 [02:22<00:28, 28.48s/it]Loss = 0.0\n","\n","Total Train Loss = 7.5516486167907715\n","#############    Validation Set Stats\n","Total Validation Loss = 3.0563817024230957\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8732\n","\n","100% 6/6 [02:50<00:00, 28.48s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 17.69554328918457\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1219332218170166\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8480\n","\n"," 17% 1/6 [00:28<02:22, 28.44s/it]Loss = 0.0\n","\n","Total Train Loss = 11.00184440612793\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3989076614379883\n","  Accuracy: 0.8551\n","  Micro F1: 0.8582\n","  Macro F1: 0.8428\n","\n"," 33% 2/6 [00:56<01:53, 28.44s/it]Loss = 0.0\n","\n","Total Train Loss = 9.541863441467285\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2934622764587402\n","  Accuracy: 0.8481\n","  Micro F1: 0.8509\n","  Macro F1: 0.8379\n","\n"," 50% 3/6 [01:25<01:25, 28.46s/it]Loss = 0.0\n","\n","Total Train Loss = 8.573262214660645\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4590232372283936\n","  Accuracy: 0.8551\n","  Micro F1: 0.8582\n","  Macro F1: 0.8436\n","\n"," 67% 4/6 [01:53<00:56, 28.47s/it]Loss = 0.0\n","\n","Total Train Loss = 8.09151554107666\n","#############    Validation Set Stats\n","Total Validation Loss = 3.563203811645508\n","  Accuracy: 0.8620\n","  Micro F1: 0.8655\n","  Macro F1: 0.8556\n","\n"," 83% 5/6 [02:22<00:28, 28.49s/it]Loss = 0.0\n","\n","Total Train Loss = 6.8842878341674805\n","#############    Validation Set Stats\n","Total Validation Loss = 3.8080427646636963\n","  Accuracy: 0.8481\n","  Micro F1: 0.8509\n","  Macro F1: 0.8347\n","\n","100% 6/6 [02:50<00:00, 28.49s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 17.498802185058594\n","#############    Validation Set Stats\n","Total Validation Loss = 2.954364538192749\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8429\n","\n"," 17% 1/6 [00:28<02:22, 28.56s/it]Loss = 0.0\n","\n","Total Train Loss = 11.041386604309082\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8532259464263916\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8477\n","\n"," 33% 2/6 [00:57<01:54, 28.56s/it]Loss = 0.0\n","\n","Total Train Loss = 10.328753471374512\n","#############    Validation Set Stats\n","Total Validation Loss = 2.746832847595215\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8784\n","\n"," 50% 3/6 [01:25<01:25, 28.56s/it]Loss = 0.0\n","\n","Total Train Loss = 9.35239028930664\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9055652618408203\n","  Accuracy: 0.8692\n","  Micro F1: 0.8655\n","  Macro F1: 0.8561\n","\n"," 67% 4/6 [01:54<00:57, 28.53s/it]Loss = 0.0\n","\n","Total Train Loss = 8.057570457458496\n","#############    Validation Set Stats\n","Total Validation Loss = 3.053403615951538\n","  Accuracy: 0.8726\n","  Micro F1: 0.8691\n","  Macro F1: 0.8580\n","\n"," 83% 5/6 [02:22<00:28, 28.51s/it]Loss = 0.0\n","\n","Total Train Loss = 7.256430149078369\n","#############    Validation Set Stats\n","Total Validation Loss = 3.161369800567627\n","  Accuracy: 0.8726\n","  Micro F1: 0.8691\n","  Macro F1: 0.8580\n","\n","100% 6/6 [02:51<00:00, 28.52s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 16.87570571899414\n","#############    Validation Set Stats\n","Total Validation Loss = 2.772143840789795\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8501\n","\n"," 17% 1/6 [00:28<02:22, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 11.569799423217773\n","#############    Validation Set Stats\n","Total Validation Loss = 2.4327170848846436\n","  Accuracy: 0.8865\n","  Micro F1: 0.8836\n","  Macro F1: 0.8758\n","\n"," 33% 2/6 [00:57<01:54, 28.54s/it]Loss = 0.0\n","\n","Total Train Loss = 10.646642684936523\n","#############    Validation Set Stats\n","Total Validation Loss = 2.606961727142334\n","  Accuracy: 0.9015\n","  Micro F1: 0.9018\n","  Macro F1: 0.8976\n","\n"," 50% 3/6 [01:25<01:25, 28.53s/it]Loss = 0.0\n","\n","Total Train Loss = 9.06786060333252\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6620006561279297\n","  Accuracy: 0.8946\n","  Micro F1: 0.8945\n","  Macro F1: 0.8893\n","\n"," 67% 4/6 [01:54<00:56, 28.49s/it]Loss = 0.0\n","\n","Total Train Loss = 7.665334701538086\n","#############    Validation Set Stats\n","Total Validation Loss = 2.930119037628174\n","  Accuracy: 0.8748\n","  Micro F1: 0.8764\n","  Macro F1: 0.8690\n","\n"," 83% 5/6 [02:22<00:28, 28.46s/it]Loss = 0.0\n","\n","Total Train Loss = 6.917229652404785\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1611015796661377\n","  Accuracy: 0.8575\n","  Micro F1: 0.8582\n","  Macro F1: 0.8484\n","\n","100% 6/6 [02:50<00:00, 28.46s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8832\n","  Micro F1: 0.8836\n","  Macro F1: 0.8769\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Y3bf2wsJWcf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596229136179,"user_tz":-330,"elapsed":7756258,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"97250b51-b198-464b-b42f-563913cb1306"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-4 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 20:44:19.123331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 18.071826934814453\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5196399688720703\n","  Accuracy: 0.8216\n","  Micro F1: 0.8182\n","  Macro F1: 0.8132\n","\n"," 17% 1/6 [00:28<02:24, 28.90s/it]Loss = 0.0\n","\n","Total Train Loss = 11.597376823425293\n","#############    Validation Set Stats\n","Total Validation Loss = 3.6841564178466797\n","  Accuracy: 0.8286\n","  Micro F1: 0.8255\n","  Macro F1: 0.8207\n","\n"," 33% 2/6 [00:58<01:56, 29.07s/it]Loss = 0.0\n","\n","Total Train Loss = 10.80411434173584\n","#############    Validation Set Stats\n","Total Validation Loss = 3.305541515350342\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8485\n","\n"," 50% 3/6 [01:26<01:26, 28.85s/it]Loss = 0.0\n","\n","Total Train Loss = 9.98223876953125\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2861928939819336\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8485\n","\n"," 67% 4/6 [01:55<00:57, 28.82s/it]Loss = 0.0\n","\n","Total Train Loss = 9.013381004333496\n","#############    Validation Set Stats\n","Total Validation Loss = 3.213865041732788\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8484\n","\n"," 83% 5/6 [02:24<00:28, 28.86s/it]Loss = 0.0\n","\n","Total Train Loss = 9.019384384155273\n","#############    Validation Set Stats\n","Total Validation Loss = 3.318845272064209\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8475\n","\n","100% 6/6 [02:53<00:00, 28.85s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.27096939086914\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4577977657318115\n","  Accuracy: 0.8401\n","  Micro F1: 0.8400\n","  Macro F1: 0.8352\n","\n"," 17% 1/6 [00:28<02:23, 28.68s/it]Loss = 0.0\n","\n","Total Train Loss = 11.853973388671875\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9933788776397705\n","  Accuracy: 0.8644\n","  Micro F1: 0.8655\n","  Macro F1: 0.8601\n","\n"," 33% 2/6 [00:57<01:54, 28.74s/it]Loss = 0.0\n","\n","Total Train Loss = 11.347635269165039\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6915781497955322\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8727\n","\n"," 50% 3/6 [01:26<01:26, 28.78s/it]Loss = 0.0\n","\n","Total Train Loss = 10.295857429504395\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6915416717529297\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8736\n","\n"," 67% 4/6 [01:55<00:57, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 9.241645812988281\n","#############    Validation Set Stats\n","Total Validation Loss = 2.717600107192993\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8768\n","\n"," 83% 5/6 [02:24<00:28, 28.82s/it]Loss = 0.0\n","\n","Total Train Loss = 8.385231971740723\n","#############    Validation Set Stats\n","Total Validation Loss = 2.719020128250122\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8753\n","\n","100% 6/6 [02:52<00:00, 28.82s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 16.079452514648438\n","#############    Validation Set Stats\n","Total Validation Loss = 3.256446361541748\n","  Accuracy: 0.8679\n","  Micro F1: 0.8691\n","  Macro F1: 0.8573\n","\n"," 17% 1/6 [00:28<02:24, 28.82s/it]Loss = 0.0\n","\n","Total Train Loss = 11.453272819519043\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4913508892059326\n","  Accuracy: 0.8575\n","  Micro F1: 0.8582\n","  Macro F1: 0.8489\n","\n"," 33% 2/6 [00:57<01:55, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 10.389901161193848\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2240593433380127\n","  Accuracy: 0.8713\n","  Micro F1: 0.8727\n","  Macro F1: 0.8634\n","\n"," 50% 3/6 [01:26<01:26, 28.78s/it]Loss = 0.0\n","\n","Total Train Loss = 9.045816421508789\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7029738426208496\n","  Accuracy: 0.8551\n","  Micro F1: 0.8582\n","  Macro F1: 0.8484\n","\n"," 67% 4/6 [01:54<00:57, 28.75s/it]Loss = 0.0\n","\n","Total Train Loss = 8.344414710998535\n","#############    Validation Set Stats\n","Total Validation Loss = 3.8485097885131836\n","  Accuracy: 0.8586\n","  Micro F1: 0.8618\n","  Macro F1: 0.8513\n","\n"," 83% 5/6 [02:23<00:28, 28.70s/it]Loss = 0.0\n","\n","Total Train Loss = 8.03128719329834\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7446818351745605\n","  Accuracy: 0.8586\n","  Micro F1: 0.8618\n","  Macro F1: 0.8501\n","\n","100% 6/6 [02:52<00:00, 28.70s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.947790145874023\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5009608268737793\n","  Accuracy: 0.8459\n","  Micro F1: 0.8436\n","  Macro F1: 0.8353\n","\n"," 17% 1/6 [00:28<02:23, 28.77s/it]Loss = 0.0\n","\n","Total Train Loss = 12.845954895019531\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8809800148010254\n","  Accuracy: 0.8575\n","  Micro F1: 0.8582\n","  Macro F1: 0.8489\n","\n"," 33% 2/6 [00:57<01:55, 28.76s/it]Loss = 0.0\n","\n","Total Train Loss = 10.702876091003418\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8623592853546143\n","  Accuracy: 0.8748\n","  Micro F1: 0.8764\n","  Macro F1: 0.8704\n","\n"," 50% 3/6 [01:26<01:26, 28.74s/it]Loss = 0.0\n","\n","Total Train Loss = 9.805707931518555\n","#############    Validation Set Stats\n","Total Validation Loss = 2.7703700065612793\n","  Accuracy: 0.8783\n","  Micro F1: 0.8800\n","  Macro F1: 0.8731\n","\n"," 67% 4/6 [01:54<00:57, 28.72s/it]Loss = 0.0\n","\n","Total Train Loss = 8.776851654052734\n","#############    Validation Set Stats\n","Total Validation Loss = 2.866212844848633\n","  Accuracy: 0.8876\n","  Micro F1: 0.8873\n","  Macro F1: 0.8812\n","\n"," 83% 5/6 [02:23<00:28, 28.72s/it]Loss = 0.0\n","\n","Total Train Loss = 8.363554000854492\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1538500785827637\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8550\n","\n","100% 6/6 [02:52<00:00, 28.72s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 17.227397918701172\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6735291481018066\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8795\n","\n"," 17% 1/6 [00:28<02:23, 28.78s/it]Loss = 0.0\n","\n","Total Train Loss = 12.843771934509277\n","#############    Validation Set Stats\n","Total Validation Loss = 2.4852867126464844\n","  Accuracy: 0.9004\n","  Micro F1: 0.8982\n","  Macro F1: 0.8925\n","\n"," 33% 2/6 [00:57<01:55, 28.81s/it]Loss = 0.0\n","\n","Total Train Loss = 10.54603385925293\n","#############    Validation Set Stats\n","Total Validation Loss = 2.285334348678589\n","  Accuracy: 0.9039\n","  Micro F1: 0.9018\n","  Macro F1: 0.8969\n","\n"," 50% 3/6 [01:26<01:26, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 10.199788093566895\n","#############    Validation Set Stats\n","Total Validation Loss = 2.341789484024048\n","  Accuracy: 0.9004\n","  Micro F1: 0.8982\n","  Macro F1: 0.8925\n","\n"," 67% 4/6 [01:55<00:57, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 8.482022285461426\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6285476684570312\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8658\n","\n"," 83% 5/6 [02:24<00:28, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 7.387478351593018\n","#############    Validation Set Stats\n","Total Validation Loss = 2.4895477294921875\n","  Accuracy: 0.8935\n","  Micro F1: 0.8909\n","  Macro F1: 0.8849\n","\n","100% 6/6 [02:52<00:00, 28.81s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8733\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QGe-rfnDJX0p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596230003488,"user_tz":-330,"elapsed":8623379,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"9ec0190a-81fd-4b40-e1a6-a20db765c8e3"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 20:58:57.982542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 18.502077102661133\n","#############    Validation Set Stats\n","Total Validation Loss = 3.437851667404175\n","  Accuracy: 0.8425\n","  Micro F1: 0.8400\n","  Macro F1: 0.8343\n","\n"," 17% 1/6 [00:28<02:23, 28.66s/it]Loss = 0.0\n","\n","Total Train Loss = 11.006739616394043\n","#############    Validation Set Stats\n","Total Validation Loss = 3.673125743865967\n","  Accuracy: 0.8216\n","  Micro F1: 0.8182\n","  Macro F1: 0.8127\n","\n"," 33% 2/6 [00:57<01:55, 28.79s/it]Loss = 0.0\n","\n","Total Train Loss = 9.929386138916016\n","#############    Validation Set Stats\n","Total Validation Loss = 3.242872476577759\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8561\n","\n"," 50% 3/6 [01:25<01:25, 28.51s/it]Loss = 0.0\n","\n","Total Train Loss = 8.906576156616211\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2194039821624756\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8511\n","\n"," 67% 4/6 [01:54<00:56, 28.50s/it]Loss = 0.0\n","\n","Total Train Loss = 8.116094589233398\n","#############    Validation Set Stats\n","Total Validation Loss = 3.439842939376831\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8484\n","\n"," 83% 5/6 [02:22<00:28, 28.53s/it]Loss = 0.0\n","\n","Total Train Loss = 7.210669994354248\n","#############    Validation Set Stats\n","Total Validation Loss = 3.455974578857422\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8489\n","\n","100% 6/6 [02:50<00:00, 28.48s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 18.27443504333496\n","#############    Validation Set Stats\n","Total Validation Loss = 3.329777717590332\n","  Accuracy: 0.8366\n","  Micro F1: 0.8364\n","  Macro F1: 0.8317\n","\n"," 17% 1/6 [00:28<02:21, 28.37s/it]Loss = 0.0\n","\n","Total Train Loss = 11.083032608032227\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6227316856384277\n","  Accuracy: 0.8852\n","  Micro F1: 0.8873\n","  Macro F1: 0.8790\n","\n"," 33% 2/6 [00:56<01:53, 28.43s/it]Loss = 0.0\n","\n","Total Train Loss = 10.372940063476562\n","#############    Validation Set Stats\n","Total Validation Loss = 2.721947193145752\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8758\n","\n"," 50% 3/6 [01:25<01:25, 28.38s/it]Loss = 0.0\n","\n","Total Train Loss = 9.07850456237793\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8349485397338867\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8639\n","\n"," 67% 4/6 [01:53<00:56, 28.35s/it]Loss = 0.0\n","\n","Total Train Loss = 7.9363017082214355\n","#############    Validation Set Stats\n","Total Validation Loss = 3.187697172164917\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8487\n","\n"," 83% 5/6 [02:21<00:28, 28.37s/it]Loss = 0.0\n","\n","Total Train Loss = 7.5115227699279785\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9611358642578125\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8639\n","\n","100% 6/6 [02:50<00:00, 28.38s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 18.083066940307617\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9577865600585938\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8681\n","\n"," 17% 1/6 [00:28<02:22, 28.46s/it]Loss = 0.0\n","\n","Total Train Loss = 10.998738288879395\n","#############    Validation Set Stats\n","Total Validation Loss = 2.834597110748291\n","  Accuracy: 0.8852\n","  Micro F1: 0.8873\n","  Macro F1: 0.8785\n","\n"," 33% 2/6 [00:56<01:53, 28.47s/it]Loss = 0.0\n","\n","Total Train Loss = 10.025826454162598\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2422943115234375\n","  Accuracy: 0.8516\n","  Micro F1: 0.8545\n","  Macro F1: 0.8407\n","\n"," 50% 3/6 [01:25<01:25, 28.46s/it]Loss = 0.0\n","\n","Total Train Loss = 9.043807029724121\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2411272525787354\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8720\n","\n"," 67% 4/6 [01:53<00:56, 28.45s/it]Loss = 0.0\n","\n","Total Train Loss = 8.22640323638916\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2763102054595947\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8560\n","\n"," 83% 5/6 [02:22<00:28, 28.44s/it]Loss = 0.0\n","\n","Total Train Loss = 7.642149448394775\n","#############    Validation Set Stats\n","Total Validation Loss = 3.472486972808838\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8553\n","\n","100% 6/6 [02:50<00:00, 28.43s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 17.586700439453125\n","#############    Validation Set Stats\n","Total Validation Loss = 3.181138515472412\n","  Accuracy: 0.8505\n","  Micro F1: 0.8509\n","  Macro F1: 0.8458\n","\n"," 17% 1/6 [00:28<02:21, 28.33s/it]Loss = 0.0\n","\n","Total Train Loss = 11.488263130187988\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8422060012817383\n","  Accuracy: 0.8702\n","  Micro F1: 0.8691\n","  Macro F1: 0.8628\n","\n"," 33% 2/6 [00:56<01:53, 28.35s/it]Loss = 0.0\n","\n","Total Train Loss = 10.63123607635498\n","#############    Validation Set Stats\n","Total Validation Loss = 2.847332715988159\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8664\n","\n"," 50% 3/6 [01:25<01:25, 28.37s/it]Loss = 0.0\n","\n","Total Train Loss = 9.584266662597656\n","#############    Validation Set Stats\n","Total Validation Loss = 2.7590315341949463\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8740\n","\n"," 67% 4/6 [01:53<00:56, 28.39s/it]Loss = 0.0\n","\n","Total Train Loss = 9.231642723083496\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8842694759368896\n","  Accuracy: 0.8726\n","  Micro F1: 0.8691\n","  Macro F1: 0.8580\n","\n"," 83% 5/6 [02:21<00:28, 28.38s/it]Loss = 0.0\n","\n","Total Train Loss = 8.589256286621094\n","#############    Validation Set Stats\n","Total Validation Loss = 2.7482924461364746\n","  Accuracy: 0.8830\n","  Micro F1: 0.8800\n","  Macro F1: 0.8722\n","\n","100% 6/6 [02:50<00:00, 28.38s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.26251983642578\n","#############    Validation Set Stats\n","Total Validation Loss = 3.377877950668335\n","  Accuracy: 0.8679\n","  Micro F1: 0.8691\n","  Macro F1: 0.8644\n","\n"," 17% 1/6 [00:28<02:21, 28.39s/it]Loss = 0.0\n","\n","Total Train Loss = 12.895676612854004\n","#############    Validation Set Stats\n","Total Validation Loss = 2.7659599781036377\n","  Accuracy: 0.8748\n","  Micro F1: 0.8764\n","  Macro F1: 0.8723\n","\n"," 33% 2/6 [00:56<01:53, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 11.603611946105957\n","#############    Validation Set Stats\n","Total Validation Loss = 2.5675816535949707\n","  Accuracy: 0.8911\n","  Micro F1: 0.8909\n","  Macro F1: 0.8867\n","\n"," 50% 3/6 [01:25<01:25, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 11.338549613952637\n","#############    Validation Set Stats\n","Total Validation Loss = 2.612504243850708\n","  Accuracy: 0.8852\n","  Micro F1: 0.8873\n","  Macro F1: 0.8831\n","\n"," 67% 4/6 [01:53<00:56, 28.40s/it]Loss = 0.0\n","\n","Total Train Loss = 10.44556713104248\n","#############    Validation Set Stats\n","Total Validation Loss = 2.492810010910034\n","  Accuracy: 0.8980\n","  Micro F1: 0.8982\n","  Macro F1: 0.8939\n","\n"," 83% 5/6 [02:22<00:28, 28.41s/it]Loss = 0.0\n","\n","Total Train Loss = 10.061443328857422\n","#############    Validation Set Stats\n","Total Validation Loss = 2.451385498046875\n","  Accuracy: 0.8935\n","  Micro F1: 0.8909\n","  Macro F1: 0.8849\n","\n","100% 6/6 [02:50<00:00, 28.39s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8832\n","  Micro F1: 0.8836\n","  Macro F1: 0.8763\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MXUKwUxhk5Qt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596230874721,"user_tz":-330,"elapsed":9494439,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"adde56cc-1014-4404-83d1-cf487cd3c839"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 21:13:25.333285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 18.871234893798828\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4857592582702637\n","  Accuracy: 0.8332\n","  Micro F1: 0.8327\n","  Macro F1: 0.8252\n","\n"," 17% 1/6 [00:28<02:23, 28.74s/it]Loss = 0.0\n","\n","Total Train Loss = 10.806347846984863\n","#############    Validation Set Stats\n","Total Validation Loss = 3.350984573364258\n","  Accuracy: 0.8529\n","  Micro F1: 0.8509\n","  Macro F1: 0.8449\n","\n"," 33% 2/6 [00:58<01:55, 28.92s/it]Loss = 0.0\n","\n","Total Train Loss = 9.71997356414795\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1640830039978027\n","  Accuracy: 0.8644\n","  Micro F1: 0.8655\n","  Macro F1: 0.8556\n","\n"," 50% 3/6 [01:26<01:26, 28.67s/it]Loss = 0.0\n","\n","Total Train Loss = 8.561989784240723\n","#############    Validation Set Stats\n","Total Validation Loss = 3.157729387283325\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8587\n","\n"," 67% 4/6 [01:54<00:57, 28.61s/it]Loss = 0.0\n","\n","Total Train Loss = 7.556265354156494\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1256375312805176\n","  Accuracy: 0.8713\n","  Micro F1: 0.8727\n","  Macro F1: 0.8649\n","\n"," 83% 5/6 [02:23<00:28, 28.65s/it]Loss = 0.0\n","\n","Total Train Loss = 7.336317539215088\n","#############    Validation Set Stats\n","Total Validation Loss = 3.176811695098877\n","  Accuracy: 0.8737\n","  Micro F1: 0.8727\n","  Macro F1: 0.8654\n","\n","100% 6/6 [02:51<00:00, 28.64s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 18.45658302307129\n","#############    Validation Set Stats\n","Total Validation Loss = 3.59073543548584\n","  Accuracy: 0.8436\n","  Micro F1: 0.8436\n","  Macro F1: 0.8391\n","\n"," 17% 1/6 [00:28<02:22, 28.42s/it]Loss = 0.0\n","\n","Total Train Loss = 11.793654441833496\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9622206687927246\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8708\n","\n"," 33% 2/6 [00:56<01:53, 28.47s/it]Loss = 0.0\n","\n","Total Train Loss = 10.83062744140625\n","#############    Validation Set Stats\n","Total Validation Loss = 2.812530517578125\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8780\n","\n"," 50% 3/6 [01:25<01:25, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 9.298851013183594\n","#############    Validation Set Stats\n","Total Validation Loss = 2.691371440887451\n","  Accuracy: 0.8946\n","  Micro F1: 0.8945\n","  Macro F1: 0.8877\n","\n"," 67% 4/6 [01:54<00:57, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 7.857472896575928\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8865931034088135\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8748\n","\n"," 83% 5/6 [02:22<00:28, 28.48s/it]Loss = 0.0\n","\n","Total Train Loss = 7.5516486167907715\n","#############    Validation Set Stats\n","Total Validation Loss = 3.0563817024230957\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8732\n","\n","100% 6/6 [02:50<00:00, 28.49s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 17.69554328918457\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1219332218170166\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8480\n","\n"," 17% 1/6 [00:28<02:22, 28.42s/it]Loss = 0.0\n","\n","Total Train Loss = 11.00184440612793\n","#############    Validation Set Stats\n","Total Validation Loss = 3.3989076614379883\n","  Accuracy: 0.8551\n","  Micro F1: 0.8582\n","  Macro F1: 0.8428\n","\n"," 33% 2/6 [00:56<01:53, 28.42s/it]Loss = 0.0\n","\n","Total Train Loss = 9.541863441467285\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2934622764587402\n","  Accuracy: 0.8481\n","  Micro F1: 0.8509\n","  Macro F1: 0.8379\n","\n"," 50% 3/6 [01:25<01:25, 28.45s/it]Loss = 0.0\n","\n","Total Train Loss = 8.573262214660645\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4590232372283936\n","  Accuracy: 0.8551\n","  Micro F1: 0.8582\n","  Macro F1: 0.8436\n","\n"," 67% 4/6 [01:53<00:56, 28.47s/it]Loss = 0.0\n","\n","Total Train Loss = 8.09151554107666\n","#############    Validation Set Stats\n","Total Validation Loss = 3.563203811645508\n","  Accuracy: 0.8620\n","  Micro F1: 0.8655\n","  Macro F1: 0.8556\n","\n"," 83% 5/6 [02:22<00:28, 28.49s/it]Loss = 0.0\n","\n","Total Train Loss = 6.8842878341674805\n","#############    Validation Set Stats\n","Total Validation Loss = 3.8080427646636963\n","  Accuracy: 0.8481\n","  Micro F1: 0.8509\n","  Macro F1: 0.8347\n","\n","100% 6/6 [02:50<00:00, 28.49s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 17.498802185058594\n","#############    Validation Set Stats\n","Total Validation Loss = 2.954364538192749\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8429\n","\n"," 17% 1/6 [00:28<02:22, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 11.041386604309082\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8532259464263916\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8477\n","\n"," 33% 2/6 [00:57<01:54, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 10.328753471374512\n","#############    Validation Set Stats\n","Total Validation Loss = 2.746832847595215\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8784\n","\n"," 50% 3/6 [01:25<01:25, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 9.35239028930664\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9055652618408203\n","  Accuracy: 0.8692\n","  Micro F1: 0.8655\n","  Macro F1: 0.8561\n","\n"," 67% 4/6 [01:54<00:57, 28.51s/it]Loss = 0.0\n","\n","Total Train Loss = 8.057570457458496\n","#############    Validation Set Stats\n","Total Validation Loss = 3.053403615951538\n","  Accuracy: 0.8726\n","  Micro F1: 0.8691\n","  Macro F1: 0.8580\n","\n"," 83% 5/6 [02:22<00:28, 28.51s/it]Loss = 0.0\n","\n","Total Train Loss = 7.256430149078369\n","#############    Validation Set Stats\n","Total Validation Loss = 3.161369800567627\n","  Accuracy: 0.8726\n","  Micro F1: 0.8691\n","  Macro F1: 0.8580\n","\n","100% 6/6 [02:51<00:00, 28.51s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 16.87570571899414\n","#############    Validation Set Stats\n","Total Validation Loss = 2.772143840789795\n","  Accuracy: 0.8633\n","  Micro F1: 0.8618\n","  Macro F1: 0.8501\n","\n"," 17% 1/6 [00:28<02:22, 28.50s/it]Loss = 0.0\n","\n","Total Train Loss = 11.569799423217773\n","#############    Validation Set Stats\n","Total Validation Loss = 2.4327170848846436\n","  Accuracy: 0.8865\n","  Micro F1: 0.8836\n","  Macro F1: 0.8758\n","\n"," 33% 2/6 [00:57<01:54, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 10.646642684936523\n","#############    Validation Set Stats\n","Total Validation Loss = 2.606961727142334\n","  Accuracy: 0.9015\n","  Micro F1: 0.9018\n","  Macro F1: 0.8976\n","\n"," 50% 3/6 [01:25<01:25, 28.52s/it]Loss = 0.0\n","\n","Total Train Loss = 9.06786060333252\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6620006561279297\n","  Accuracy: 0.8946\n","  Micro F1: 0.8945\n","  Macro F1: 0.8893\n","\n"," 67% 4/6 [01:54<00:57, 28.51s/it]Loss = 0.0\n","\n","Total Train Loss = 7.665334701538086\n","#############    Validation Set Stats\n","Total Validation Loss = 2.930119037628174\n","  Accuracy: 0.8748\n","  Micro F1: 0.8764\n","  Macro F1: 0.8690\n","\n"," 83% 5/6 [02:22<00:28, 28.51s/it]Loss = 0.0\n","\n","Total Train Loss = 6.917229652404785\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1611015796661377\n","  Accuracy: 0.8575\n","  Micro F1: 0.8582\n","  Macro F1: 0.8484\n","\n","100% 6/6 [02:51<00:00, 28.52s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8832\n","  Micro F1: 0.8836\n","  Macro F1: 0.8769\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E8occyW1Jewb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596231752420,"user_tz":-330,"elapsed":10371667,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"67e160d7-5e05-456d-eb14-adce992de816"},"source":["!python bert_han_cross_val.py -f Datasets/Sarcasm/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-3 --num_labels 2 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 21:27:56.523430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","\n","Total Train Loss = 18.071826934814453\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5196399688720703\n","  Accuracy: 0.8216\n","  Micro F1: 0.8182\n","  Macro F1: 0.8132\n","\n"," 17% 1/6 [00:28<02:24, 28.96s/it]Loss = 0.0\n","\n","Total Train Loss = 11.597376823425293\n","#############    Validation Set Stats\n","Total Validation Loss = 3.6841564178466797\n","  Accuracy: 0.8286\n","  Micro F1: 0.8255\n","  Macro F1: 0.8207\n","\n"," 33% 2/6 [00:58<01:56, 29.11s/it]Loss = 0.0\n","\n","Total Train Loss = 10.80411434173584\n","#############    Validation Set Stats\n","Total Validation Loss = 3.305541515350342\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8485\n","\n"," 50% 3/6 [01:26<01:26, 28.87s/it]Loss = 0.0\n","\n","Total Train Loss = 9.98223876953125\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2861928939819336\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8485\n","\n"," 67% 4/6 [01:55<00:57, 28.82s/it]Loss = 0.0\n","\n","Total Train Loss = 9.013381004333496\n","#############    Validation Set Stats\n","Total Validation Loss = 3.213865041732788\n","  Accuracy: 0.8598\n","  Micro F1: 0.8582\n","  Macro F1: 0.8484\n","\n"," 83% 5/6 [02:24<00:28, 28.86s/it]Loss = 0.0\n","\n","Total Train Loss = 9.019384384155273\n","#############    Validation Set Stats\n","Total Validation Loss = 3.318845272064209\n","  Accuracy: 0.8564\n","  Micro F1: 0.8545\n","  Macro F1: 0.8475\n","\n","100% 6/6 [02:53<00:00, 28.84s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.27096939086914\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4577977657318115\n","  Accuracy: 0.8401\n","  Micro F1: 0.8400\n","  Macro F1: 0.8352\n","\n"," 17% 1/6 [00:28<02:23, 28.69s/it]Loss = 0.0\n","\n","Total Train Loss = 11.853973388671875\n","#############    Validation Set Stats\n","Total Validation Loss = 2.9933788776397705\n","  Accuracy: 0.8644\n","  Micro F1: 0.8655\n","  Macro F1: 0.8601\n","\n"," 33% 2/6 [00:57<01:54, 28.74s/it]Loss = 0.0\n","\n","Total Train Loss = 11.347635269165039\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6915781497955322\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8727\n","\n"," 50% 3/6 [01:26<01:26, 28.73s/it]Loss = 0.0\n","\n","Total Train Loss = 10.295857429504395\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6915416717529297\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8736\n","\n"," 67% 4/6 [01:54<00:57, 28.70s/it]Loss = 0.0\n","\n","Total Train Loss = 9.241645812988281\n","#############    Validation Set Stats\n","Total Validation Loss = 2.717600107192993\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8768\n","\n"," 83% 5/6 [02:23<00:28, 28.69s/it]Loss = 0.0\n","\n","Total Train Loss = 8.385231971740723\n","#############    Validation Set Stats\n","Total Validation Loss = 2.719020128250122\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8753\n","\n","100% 6/6 [02:52<00:00, 28.70s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 16.079452514648438\n","#############    Validation Set Stats\n","Total Validation Loss = 3.256446361541748\n","  Accuracy: 0.8679\n","  Micro F1: 0.8691\n","  Macro F1: 0.8573\n","\n"," 17% 1/6 [00:28<02:23, 28.71s/it]Loss = 0.0\n","\n","Total Train Loss = 11.453272819519043\n","#############    Validation Set Stats\n","Total Validation Loss = 3.4913508892059326\n","  Accuracy: 0.8575\n","  Micro F1: 0.8582\n","  Macro F1: 0.8489\n","\n"," 33% 2/6 [00:57<01:54, 28.70s/it]Loss = 0.0\n","\n","Total Train Loss = 10.389901161193848\n","#############    Validation Set Stats\n","Total Validation Loss = 3.2240593433380127\n","  Accuracy: 0.8713\n","  Micro F1: 0.8727\n","  Macro F1: 0.8634\n","\n"," 50% 3/6 [01:26<01:26, 28.72s/it]Loss = 0.0\n","\n","Total Train Loss = 9.045816421508789\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7029738426208496\n","  Accuracy: 0.8551\n","  Micro F1: 0.8582\n","  Macro F1: 0.8484\n","\n"," 67% 4/6 [01:54<00:57, 28.72s/it]Loss = 0.0\n","\n","Total Train Loss = 8.344414710998535\n","#############    Validation Set Stats\n","Total Validation Loss = 3.8485097885131836\n","  Accuracy: 0.8586\n","  Micro F1: 0.8618\n","  Macro F1: 0.8513\n","\n"," 83% 5/6 [02:23<00:28, 28.70s/it]Loss = 0.0\n","\n","Total Train Loss = 8.03128719329834\n","#############    Validation Set Stats\n","Total Validation Loss = 3.7446818351745605\n","  Accuracy: 0.8586\n","  Micro F1: 0.8618\n","  Macro F1: 0.8501\n","\n","100% 6/6 [02:52<00:00, 28.70s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 20.947790145874023\n","#############    Validation Set Stats\n","Total Validation Loss = 3.5009608268737793\n","  Accuracy: 0.8459\n","  Micro F1: 0.8436\n","  Macro F1: 0.8353\n","\n"," 17% 1/6 [00:28<02:23, 28.73s/it]Loss = 0.0\n","\n","Total Train Loss = 12.845954895019531\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8809800148010254\n","  Accuracy: 0.8575\n","  Micro F1: 0.8582\n","  Macro F1: 0.8489\n","\n"," 33% 2/6 [00:57<01:54, 28.74s/it]Loss = 0.0\n","\n","Total Train Loss = 10.702876091003418\n","#############    Validation Set Stats\n","Total Validation Loss = 2.8623592853546143\n","  Accuracy: 0.8748\n","  Micro F1: 0.8764\n","  Macro F1: 0.8704\n","\n"," 50% 3/6 [01:26<01:26, 28.75s/it]Loss = 0.0\n","\n","Total Train Loss = 9.805707931518555\n","#############    Validation Set Stats\n","Total Validation Loss = 2.7703700065612793\n","  Accuracy: 0.8783\n","  Micro F1: 0.8800\n","  Macro F1: 0.8731\n","\n"," 67% 4/6 [01:55<00:57, 28.76s/it]Loss = 0.0\n","\n","Total Train Loss = 8.776851654052734\n","#############    Validation Set Stats\n","Total Validation Loss = 2.866212844848633\n","  Accuracy: 0.8876\n","  Micro F1: 0.8873\n","  Macro F1: 0.8812\n","\n"," 83% 5/6 [02:23<00:28, 28.77s/it]Loss = 0.0\n","\n","Total Train Loss = 8.363554000854492\n","#############    Validation Set Stats\n","Total Validation Loss = 3.1538500785827637\n","  Accuracy: 0.8668\n","  Micro F1: 0.8655\n","  Macro F1: 0.8550\n","\n","100% 6/6 [02:52<00:00, 28.77s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","\n","Total Train Loss = 17.227397918701172\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6735291481018066\n","  Accuracy: 0.8841\n","  Micro F1: 0.8836\n","  Macro F1: 0.8795\n","\n"," 17% 1/6 [00:28<02:23, 28.79s/it]Loss = 0.0\n","\n","Total Train Loss = 12.843771934509277\n","#############    Validation Set Stats\n","Total Validation Loss = 2.4852867126464844\n","  Accuracy: 0.9004\n","  Micro F1: 0.8982\n","  Macro F1: 0.8925\n","\n"," 33% 2/6 [00:57<01:55, 28.82s/it]Loss = 0.0\n","\n","Total Train Loss = 10.54603385925293\n","#############    Validation Set Stats\n","Total Validation Loss = 2.285334348678589\n","  Accuracy: 0.9039\n","  Micro F1: 0.9018\n","  Macro F1: 0.8969\n","\n"," 50% 3/6 [01:26<01:26, 28.80s/it]Loss = 0.0\n","\n","Total Train Loss = 10.199788093566895\n","#############    Validation Set Stats\n","Total Validation Loss = 2.341789484024048\n","  Accuracy: 0.9004\n","  Micro F1: 0.8982\n","  Macro F1: 0.8925\n","\n"," 67% 4/6 [01:55<00:57, 28.79s/it]Loss = 0.0\n","\n","Total Train Loss = 8.482022285461426\n","#############    Validation Set Stats\n","Total Validation Loss = 2.6285476684570312\n","  Accuracy: 0.8772\n","  Micro F1: 0.8764\n","  Macro F1: 0.8658\n","\n"," 83% 5/6 [02:23<00:28, 28.77s/it]Loss = 0.0\n","\n","Total Train Loss = 7.387478351593018\n","#############    Validation Set Stats\n","Total Validation Loss = 2.4895477294921875\n","  Accuracy: 0.8935\n","  Micro F1: 0.8909\n","  Macro F1: 0.8849\n","\n","100% 6/6 [02:52<00:00, 28.77s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.8807\n","  Micro F1: 0.8800\n","  Macro F1: 0.8733\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q-dxQ1a-6ugJ","colab_type":"text"},"source":["## SENTIMENT 22"]},{"cell_type":"code","metadata":{"id":"GLFlUykokYBV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596239746125,"user_tz":-330,"elapsed":7993682,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"eb53110e-1ad2-465f-a9fb-6f6c08b33379"},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-4 --num_labels 3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 21:42:35.524768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(1.0299, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0220, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0108, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9975, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9880, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9821, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 318.30279541015625\n","#############    Validation Set Stats\n","Total Validation Loss = 74.47499084472656\n","  Accuracy: 0.5780\n","  Micro F1: 0.5781\n","  Macro F1: 0.5332\n","\n"," 17% 1/6 [04:26<22:11, 266.24s/it]Loss = 0.0\n","Loss = tensor(0.8435, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8568, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8526, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8569, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8556, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8543, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 277.3219909667969\n","#############    Validation Set Stats\n","Total Validation Loss = 74.88798522949219\n","  Accuracy: 0.5568\n","  Micro F1: 0.5568\n","  Macro F1: 0.5517\n","\n"," 33% 2/6 [08:51<17:44, 266.05s/it]Loss = 0.0\n","Loss = tensor(0.7414, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7366, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7423, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7319, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7312, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 237.79592895507812\n","#############    Validation Set Stats\n","Total Validation Loss = 74.20243835449219\n","  Accuracy: 0.5838\n","  Micro F1: 0.5838\n","  Macro F1: 0.5676\n","\n"," 50% 3/6 [13:17<13:17, 265.88s/it]Loss = 0.0\n","Loss = tensor(0.6278, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6338, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6272, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6293, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6246, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6267, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 203.65089416503906\n","#############    Validation Set Stats\n","Total Validation Loss = 77.5147476196289\n","  Accuracy: 0.5890\n","  Micro F1: 0.5889\n","  Macro F1: 0.5547\n","\n"," 67% 4/6 [17:43<08:51, 265.96s/it]Loss = 0.0\n","Loss = tensor(0.5566, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5462, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5386, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5402, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5384, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 175.070556640625\n","#############    Validation Set Stats\n","Total Validation Loss = 82.40632629394531\n","  Accuracy: 0.5847\n","  Micro F1: 0.5846\n","  Macro F1: 0.5703\n","\n"," 83% 5/6 [22:09<04:25, 265.92s/it]Loss = 0.0\n","Loss = tensor(0.4629, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4626, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4668, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4738, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4735, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 152.89088439941406\n","#############    Validation Set Stats\n","Total Validation Loss = 85.2085952758789\n","  Accuracy: 0.5854\n","  Micro F1: 0.5854\n","  Macro F1: 0.5703\n","\n","100% 6/6 [26:35<00:00, 265.84s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0225, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0284, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0205, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0135, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0016, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9943, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 321.7132263183594\n","#############    Validation Set Stats\n","Total Validation Loss = 73.26118469238281\n","  Accuracy: 0.5784\n","  Micro F1: 0.5787\n","  Macro F1: 0.5447\n","\n"," 17% 1/6 [04:25<22:06, 265.37s/it]Loss = 0.0\n","Loss = tensor(0.8394, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8398, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8459, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8500, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8535, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8525, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 276.7972412109375\n","#############    Validation Set Stats\n","Total Validation Loss = 71.79631805419922\n","  Accuracy: 0.5907\n","  Micro F1: 0.5906\n","  Macro F1: 0.5820\n","\n"," 33% 2/6 [08:50<17:41, 265.38s/it]Loss = 0.0\n","Loss = tensor(0.7232, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7384, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7440, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7289, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7362, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7304, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 238.4403076171875\n","#############    Validation Set Stats\n","Total Validation Loss = 73.48700714111328\n","  Accuracy: 0.5714\n","  Micro F1: 0.5713\n","  Macro F1: 0.5656\n","\n"," 50% 3/6 [13:16<13:16, 265.38s/it]Loss = 0.0\n","Loss = tensor(0.6408, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6310, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6247, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6210, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6294, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6311, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 204.8599395751953\n","#############    Validation Set Stats\n","Total Validation Loss = 77.89041137695312\n","  Accuracy: 0.5904\n","  Micro F1: 0.5906\n","  Macro F1: 0.5638\n","\n"," 67% 4/6 [17:41<08:50, 265.47s/it]Loss = 0.0\n","Loss = tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5430, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5385, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5408, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5391, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5392, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 175.43667602539062\n","#############    Validation Set Stats\n","Total Validation Loss = 80.8228988647461\n","  Accuracy: 0.5920\n","  Micro F1: 0.5922\n","  Macro F1: 0.5801\n","\n"," 83% 5/6 [22:07<04:25, 265.51s/it]Loss = 0.0\n","Loss = tensor(0.4859, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4778, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4791, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 155.27072143554688\n","#############    Validation Set Stats\n","Total Validation Loss = 83.64427947998047\n","  Accuracy: 0.5904\n","  Micro F1: 0.5906\n","  Macro F1: 0.5761\n","\n","100% 6/6 [26:33<00:00, 265.55s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0399, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0296, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0161, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0100, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0013, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9953, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 321.560546875\n","#############    Validation Set Stats\n","Total Validation Loss = 74.47100067138672\n","  Accuracy: 0.5725\n","  Micro F1: 0.5725\n","  Macro F1: 0.5120\n","\n"," 17% 1/6 [04:25<22:09, 265.93s/it]Loss = 0.0\n","Loss = tensor(0.8356, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8593, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8547, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8607, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8614, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8602, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 279.6020202636719\n","#############    Validation Set Stats\n","Total Validation Loss = 73.37074279785156\n","  Accuracy: 0.5722\n","  Micro F1: 0.5721\n","  Macro F1: 0.5505\n","\n"," 33% 2/6 [08:51<17:43, 265.92s/it]Loss = 0.0\n","Loss = tensor(0.7425, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7333, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7441, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7492, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7525, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7480, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 243.05633544921875\n","#############    Validation Set Stats\n","Total Validation Loss = 73.0450439453125\n","  Accuracy: 0.5855\n","  Micro F1: 0.5852\n","  Macro F1: 0.5687\n","\n"," 50% 3/6 [13:17<13:17, 265.88s/it]Loss = 0.0\n","Loss = tensor(0.6093, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6319, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6392, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6414, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6422, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 208.55770874023438\n","#############    Validation Set Stats\n","Total Validation Loss = 76.91165161132812\n","  Accuracy: 0.5896\n","  Micro F1: 0.5895\n","  Macro F1: 0.5732\n","\n"," 67% 4/6 [17:43<08:51, 265.79s/it]Loss = 0.0\n","Loss = tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5394, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5451, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5426, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5471, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5428, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 177.16506958007812\n","#############    Validation Set Stats\n","Total Validation Loss = 79.96708679199219\n","  Accuracy: 0.5936\n","  Micro F1: 0.5934\n","  Macro F1: 0.5776\n","\n"," 83% 5/6 [22:08<04:25, 265.67s/it]Loss = 0.0\n","Loss = tensor(0.4768, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4706, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4795, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4734, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 154.76219177246094\n","#############    Validation Set Stats\n","Total Validation Loss = 84.71800994873047\n","  Accuracy: 0.5967\n","  Micro F1: 0.5964\n","  Macro F1: 0.5795\n","\n","100% 6/6 [26:34<00:00, 265.68s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0168, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0284, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0095, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9960, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9880, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9801, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 317.92755126953125\n","#############    Validation Set Stats\n","Total Validation Loss = 75.13622283935547\n","  Accuracy: 0.5609\n","  Micro F1: 0.5609\n","  Macro F1: 0.4736\n","\n"," 17% 1/6 [04:25<22:07, 265.49s/it]Loss = 0.0\n","Loss = tensor(0.8771, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8688, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8640, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8551, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8537, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8461, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 275.2132568359375\n","#############    Validation Set Stats\n","Total Validation Loss = 71.1480712890625\n","  Accuracy: 0.5990\n","  Micro F1: 0.5991\n","  Macro F1: 0.5717\n","\n"," 33% 2/6 [08:50<17:41, 265.47s/it]Loss = 0.0\n","Loss = tensor(0.7079, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7110, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7196, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7232, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7234, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7262, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 235.36196899414062\n","#############    Validation Set Stats\n","Total Validation Loss = 73.41356658935547\n","  Accuracy: 0.6023\n","  Micro F1: 0.6022\n","  Macro F1: 0.5805\n","\n"," 50% 3/6 [13:16<13:16, 265.61s/it]Loss = 0.0\n","Loss = tensor(0.5656, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5902, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6066, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6059, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6118, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 199.12298583984375\n","#############    Validation Set Stats\n","Total Validation Loss = 80.59991455078125\n","  Accuracy: 0.5918\n","  Micro F1: 0.5918\n","  Macro F1: 0.5608\n","\n"," 67% 4/6 [17:42<08:51, 265.69s/it]Loss = 0.0\n","Loss = tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5144, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5123, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5140, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 167.94676208496094\n","#############    Validation Set Stats\n","Total Validation Loss = 81.20233917236328\n","  Accuracy: 0.5907\n","  Micro F1: 0.5906\n","  Macro F1: 0.5746\n","\n"," 83% 5/6 [22:08<04:25, 265.78s/it]Loss = 0.0\n","Loss = tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4368, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4601, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4566, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4482, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 146.1673583984375\n","#############    Validation Set Stats\n","Total Validation Loss = 85.32818603515625\n","  Accuracy: 0.5946\n","  Micro F1: 0.5945\n","  Macro F1: 0.5754\n","\n","100% 6/6 [26:34<00:00, 265.78s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0290, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0315, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0214, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0086, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9990, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9828, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 318.122314453125\n","#############    Validation Set Stats\n","Total Validation Loss = 74.47560119628906\n","  Accuracy: 0.5704\n","  Micro F1: 0.5702\n","  Macro F1: 0.5152\n","\n"," 17% 1/6 [04:25<22:07, 265.46s/it]Loss = 0.0\n","Loss = tensor(0.8529, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8480, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8469, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8477, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8539, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8509, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 276.06158447265625\n","#############    Validation Set Stats\n","Total Validation Loss = 72.14257049560547\n","  Accuracy: 0.5980\n","  Micro F1: 0.5980\n","  Macro F1: 0.5497\n","\n"," 33% 2/6 [08:51<17:42, 265.60s/it]Loss = 0.0\n","Loss = tensor(0.7367, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7588, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7541, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7471, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7425, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7398, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 240.2752227783203\n","#############    Validation Set Stats\n","Total Validation Loss = 71.23641967773438\n","  Accuracy: 0.6109\n","  Micro F1: 0.6107\n","  Macro F1: 0.5936\n","\n"," 50% 3/6 [13:17<13:16, 265.63s/it]Loss = 0.0\n","Loss = tensor(0.5985, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6076, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6176, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6219, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6197, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6196, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 201.60748291015625\n","#############    Validation Set Stats\n","Total Validation Loss = 76.39262390136719\n","  Accuracy: 0.6082\n","  Micro F1: 0.6080\n","  Macro F1: 0.5910\n","\n"," 67% 4/6 [17:42<08:51, 265.69s/it]Loss = 0.0\n","Loss = tensor(0.5269, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5222, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5186, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5235, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5268, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 170.34617614746094\n","#############    Validation Set Stats\n","Total Validation Loss = 79.01398468017578\n","  Accuracy: 0.6082\n","  Micro F1: 0.6080\n","  Macro F1: 0.5924\n","\n"," 83% 5/6 [22:08<04:25, 265.69s/it]Loss = 0.0\n","Loss = tensor(0.4552, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4593, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4551, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4556, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 147.78489685058594\n","#############    Validation Set Stats\n","Total Validation Loss = 82.68505096435547\n","  Accuracy: 0.6036\n","  Micro F1: 0.6034\n","  Macro F1: 0.5946\n","\n","100% 6/6 [26:34<00:00, 265.82s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.5957\n","  Micro F1: 0.5956\n","  Macro F1: 0.5814\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JzycmsANNjHK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596247778486,"user_tz":-330,"elapsed":16026028,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"4f881229-1dab-4f0f-d1a0-96cc581d270f"},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-4 --num_labels 3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-31 23:55:48.037532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(1.0274, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0247, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0128, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9857, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9766, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 316.67987060546875\n","#############    Validation Set Stats\n","Total Validation Loss = 74.35680389404297\n","  Accuracy: 0.5716\n","  Micro F1: 0.5715\n","  Macro F1: 0.5217\n","\n"," 17% 1/6 [04:27<22:18, 267.65s/it]Loss = 0.0\n","Loss = tensor(0.8379, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8399, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8394, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8453, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8434, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8389, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 272.781494140625\n","#############    Validation Set Stats\n","Total Validation Loss = 71.64213562011719\n","  Accuracy: 0.5927\n","  Micro F1: 0.5927\n","  Macro F1: 0.5764\n","\n"," 33% 2/6 [08:54<17:49, 267.40s/it]Loss = 0.0\n","Loss = tensor(0.7066, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7127, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7164, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7160, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7185, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 233.80641174316406\n","#############    Validation Set Stats\n","Total Validation Loss = 72.97129821777344\n","  Accuracy: 0.6005\n","  Micro F1: 0.6005\n","  Macro F1: 0.5881\n","\n"," 50% 3/6 [13:21<13:22, 267.34s/it]Loss = 0.0\n","Loss = tensor(0.6031, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6080, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6109, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5981, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5993, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6014, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 194.92547607421875\n","#############    Validation Set Stats\n","Total Validation Loss = 78.8615951538086\n","  Accuracy: 0.5951\n","  Micro F1: 0.5951\n","  Macro F1: 0.5815\n","\n"," 67% 4/6 [17:48<08:54, 267.22s/it]Loss = 0.0\n","Loss = tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4972, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5031, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5017, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 163.15257263183594\n","#############    Validation Set Stats\n","Total Validation Loss = 84.8025894165039\n","  Accuracy: 0.5932\n","  Micro F1: 0.5931\n","  Macro F1: 0.5760\n","\n"," 83% 5/6 [22:15<04:27, 267.16s/it]Loss = 0.0\n","Loss = tensor(0.4164, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4247, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4323, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4319, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 140.678466796875\n","#############    Validation Set Stats\n","Total Validation Loss = 89.45317840576172\n","  Accuracy: 0.5877\n","  Micro F1: 0.5877\n","  Macro F1: 0.5768\n","\n","100% 6/6 [26:42<00:00, 267.05s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0415, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0252, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0062, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9913, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9787, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 317.0845031738281\n","#############    Validation Set Stats\n","Total Validation Loss = 73.69796752929688\n","  Accuracy: 0.5755\n","  Micro F1: 0.5756\n","  Macro F1: 0.5613\n","\n"," 17% 1/6 [04:26<22:13, 266.76s/it]Loss = 0.0\n","Loss = tensor(0.8272, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8287, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8376, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8373, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8383, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8365, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 272.30218505859375\n","#############    Validation Set Stats\n","Total Validation Loss = 71.43833923339844\n","  Accuracy: 0.5975\n","  Micro F1: 0.5976\n","  Macro F1: 0.5842\n","\n"," 33% 2/6 [08:54<17:47, 266.93s/it]Loss = 0.0\n","Loss = tensor(0.7040, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7119, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7091, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7109, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7055, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7054, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 228.98431396484375\n","#############    Validation Set Stats\n","Total Validation Loss = 74.82818603515625\n","  Accuracy: 0.5889\n","  Micro F1: 0.5891\n","  Macro F1: 0.5718\n","\n"," 50% 3/6 [13:21<13:20, 266.98s/it]Loss = 0.0\n","Loss = tensor(0.5783, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6039, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6013, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5898, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5887, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 189.4431610107422\n","#############    Validation Set Stats\n","Total Validation Loss = 83.79215240478516\n","  Accuracy: 0.5934\n","  Micro F1: 0.5934\n","  Macro F1: 0.5803\n","\n"," 67% 4/6 [17:48<08:54, 267.08s/it]Loss = 0.0\n","Loss = tensor(0.5281, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5254, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5021, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4926, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4924, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 159.60568237304688\n","#############    Validation Set Stats\n","Total Validation Loss = 87.14097595214844\n","  Accuracy: 0.5928\n","  Micro F1: 0.5930\n","  Macro F1: 0.5719\n","\n"," 83% 5/6 [22:15<04:27, 267.08s/it]Loss = 0.0\n","Loss = tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4126, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4187, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4169, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 135.2696075439453\n","#############    Validation Set Stats\n","Total Validation Loss = 92.6662368774414\n","  Accuracy: 0.5836\n","  Micro F1: 0.5837\n","  Macro F1: 0.5637\n","\n","100% 6/6 [26:42<00:00, 267.16s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0333, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0174, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0135, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9963, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9846, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9765, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 316.17193603515625\n","#############    Validation Set Stats\n","Total Validation Loss = 75.35938262939453\n","  Accuracy: 0.5644\n","  Micro F1: 0.5644\n","  Macro F1: 0.5307\n","\n"," 17% 1/6 [04:27<22:15, 267.00s/it]Loss = 0.0\n","Loss = tensor(0.8815, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8668, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8548, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8470, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8401, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8351, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 271.23040771484375\n","#############    Validation Set Stats\n","Total Validation Loss = 72.65827178955078\n","  Accuracy: 0.5928\n","  Micro F1: 0.5926\n","  Macro F1: 0.5664\n","\n"," 33% 2/6 [08:54<17:48, 267.04s/it]Loss = 0.0\n","Loss = tensor(0.7287, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7186, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7163, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7062, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7095, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 230.7296600341797\n","#############    Validation Set Stats\n","Total Validation Loss = 75.63358306884766\n","  Accuracy: 0.5854\n","  Micro F1: 0.5852\n","  Macro F1: 0.5734\n","\n"," 50% 3/6 [13:21<13:21, 267.21s/it]Loss = 0.0\n","Loss = tensor(0.5762, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5869, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5894, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5907, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5905, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 192.44969177246094\n","#############    Validation Set Stats\n","Total Validation Loss = 78.74346160888672\n","  Accuracy: 0.6026\n","  Micro F1: 0.6026\n","  Macro F1: 0.5850\n","\n"," 67% 4/6 [17:49<08:54, 267.24s/it]Loss = 0.0\n","Loss = tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4990, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4982, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5021, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4991, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 162.83135986328125\n","#############    Validation Set Stats\n","Total Validation Loss = 82.25293731689453\n","  Accuracy: 0.6035\n","  Micro F1: 0.6034\n","  Macro F1: 0.5837\n","\n"," 83% 5/6 [22:16<04:27, 267.20s/it]Loss = 0.0\n","Loss = tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4337, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4276, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4244, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4247, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 138.961181640625\n","#############    Validation Set Stats\n","Total Validation Loss = 89.03263092041016\n","  Accuracy: 0.5990\n","  Micro F1: 0.5988\n","  Macro F1: 0.5793\n","\n","100% 6/6 [26:42<00:00, 267.15s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0316, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0308, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0212, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0148, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0041, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9932, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 321.24652099609375\n","#############    Validation Set Stats\n","Total Validation Loss = 73.21204376220703\n","  Accuracy: 0.5849\n","  Micro F1: 0.5848\n","  Macro F1: 0.5462\n","\n"," 17% 1/6 [04:26<22:14, 266.90s/it]Loss = 0.0\n","Loss = tensor(0.8434, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8662, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8549, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8465, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8483, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8481, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 275.71783447265625\n","#############    Validation Set Stats\n","Total Validation Loss = 71.46004486083984\n","  Accuracy: 0.5965\n","  Micro F1: 0.5964\n","  Macro F1: 0.5744\n","\n"," 33% 2/6 [08:53<17:47, 266.95s/it]Loss = 0.0\n","Loss = tensor(0.7193, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7155, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7234, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7217, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7244, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7227, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 234.8262176513672\n","#############    Validation Set Stats\n","Total Validation Loss = 73.10105895996094\n","  Accuracy: 0.5957\n","  Micro F1: 0.5957\n","  Macro F1: 0.5756\n","\n"," 50% 3/6 [13:20<13:20, 266.95s/it]Loss = 0.0\n","Loss = tensor(0.6171, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6125, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6201, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6138, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6117, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 199.7726287841797\n","#############    Validation Set Stats\n","Total Validation Loss = 78.34355926513672\n","  Accuracy: 0.5935\n","  Micro F1: 0.5934\n","  Macro F1: 0.5767\n","\n"," 67% 4/6 [17:48<08:54, 267.05s/it]Loss = 0.0\n","Loss = tensor(0.5091, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5238, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5214, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5166, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5201, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 169.2009735107422\n","#############    Validation Set Stats\n","Total Validation Loss = 84.17710876464844\n","  Accuracy: 0.6008\n","  Micro F1: 0.6007\n","  Macro F1: 0.5765\n","\n"," 83% 5/6 [22:15<04:27, 267.09s/it]Loss = 0.0\n","Loss = tensor(0.4422, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4593, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4544, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4567, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4510, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 145.87918090820312\n","#############    Validation Set Stats\n","Total Validation Loss = 86.87177276611328\n","  Accuracy: 0.6044\n","  Micro F1: 0.6042\n","  Macro F1: 0.5823\n","\n","100% 6/6 [26:42<00:00, 267.09s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0281, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0178, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0110, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9971, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9848, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9748, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 314.8164367675781\n","#############    Validation Set Stats\n","Total Validation Loss = 73.0487289428711\n","  Accuracy: 0.5859\n","  Micro F1: 0.5860\n","  Macro F1: 0.5760\n","\n"," 17% 1/6 [04:26<22:14, 266.91s/it]Loss = 0.0\n","Loss = tensor(0.8011, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8284, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8355, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8387, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8360, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8351, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 271.4231262207031\n","#############    Validation Set Stats\n","Total Validation Loss = 69.40462493896484\n","  Accuracy: 0.6206\n","  Micro F1: 0.6204\n","  Macro F1: 0.5958\n","\n"," 33% 2/6 [08:53<17:47, 266.93s/it]Loss = 0.0\n","Loss = tensor(0.7092, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7058, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7118, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7150, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7125, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7154, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 232.42779541015625\n","#############    Validation Set Stats\n","Total Validation Loss = 73.45539855957031\n","  Accuracy: 0.6098\n","  Micro F1: 0.6096\n","  Macro F1: 0.6020\n","\n"," 50% 3/6 [13:20<13:20, 266.98s/it]Loss = 0.0\n","Loss = tensor(0.5967, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6036, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5991, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6016, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5955, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6002, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 195.19012451171875\n","#############    Validation Set Stats\n","Total Validation Loss = 74.43181610107422\n","  Accuracy: 0.6112\n","  Micro F1: 0.6111\n","  Macro F1: 0.5939\n","\n"," 67% 4/6 [17:48<08:54, 267.00s/it]Loss = 0.0\n","Loss = tensor(0.5059, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5136, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5046, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5028, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5033, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 163.27809143066406\n","#############    Validation Set Stats\n","Total Validation Loss = 80.96195220947266\n","  Accuracy: 0.6166\n","  Micro F1: 0.6165\n","  Macro F1: 0.5948\n","\n"," 83% 5/6 [22:15<04:27, 267.04s/it]Loss = 0.0\n","Loss = tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4274, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4264, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4281, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4345, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4301, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 139.83172607421875\n","#############    Validation Set Stats\n","Total Validation Loss = 84.74274444580078\n","  Accuracy: 0.6116\n","  Micro F1: 0.6115\n","  Macro F1: 0.5954\n","\n","100% 6/6 [26:42<00:00, 267.02s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6029\n","  Micro F1: 0.6029\n","  Macro F1: 0.5883\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uaXHrzmaNkXW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596255889194,"user_tz":-330,"elapsed":24136731,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"47cd2412-0401-4ee7-912d-062d0e77c03e"},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-4 --num_labels 3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-01 02:09:40.419960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(1.0501, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0454, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0349, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0329, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0098, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 326.9302978515625\n","#############    Validation Set Stats\n","Total Validation Loss = 76.5968246459961\n","  Accuracy: 0.5455\n","  Micro F1: 0.5456\n","  Macro F1: 0.5191\n","\n"," 17% 1/6 [04:29<22:29, 269.82s/it]Loss = 0.0\n","Loss = tensor(0.8686, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8876, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8930, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8937, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8897, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8850, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 286.7619934082031\n","#############    Validation Set Stats\n","Total Validation Loss = 72.60673522949219\n","  Accuracy: 0.5806\n","  Micro F1: 0.5808\n","  Macro F1: 0.5684\n","\n"," 33% 2/6 [08:59<17:59, 269.81s/it]Loss = 0.0\n","Loss = tensor(0.7562, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7655, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7714, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7711, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7712, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7710, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 249.72860717773438\n","#############    Validation Set Stats\n","Total Validation Loss = 73.97674560546875\n","  Accuracy: 0.5978\n","  Micro F1: 0.5978\n","  Macro F1: 0.5599\n","\n"," 50% 3/6 [13:29<13:29, 269.79s/it]Loss = 0.0\n","Loss = tensor(0.6586, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6577, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6615, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6577, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6603, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 214.41749572753906\n","#############    Validation Set Stats\n","Total Validation Loss = 76.98786926269531\n","  Accuracy: 0.6001\n","  Micro F1: 0.6001\n","  Macro F1: 0.5835\n","\n"," 67% 4/6 [17:58<08:59, 269.63s/it]Loss = 0.0\n","Loss = tensor(0.5596, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5612, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5607, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5535, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5631, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 183.6871795654297\n","#############    Validation Set Stats\n","Total Validation Loss = 83.68250274658203\n","  Accuracy: 0.5739\n","  Micro F1: 0.5738\n","  Macro F1: 0.5663\n","\n"," 83% 5/6 [22:27<04:29, 269.55s/it]Loss = 0.0\n","Loss = tensor(0.4705, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4837, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4923, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4925, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4954, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4963, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 161.10076904296875\n","#############    Validation Set Stats\n","Total Validation Loss = 85.39421081542969\n","  Accuracy: 0.5832\n","  Micro F1: 0.5831\n","  Macro F1: 0.5672\n","\n","100% 6/6 [26:57<00:00, 269.62s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0318, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0372, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0228, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0099, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9874, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 318.6459045410156\n","#############    Validation Set Stats\n","Total Validation Loss = 73.48859405517578\n","  Accuracy: 0.5723\n","  Micro F1: 0.5725\n","  Macro F1: 0.5183\n","\n"," 17% 1/6 [04:29<22:27, 269.49s/it]Loss = 0.0\n","Loss = tensor(0.8061, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8370, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8374, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8353, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8328, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8322, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 270.1369323730469\n","#############    Validation Set Stats\n","Total Validation Loss = 71.0284194946289\n","  Accuracy: 0.6102\n","  Micro F1: 0.6104\n","  Macro F1: 0.6006\n","\n"," 33% 2/6 [08:59<17:57, 269.50s/it]Loss = 0.0\n","Loss = tensor(0.6953, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6934, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6887, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6939, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7010, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7057, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 229.49179077148438\n","#############    Validation Set Stats\n","Total Validation Loss = 73.16988372802734\n","  Accuracy: 0.6013\n","  Micro F1: 0.6015\n","  Macro F1: 0.5828\n","\n"," 50% 3/6 [13:28<13:28, 269.59s/it]Loss = 0.0\n","Loss = tensor(0.5749, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5788, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5850, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5799, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5811, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5816, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 189.92596435546875\n","#############    Validation Set Stats\n","Total Validation Loss = 79.40958404541016\n","  Accuracy: 0.5858\n","  Micro F1: 0.5860\n","  Macro F1: 0.5780\n","\n"," 67% 4/6 [17:58<08:59, 269.73s/it]Loss = 0.0\n","Loss = tensor(0.4681, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4635, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4774, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4804, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 155.98097229003906\n","#############    Validation Set Stats\n","Total Validation Loss = 87.90442657470703\n","  Accuracy: 0.5843\n","  Micro F1: 0.5845\n","  Macro F1: 0.5656\n","\n"," 83% 5/6 [22:28<04:29, 269.62s/it]Loss = 0.0\n","Loss = tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4108, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4151, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4131, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 134.17335510253906\n","#############    Validation Set Stats\n","Total Validation Loss = 92.54256439208984\n","  Accuracy: 0.5793\n","  Micro F1: 0.5794\n","  Macro F1: 0.5635\n","\n","100% 6/6 [26:57<00:00, 269.66s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0470, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0420, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0301, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0218, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0104, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0040, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 324.25689697265625\n","#############    Validation Set Stats\n","Total Validation Loss = 77.4845962524414\n","  Accuracy: 0.5534\n","  Micro F1: 0.5535\n","  Macro F1: 0.4461\n","\n"," 17% 1/6 [04:30<22:30, 270.11s/it]Loss = 0.0\n","Loss = tensor(0.8457, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8591, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8655, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8629, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8598, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8575, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 278.7623291015625\n","#############    Validation Set Stats\n","Total Validation Loss = 72.74781036376953\n","  Accuracy: 0.5839\n","  Micro F1: 0.5837\n","  Macro F1: 0.5536\n","\n"," 33% 2/6 [09:00<18:00, 270.05s/it]Loss = 0.0\n","Loss = tensor(0.7305, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7317, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7262, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7257, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7317, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7328, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 238.11521911621094\n","#############    Validation Set Stats\n","Total Validation Loss = 74.28852081298828\n","  Accuracy: 0.5992\n","  Micro F1: 0.5991\n","  Macro F1: 0.5721\n","\n"," 50% 3/6 [13:29<13:29, 269.88s/it]Loss = 0.0\n","Loss = tensor(0.5961, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5987, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6084, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6095, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 199.0681610107422\n","#############    Validation Set Stats\n","Total Validation Loss = 78.76457977294922\n","  Accuracy: 0.5919\n","  Micro F1: 0.5918\n","  Macro F1: 0.5789\n","\n"," 67% 4/6 [17:59<08:59, 269.83s/it]Loss = 0.0\n","Loss = tensor(0.4970, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5051, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5121, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5017, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 166.45785522460938\n","#############    Validation Set Stats\n","Total Validation Loss = 85.2841567993164\n","  Accuracy: 0.6005\n","  Micro F1: 0.6003\n","  Macro F1: 0.5850\n","\n"," 83% 5/6 [22:29<04:29, 269.82s/it]Loss = 0.0\n","Loss = tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4367, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4334, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 141.9562225341797\n","#############    Validation Set Stats\n","Total Validation Loss = 89.82113647460938\n","  Accuracy: 0.6005\n","  Micro F1: 0.6003\n","  Macro F1: 0.5826\n","\n","100% 6/6 [26:58<00:00, 269.75s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0486, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0365, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0192, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0046, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9893, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9802, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 316.6168212890625\n","#############    Validation Set Stats\n","Total Validation Loss = 72.97685241699219\n","  Accuracy: 0.5861\n","  Micro F1: 0.5860\n","  Macro F1: 0.5529\n","\n"," 17% 1/6 [04:29<22:28, 269.64s/it]Loss = 0.0\n","Loss = tensor(0.8384, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8389, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8369, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8366, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8326, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8325, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 271.0129089355469\n","#############    Validation Set Stats\n","Total Validation Loss = 69.86607360839844\n","  Accuracy: 0.6103\n","  Micro F1: 0.6104\n","  Macro F1: 0.5825\n","\n"," 33% 2/6 [08:59<17:58, 269.71s/it]Loss = 0.0\n","Loss = tensor(0.7012, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7129, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7174, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7119, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7100, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 230.65597534179688\n","#############    Validation Set Stats\n","Total Validation Loss = 74.25052642822266\n","  Accuracy: 0.6025\n","  Micro F1: 0.6026\n","  Macro F1: 0.5868\n","\n"," 50% 3/6 [13:29<13:29, 269.79s/it]Loss = 0.0\n","Loss = tensor(0.5829, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5652, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5813, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5854, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5884, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5842, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 189.4779510498047\n","#############    Validation Set Stats\n","Total Validation Loss = 79.87013244628906\n","  Accuracy: 0.5979\n","  Micro F1: 0.5980\n","  Macro F1: 0.5698\n","\n"," 67% 4/6 [17:59<08:59, 269.74s/it]Loss = 0.0\n","Loss = tensor(0.4783, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4742, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4666, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4760, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4801, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 155.70645141601562\n","#############    Validation Set Stats\n","Total Validation Loss = 86.43255615234375\n","  Accuracy: 0.6014\n","  Micro F1: 0.6015\n","  Macro F1: 0.5808\n","\n"," 83% 5/6 [22:28<04:29, 269.74s/it]Loss = 0.0\n","Loss = tensor(0.4131, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4112, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4067, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4063, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 132.38931274414062\n","#############    Validation Set Stats\n","Total Validation Loss = 91.56253814697266\n","  Accuracy: 0.5964\n","  Micro F1: 0.5964\n","  Macro F1: 0.5820\n","\n","100% 6/6 [26:58<00:00, 269.67s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0426, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0490, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0383, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0243, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0162, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0036, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 325.4319763183594\n","#############    Validation Set Stats\n","Total Validation Loss = 74.15252685546875\n","  Accuracy: 0.5690\n","  Micro F1: 0.5690\n","  Macro F1: 0.5325\n","\n"," 17% 1/6 [04:29<22:26, 269.39s/it]Loss = 0.0\n","Loss = tensor(0.8648, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8609, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8632, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8621, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8607, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8603, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 280.0616760253906\n","#############    Validation Set Stats\n","Total Validation Loss = 70.09288024902344\n","  Accuracy: 0.6018\n","  Micro F1: 0.6019\n","  Macro F1: 0.5751\n","\n"," 33% 2/6 [08:58<17:57, 269.45s/it]Loss = 0.0\n","Loss = tensor(0.7154, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7339, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7409, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7422, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7358, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 238.66714477539062\n","#############    Validation Set Stats\n","Total Validation Loss = 72.10002136230469\n","  Accuracy: 0.6210\n","  Micro F1: 0.6208\n","  Macro F1: 0.6051\n","\n"," 50% 3/6 [13:29<13:28, 269.64s/it]Loss = 0.0\n","Loss = tensor(0.6002, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6179, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6242, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6247, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6289, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 204.79840087890625\n","#############    Validation Set Stats\n","Total Validation Loss = 73.76968383789062\n","  Accuracy: 0.6174\n","  Micro F1: 0.6173\n","  Macro F1: 0.5935\n","\n"," 67% 4/6 [17:58<08:59, 269.65s/it]Loss = 0.0\n","Loss = tensor(0.4933, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5150, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5244, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5360, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5327, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 173.21493530273438\n","#############    Validation Set Stats\n","Total Validation Loss = 79.99102783203125\n","  Accuracy: 0.6170\n","  Micro F1: 0.6169\n","  Macro F1: 0.6053\n","\n"," 83% 5/6 [22:29<04:29, 269.84s/it]Loss = 0.0\n","Loss = tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4556, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4568, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4584, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 149.86666870117188\n","#############    Validation Set Stats\n","Total Validation Loss = 83.86254119873047\n","  Accuracy: 0.6183\n","  Micro F1: 0.6181\n","  Macro F1: 0.6060\n","\n","100% 6/6 [26:58<00:00, 269.80s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6063\n","  Micro F1: 0.6063\n","  Macro F1: 0.5924\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k7nNHtN8NlW2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596260774483,"user_tz":-330,"elapsed":4250800,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"b13c900f-f9ee-4916-d700-a1a96b65e8bf"},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-3 --num_labels 3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-01 04:35:31.928557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100% 996k/996k [00:01<00:00, 894kB/s]\n","Downloading: 100% 625/625 [00:00<00:00, 436kB/s]\n","Downloading: 100% 714M/714M [00:08<00:00, 86.7MB/s]\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(1.0325, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0321, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0217, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0093, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9910, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 320.7201843261719\n","#############    Validation Set Stats\n","Total Validation Loss = 74.26820373535156\n","  Accuracy: 0.5753\n","  Micro F1: 0.5753\n","  Macro F1: 0.5353\n","\n"," 17% 1/6 [02:19<11:39, 139.85s/it]Loss = 0.0\n","Loss = tensor(0.8467, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8592, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8570, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8634, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8647, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8633, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 279.8392333984375\n","#############    Validation Set Stats\n","Total Validation Loss = 73.3109359741211\n","  Accuracy: 0.5779\n","  Micro F1: 0.5781\n","  Macro F1: 0.5719\n","\n"," 33% 2/6 [04:39<09:19, 139.84s/it]Loss = 0.0\n","Loss = tensor(0.7544, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7522, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7601, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7451, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7481, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7450, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 242.61289978027344\n","#############    Validation Set Stats\n","Total Validation Loss = 72.74993896484375\n","  Accuracy: 0.5976\n","  Micro F1: 0.5978\n","  Macro F1: 0.5828\n","\n"," 50% 3/6 [06:59<06:59, 139.83s/it]Loss = 0.0\n","Loss = tensor(0.6578, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6483, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6456, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6458, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6398, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6418, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 208.79754638671875\n","#############    Validation Set Stats\n","Total Validation Loss = 75.46742248535156\n","  Accuracy: 0.6031\n","  Micro F1: 0.6032\n","  Macro F1: 0.5703\n","\n"," 67% 4/6 [09:19<04:39, 139.82s/it]Loss = 0.0\n","Loss = tensor(0.5747, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5580, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5558, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5595, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5653, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 180.59715270996094\n","#############    Validation Set Stats\n","Total Validation Loss = 80.43575286865234\n","  Accuracy: 0.5977\n","  Micro F1: 0.5978\n","  Macro F1: 0.5783\n","\n"," 83% 5/6 [11:39<02:19, 139.80s/it]Loss = 0.0\n","Loss = tensor(0.4814, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4906, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4930, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4933, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4933, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 159.83975219726562\n","#############    Validation Set Stats\n","Total Validation Loss = 82.57893371582031\n","  Accuracy: 0.5872\n","  Micro F1: 0.5873\n","  Macro F1: 0.5738\n","\n","100% 6/6 [13:58<00:00, 139.78s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0171, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0211, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0136, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0043, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9907, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9840, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 318.1217041015625\n","#############    Validation Set Stats\n","Total Validation Loss = 74.88927459716797\n","  Accuracy: 0.5718\n","  Micro F1: 0.5721\n","  Macro F1: 0.5322\n","\n"," 17% 1/6 [02:19<11:37, 139.44s/it]Loss = 0.0\n","Loss = tensor(0.8310, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8325, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8312, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8380, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8423, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8425, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 272.9170227050781\n","#############    Validation Set Stats\n","Total Validation Loss = 73.44099426269531\n","  Accuracy: 0.5795\n","  Micro F1: 0.5794\n","  Macro F1: 0.5707\n","\n"," 33% 2/6 [04:39<09:18, 139.52s/it]Loss = 0.0\n","Loss = tensor(0.7134, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7214, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7326, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7208, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7260, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7194, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 234.55406188964844\n","#############    Validation Set Stats\n","Total Validation Loss = 74.71024322509766\n","  Accuracy: 0.5888\n","  Micro F1: 0.5891\n","  Macro F1: 0.5807\n","\n"," 50% 3/6 [06:58<06:58, 139.58s/it]Loss = 0.0\n","Loss = tensor(0.6235, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6013, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5978, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6095, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6110, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 198.12448120117188\n","#############    Validation Set Stats\n","Total Validation Loss = 81.27840423583984\n","  Accuracy: 0.5769\n","  Micro F1: 0.5771\n","  Macro F1: 0.5554\n","\n"," 67% 4/6 [09:18<04:39, 139.61s/it]Loss = 0.0\n","Loss = tensor(0.5322, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5310, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5280, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5266, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5205, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5205, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 168.8456268310547\n","#############    Validation Set Stats\n","Total Validation Loss = 83.62147521972656\n","  Accuracy: 0.5913\n","  Micro F1: 0.5914\n","  Macro F1: 0.5777\n","\n"," 83% 5/6 [11:38<02:19, 139.68s/it]Loss = 0.0\n","Loss = tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4457, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4425, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 144.46620178222656\n","#############    Validation Set Stats\n","Total Validation Loss = 87.72368621826172\n","  Accuracy: 0.5867\n","  Micro F1: 0.5868\n","  Macro F1: 0.5705\n","\n","100% 6/6 [13:58<00:00, 139.70s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0433, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0338, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0193, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0122, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0023, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9947, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 321.2184753417969\n","#############    Validation Set Stats\n","Total Validation Loss = 74.55924987792969\n","  Accuracy: 0.5717\n","  Micro F1: 0.5717\n","  Macro F1: 0.5137\n","\n"," 17% 1/6 [02:19<11:38, 139.68s/it]Loss = 0.0\n","Loss = tensor(0.8375, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8537, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8511, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8520, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8556, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8534, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 277.0805969238281\n","#############    Validation Set Stats\n","Total Validation Loss = 72.80780029296875\n","  Accuracy: 0.5785\n","  Micro F1: 0.5783\n","  Macro F1: 0.5539\n","\n"," 33% 2/6 [04:39<09:18, 139.74s/it]Loss = 0.0\n","Loss = tensor(0.7366, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7318, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7359, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7399, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7389, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7357, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 239.89295959472656\n","#############    Validation Set Stats\n","Total Validation Loss = 72.66516876220703\n","  Accuracy: 0.6109\n","  Micro F1: 0.6107\n","  Macro F1: 0.5804\n","\n"," 50% 3/6 [06:59<06:59, 139.79s/it]Loss = 0.0\n","Loss = tensor(0.6101, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6274, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6290, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6303, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6303, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6310, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 204.71653747558594\n","#############    Validation Set Stats\n","Total Validation Loss = 76.92882537841797\n","  Accuracy: 0.6006\n","  Micro F1: 0.6003\n","  Macro F1: 0.5850\n","\n"," 67% 4/6 [09:19<04:39, 139.86s/it]Loss = 0.0\n","Loss = tensor(0.5184, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5397, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5340, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5320, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 174.1609344482422\n","#############    Validation Set Stats\n","Total Validation Loss = 79.81645202636719\n","  Accuracy: 0.6017\n","  Micro F1: 0.6015\n","  Macro F1: 0.5883\n","\n"," 83% 5/6 [11:39<02:19, 139.88s/it]Loss = 0.0\n","Loss = tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4677, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4682, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4718, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4740, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 153.0220489501953\n","#############    Validation Set Stats\n","Total Validation Loss = 82.73182678222656\n","  Accuracy: 0.6044\n","  Micro F1: 0.6042\n","  Macro F1: 0.5866\n","\n","100% 6/6 [13:59<00:00, 139.89s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0112, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0227, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0067, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9934, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9857, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9773, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 316.8418884277344\n","#############    Validation Set Stats\n","Total Validation Loss = 74.38660430908203\n","  Accuracy: 0.5822\n","  Micro F1: 0.5821\n","  Macro F1: 0.5256\n","\n"," 17% 1/6 [02:19<11:39, 139.89s/it]Loss = 0.0\n","Loss = tensor(0.8643, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8561, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8511, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8423, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8415, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8377, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 273.3671875\n","#############    Validation Set Stats\n","Total Validation Loss = 71.71771240234375\n","  Accuracy: 0.5957\n","  Micro F1: 0.5957\n","  Macro F1: 0.5459\n","\n"," 33% 2/6 [04:39<09:19, 139.89s/it]Loss = 0.0\n","Loss = tensor(0.6953, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7079, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7102, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7165, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7186, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7195, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 233.58340454101562\n","#############    Validation Set Stats\n","Total Validation Loss = 73.20014953613281\n","  Accuracy: 0.6007\n","  Micro F1: 0.6007\n","  Macro F1: 0.5828\n","\n"," 50% 3/6 [06:59<06:59, 139.92s/it]Loss = 0.0\n","Loss = tensor(0.5779, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5958, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6027, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6106, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6111, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6181, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 200.7023468017578\n","#############    Validation Set Stats\n","Total Validation Loss = 77.3843765258789\n","  Accuracy: 0.6015\n","  Micro F1: 0.6015\n","  Macro F1: 0.5806\n","\n"," 67% 4/6 [09:19<04:39, 139.94s/it]Loss = 0.0\n","Loss = tensor(0.5075, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5204, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5180, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5199, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 169.20828247070312\n","#############    Validation Set Stats\n","Total Validation Loss = 80.14303588867188\n","  Accuracy: 0.6000\n","  Micro F1: 0.5999\n","  Macro F1: 0.5845\n","\n"," 83% 5/6 [11:39<02:19, 139.95s/it]Loss = 0.0\n","Loss = tensor(0.4198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4323, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4525, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4484, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 145.40997314453125\n","#############    Validation Set Stats\n","Total Validation Loss = 83.31066131591797\n","  Accuracy: 0.6031\n","  Micro F1: 0.6030\n","  Macro F1: 0.5835\n","\n","100% 6/6 [13:59<00:00, 139.95s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0335, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0268, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0194, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0089, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9999, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9829, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 318.2396240234375\n","#############    Validation Set Stats\n","Total Validation Loss = 74.24352264404297\n","  Accuracy: 0.5730\n","  Micro F1: 0.5729\n","  Macro F1: 0.5016\n","\n"," 17% 1/6 [02:19<11:39, 139.82s/it]Loss = 0.0\n","Loss = tensor(0.8490, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8478, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8513, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8501, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8560, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8543, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 277.06292724609375\n","#############    Validation Set Stats\n","Total Validation Loss = 69.7029800415039\n","  Accuracy: 0.6155\n","  Micro F1: 0.6154\n","  Macro F1: 0.5881\n","\n"," 33% 2/6 [04:39<09:19, 139.92s/it]Loss = 0.0\n","Loss = tensor(0.7225, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7505, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7439, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7371, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7367, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7363, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 239.1625213623047\n","#############    Validation Set Stats\n","Total Validation Loss = 70.62602233886719\n","  Accuracy: 0.6105\n","  Micro F1: 0.6104\n","  Macro F1: 0.5930\n","\n"," 50% 3/6 [06:59<06:59, 139.94s/it]Loss = 0.0\n","Loss = tensor(0.6032, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6157, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6274, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6224, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6242, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6238, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 202.28311157226562\n","#############    Validation Set Stats\n","Total Validation Loss = 74.33992767333984\n","  Accuracy: 0.6179\n","  Micro F1: 0.6177\n","  Macro F1: 0.5992\n","\n"," 67% 4/6 [09:20<04:39, 139.98s/it]Loss = 0.0\n","Loss = tensor(0.5289, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5295, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5237, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5314, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5302, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 171.95272827148438\n","#############    Validation Set Stats\n","Total Validation Loss = 78.1822738647461\n","  Accuracy: 0.6085\n","  Micro F1: 0.6084\n","  Macro F1: 0.5925\n","\n"," 83% 5/6 [11:40<02:20, 140.00s/it]Loss = 0.0\n","Loss = tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4591, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4593, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4627, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4631, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 150.67564392089844\n","#############    Validation Set Stats\n","Total Validation Loss = 81.09986114501953\n","  Accuracy: 0.6001\n","  Micro F1: 0.5999\n","  Macro F1: 0.5881\n","\n","100% 6/6 [14:00<00:00, 140.02s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6012\n","  Micro F1: 0.6012\n","  Macro F1: 0.5871\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ipO7E2FkNmfi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1596293844766,"user_tz":-330,"elapsed":10210265,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"e81ede29-ee7c-4512-82c8-a8c96993eda0"},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-3 --num_labels 3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-01 12:07:23.767410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100% 996k/996k [00:00<00:00, 1.84MB/s]\n","Downloading: 100% 625/625 [00:00<00:00, 442kB/s]\n","Downloading: 100% 714M/714M [00:14<00:00, 47.7MB/s]\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(1.0281, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0184, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0102, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9852, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9747, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 315.8717041015625\n","#############    Validation Set Stats\n","Total Validation Loss = 73.03298950195312\n","  Accuracy: 0.5869\n","  Micro F1: 0.5869\n","  Macro F1: 0.5349\n","\n"," 17% 1/6 [07:49<39:09, 469.90s/it]Loss = 0.0\n","Loss = tensor(0.8431, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8359, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8358, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8395, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8368, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8311, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 269.9875793457031\n","#############    Validation Set Stats\n","Total Validation Loss = 71.67372131347656\n","  Accuracy: 0.6022\n","  Micro F1: 0.6024\n","  Macro F1: 0.5873\n","\n"," 33% 2/6 [15:47<31:28, 472.19s/it]Loss = 0.0\n","Loss = tensor(0.6890, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6987, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7012, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7042, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7054, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7064, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 229.96243286132812\n","#############    Validation Set Stats\n","Total Validation Loss = 74.61557006835938\n","  Accuracy: 0.5915\n","  Micro F1: 0.5916\n","  Macro F1: 0.5861\n","\n"," 50% 3/6 [23:34<23:32, 470.80s/it]Loss = 0.0\n","Loss = tensor(0.5795, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5838, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5944, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5847, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5924, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 192.6591339111328\n","#############    Validation Set Stats\n","Total Validation Loss = 80.22134399414062\n","  Accuracy: 0.5920\n","  Micro F1: 0.5920\n","  Macro F1: 0.5817\n","\n"," 67% 4/6 [31:23<15:40, 470.13s/it]Loss = 0.0\n","Loss = tensor(0.4646, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4773, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4823, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4908, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4910, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 159.4956512451172\n","#############    Validation Set Stats\n","Total Validation Loss = 85.32537078857422\n","  Accuracy: 0.5970\n","  Micro F1: 0.5970\n","  Macro F1: 0.5815\n","\n"," 83% 5/6 [39:11<07:49, 469.50s/it]Loss = 0.0\n","Loss = tensor(0.3936, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4082, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4172, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4129, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 134.51609802246094\n","#############    Validation Set Stats\n","Total Validation Loss = 90.76591491699219\n","  Accuracy: 0.5846\n","  Micro F1: 0.5846\n","  Macro F1: 0.5748\n","\n","100% 6/6 [47:00<00:00, 470.08s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0450, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0401, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0339, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0142, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9858, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 319.18878173828125\n","#############    Validation Set Stats\n","Total Validation Loss = 73.80500030517578\n","  Accuracy: 0.5756\n","  Micro F1: 0.5756\n","  Macro F1: 0.5555\n","\n"," 17% 1/6 [07:48<39:02, 468.43s/it]Loss = 0.0\n","Loss = tensor(0.8433, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8435, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8506, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8492, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8490, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8479, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 276.29046630859375\n","#############    Validation Set Stats\n","Total Validation Loss = 71.79804992675781\n","  Accuracy: 0.5910\n","  Micro F1: 0.5910\n","  Macro F1: 0.5743\n","\n"," 33% 2/6 [15:37<31:14, 468.75s/it]Loss = 0.0\n","Loss = tensor(0.7339, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7383, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7292, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7286, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7216, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7216, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 234.20240783691406\n","#############    Validation Set Stats\n","Total Validation Loss = 73.84111022949219\n","  Accuracy: 0.5951\n","  Micro F1: 0.5953\n","  Macro F1: 0.5746\n","\n"," 50% 3/6 [23:34<23:33, 471.20s/it]Loss = 0.0\n","Loss = tensor(0.5898, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6202, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6272, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6108, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6113, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 197.6102752685547\n","#############    Validation Set Stats\n","Total Validation Loss = 80.95024871826172\n","  Accuracy: 0.5812\n","  Micro F1: 0.5814\n","  Macro F1: 0.5709\n","\n"," 67% 4/6 [31:32<15:46, 473.18s/it]Loss = 0.0\n","Loss = tensor(0.5403, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5206, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5152, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 166.84530639648438\n","#############    Validation Set Stats\n","Total Validation Loss = 85.38458251953125\n","  Accuracy: 0.5904\n","  Micro F1: 0.5906\n","  Macro F1: 0.5602\n","\n"," 83% 5/6 [39:31<07:54, 474.77s/it]Loss = 0.0\n","Loss = tensor(0.4392, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4459, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4448, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 144.45448303222656\n","#############    Validation Set Stats\n","Total Validation Loss = 88.23404693603516\n","  Accuracy: 0.5916\n","  Micro F1: 0.5918\n","  Macro F1: 0.5723\n","\n","100% 6/6 [47:27<00:00, 474.64s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0322, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0191, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0118, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9958, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9844, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9768, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 316.72314453125\n","#############    Validation Set Stats\n","Total Validation Loss = 74.30071258544922\n","  Accuracy: 0.5697\n","  Micro F1: 0.5698\n","  Macro F1: 0.5006\n","\n"," 17% 1/6 [07:56<39:40, 476.15s/it]Loss = 0.0\n","Loss = tensor(0.8759, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8700, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8552, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8502, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8437, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8381, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 272.4971008300781\n","#############    Validation Set Stats\n","Total Validation Loss = 71.39208221435547\n","  Accuracy: 0.6010\n","  Micro F1: 0.6007\n","  Macro F1: 0.5832\n","\n"," 33% 2/6 [15:51<31:43, 475.99s/it]Loss = 0.0\n","Loss = tensor(0.7198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7201, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7211, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7154, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7164, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 231.0192108154297\n","#############    Validation Set Stats\n","Total Validation Loss = 77.85126495361328\n","  Accuracy: 0.5717\n","  Micro F1: 0.5713\n","  Macro F1: 0.5644\n","\n"," 50% 3/6 [23:45<23:46, 475.45s/it]Loss = 0.0\n","Loss = tensor(0.5657, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5829, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5800, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5829, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5859, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5872, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 191.49354553222656\n","#############    Validation Set Stats\n","Total Validation Loss = 78.88837432861328\n","  Accuracy: 0.6053\n","  Micro F1: 0.6053\n","  Macro F1: 0.5846\n","\n"," 67% 4/6 [31:30<15:44, 472.19s/it]Loss = 0.0\n","Loss = tensor(0.4751, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4808, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4896, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4936, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4986, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4969, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 161.20004272460938\n","#############    Validation Set Stats\n","Total Validation Loss = 85.25645446777344\n","  Accuracy: 0.5988\n","  Micro F1: 0.5988\n","  Macro F1: 0.5773\n","\n"," 83% 5/6 [39:16<07:50, 470.34s/it]Loss = 0.0\n","Loss = tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4186, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4209, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4183, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4113, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 134.760009765625\n","#############    Validation Set Stats\n","Total Validation Loss = 90.98611450195312\n","  Accuracy: 0.5860\n","  Micro F1: 0.5860\n","  Macro F1: 0.5708\n","\n","100% 6/6 [47:03<00:00, 470.62s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0326, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0294, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0201, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0101, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9962, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9842, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 318.5510559082031\n","#############    Validation Set Stats\n","Total Validation Loss = 72.81922912597656\n","  Accuracy: 0.5869\n","  Micro F1: 0.5868\n","  Macro F1: 0.5421\n","\n"," 17% 1/6 [07:47<38:56, 467.36s/it]Loss = 0.0\n","Loss = tensor(0.8384, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8583, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8448, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8378, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8412, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8403, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 273.0982666015625\n","#############    Validation Set Stats\n","Total Validation Loss = 71.07598114013672\n","  Accuracy: 0.5974\n","  Micro F1: 0.5972\n","  Macro F1: 0.5664\n","\n"," 33% 2/6 [15:34<31:09, 467.29s/it]Loss = 0.0\n","Loss = tensor(0.7233, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7172, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7188, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7138, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7165, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7129, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 232.05294799804688\n","#############    Validation Set Stats\n","Total Validation Loss = 73.28688049316406\n","  Accuracy: 0.6077\n","  Micro F1: 0.6077\n","  Macro F1: 0.5811\n","\n"," 50% 3/6 [23:21<23:21, 467.22s/it]Loss = 0.0\n","Loss = tensor(0.5927, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5903, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5955, device='cuda:0', grad_fn=<DivBackward0>)\n","Traceback (most recent call last):\n","  File \"bert_han_cross_val.py\", line 86, in <module>\n","    best_model, acc, micro, macro = train_v2(training_dataloader, test_dataloader, copy.deepcopy(model), epochs = args.epochs, lr2 = args.learning_rate)\n","  File \"/content/gdrive/.shortcut-targets-by-id/16d21Z770y3FtwaqfT2owsqSncD_5TXQf/Code_Switch/utils.py\", line 197, in train_v2\n","    loss.backward()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 185, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 127, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n"," 50% 3/6 [27:36<27:36, 552.28s/it]\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-b8496b599553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-3 --num_labels 3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"M3sA95g0Nnge","colab_type":"code","colab":{}},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-3 --num_labels 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWLFbeMKNoHq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ILohDJc-61P2","colab_type":"text"},"source":["## SENTIMENT 9\n"]},{"cell_type":"code","metadata":{"id":"NNA9DJJqks64","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596265264762,"user_tz":-330,"elapsed":2387034,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"5531ab57-9afb-43c2-8ca8-7c9e62814a83"},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-4 --num_labels 3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-01 05:50:46.269161: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(1.0293, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0187, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9974, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9886, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9787, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 317.146728515625\n","#############    Validation Set Stats\n","Total Validation Loss = 73.33802795410156\n","  Accuracy: 0.5768\n","  Micro F1: 0.5769\n","  Macro F1: 0.5411\n","\n"," 17% 1/6 [02:20<11:40, 140.02s/it]Loss = 0.0\n","Loss = tensor(0.8391, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8490, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8396, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8384, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8381, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8344, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 270.97235107421875\n","#############    Validation Set Stats\n","Total Validation Loss = 71.92256927490234\n","  Accuracy: 0.5941\n","  Micro F1: 0.5943\n","  Macro F1: 0.5768\n","\n"," 33% 2/6 [04:40<09:20, 140.02s/it]Loss = 0.0\n","Loss = tensor(0.7063, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7132, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7127, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7108, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7170, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7180, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 232.56649780273438\n","#############    Validation Set Stats\n","Total Validation Loss = 75.01677703857422\n","  Accuracy: 0.6030\n","  Micro F1: 0.6032\n","  Macro F1: 0.5653\n","\n"," 50% 3/6 [07:00<07:00, 140.00s/it]Loss = 0.0\n","Loss = tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5945, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6104, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6084, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6103, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 197.47959899902344\n","#############    Validation Set Stats\n","Total Validation Loss = 80.8085708618164\n","  Accuracy: 0.5923\n","  Micro F1: 0.5923\n","  Macro F1: 0.5720\n","\n"," 67% 4/6 [09:19<04:39, 139.99s/it]Loss = 0.0\n","Loss = tensor(0.5077, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5110, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5058, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5112, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5139, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 167.43031311035156\n","#############    Validation Set Stats\n","Total Validation Loss = 82.5517578125\n","  Accuracy: 0.5942\n","  Micro F1: 0.5943\n","  Macro F1: 0.5824\n","\n"," 83% 5/6 [11:39<02:19, 140.00s/it]Loss = 0.0\n","Loss = tensor(0.4661, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4561, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4533, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4543, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 147.63853454589844\n","#############    Validation Set Stats\n","Total Validation Loss = 86.25675201416016\n","  Accuracy: 0.5958\n","  Micro F1: 0.5958\n","  Macro F1: 0.5819\n","\n","100% 6/6 [13:59<00:00, 139.99s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0360, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0366, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0278, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0178, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0077, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9996, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 323.0372009277344\n","#############    Validation Set Stats\n","Total Validation Loss = 74.2925033569336\n","  Accuracy: 0.5607\n","  Micro F1: 0.5609\n","  Macro F1: 0.5173\n","\n"," 17% 1/6 [02:19<11:39, 139.93s/it]Loss = 0.0\n","Loss = tensor(0.8647, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8697, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8832, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8812, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8795, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8694, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 282.9581298828125\n","#############    Validation Set Stats\n","Total Validation Loss = 74.30643463134766\n","  Accuracy: 0.5600\n","  Micro F1: 0.5601\n","  Macro F1: 0.5577\n","\n"," 33% 2/6 [04:39<09:19, 139.97s/it]Loss = 0.0\n","Loss = tensor(0.7889, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7651, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7742, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7741, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7727, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7683, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 250.10069274902344\n","#############    Validation Set Stats\n","Total Validation Loss = 73.51414489746094\n","  Accuracy: 0.5770\n","  Micro F1: 0.5771\n","  Macro F1: 0.5671\n","\n"," 50% 3/6 [06:59<06:59, 139.97s/it]Loss = 0.0\n","Loss = tensor(0.6896, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6750, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6727, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6666, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6610, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6616, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 214.6045379638672\n","#############    Validation Set Stats\n","Total Validation Loss = 78.3815689086914\n","  Accuracy: 0.5843\n","  Micro F1: 0.5845\n","  Macro F1: 0.5740\n","\n"," 67% 4/6 [09:19<04:39, 139.97s/it]Loss = 0.0\n","Loss = tensor(0.5417, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5477, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5504, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5536, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 182.4571533203125\n","#############    Validation Set Stats\n","Total Validation Loss = 80.0941390991211\n","  Accuracy: 0.5839\n","  Micro F1: 0.5841\n","  Macro F1: 0.5661\n","\n"," 83% 5/6 [11:39<02:19, 139.98s/it]Loss = 0.0\n","Loss = tensor(0.4760, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4859, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4853, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4871, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4891, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4917, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 159.8697509765625\n","#############    Validation Set Stats\n","Total Validation Loss = 85.19905090332031\n","  Accuracy: 0.5850\n","  Micro F1: 0.5852\n","  Macro F1: 0.5709\n","\n","100% 6/6 [13:59<00:00, 140.00s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0118, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0135, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0079, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9879, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9797, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 317.6984558105469\n","#############    Validation Set Stats\n","Total Validation Loss = 75.83623504638672\n","  Accuracy: 0.5524\n","  Micro F1: 0.5524\n","  Macro F1: 0.5202\n","\n"," 17% 1/6 [02:19<11:39, 139.82s/it]Loss = 0.0\n","Loss = tensor(0.8531, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8411, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8461, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8496, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8471, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8464, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 275.2963562011719\n","#############    Validation Set Stats\n","Total Validation Loss = 75.1515121459961\n","  Accuracy: 0.5651\n","  Micro F1: 0.5651\n","  Macro F1: 0.5611\n","\n"," 33% 2/6 [04:39<09:19, 139.81s/it]Loss = 0.0\n","Loss = tensor(0.7134, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7296, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7286, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7295, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7233, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7224, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 235.3709716796875\n","#############    Validation Set Stats\n","Total Validation Loss = 73.35198211669922\n","  Accuracy: 0.5791\n","  Micro F1: 0.5790\n","  Macro F1: 0.5720\n","\n"," 50% 3/6 [06:59<06:59, 139.78s/it]Loss = 0.0\n","Loss = tensor(0.5979, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6149, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6085, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6059, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 197.14910888671875\n","#############    Validation Set Stats\n","Total Validation Loss = 77.89239501953125\n","  Accuracy: 0.5951\n","  Micro F1: 0.5949\n","  Macro F1: 0.5843\n","\n"," 67% 4/6 [09:18<04:39, 139.75s/it]Loss = 0.0\n","Loss = tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5161, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5109, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 166.3113555908203\n","#############    Validation Set Stats\n","Total Validation Loss = 81.94091796875\n","  Accuracy: 0.6035\n","  Micro F1: 0.6034\n","  Macro F1: 0.5876\n","\n"," 83% 5/6 [11:38<02:19, 139.73s/it]Loss = 0.0\n","Loss = tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4466, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4470, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4425, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 143.13294982910156\n","#############    Validation Set Stats\n","Total Validation Loss = 85.37055206298828\n","  Accuracy: 0.5990\n","  Micro F1: 0.5988\n","  Macro F1: 0.5834\n","\n","100% 6/6 [13:58<00:00, 139.72s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0333, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0231, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0103, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0001, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9968, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9848, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 318.65020751953125\n","#############    Validation Set Stats\n","Total Validation Loss = 73.52249145507812\n","  Accuracy: 0.5867\n","  Micro F1: 0.5868\n","  Macro F1: 0.5535\n","\n"," 17% 1/6 [02:19<11:37, 139.54s/it]Loss = 0.0\n","Loss = tensor(0.8334, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8488, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8645, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8575, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8578, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8556, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 276.9469909667969\n","#############    Validation Set Stats\n","Total Validation Loss = 73.00526428222656\n","  Accuracy: 0.6071\n","  Micro F1: 0.6073\n","  Macro F1: 0.5639\n","\n"," 33% 2/6 [04:39<09:18, 139.56s/it]Loss = 0.0\n","Loss = tensor(0.7368, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7411, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7446, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7436, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7417, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7361, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 239.7197723388672\n","#############    Validation Set Stats\n","Total Validation Loss = 74.1139144897461\n","  Accuracy: 0.5860\n","  Micro F1: 0.5860\n","  Macro F1: 0.5766\n","\n"," 50% 3/6 [06:58<06:58, 139.59s/it]Loss = 0.0\n","Loss = tensor(0.6162, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6317, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6380, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6369, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6331, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6256, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 203.17530822753906\n","#############    Validation Set Stats\n","Total Validation Loss = 76.31495666503906\n","  Accuracy: 0.6136\n","  Micro F1: 0.6135\n","  Macro F1: 0.5862\n","\n"," 67% 4/6 [09:18<04:39, 139.60s/it]Loss = 0.0\n","Loss = tensor(0.5396, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5252, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5278, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5313, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5385, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5367, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 173.1221923828125\n","#############    Validation Set Stats\n","Total Validation Loss = 81.04308319091797\n","  Accuracy: 0.6006\n","  Micro F1: 0.6007\n","  Macro F1: 0.5861\n","\n"," 83% 5/6 [11:38<02:19, 139.59s/it]Loss = 0.0\n","Loss = tensor(0.4470, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4585, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4619, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 149.64764404296875\n","#############    Validation Set Stats\n","Total Validation Loss = 83.41996002197266\n","  Accuracy: 0.6026\n","  Micro F1: 0.6026\n","  Macro F1: 0.5840\n","\n","100% 6/6 [13:57<00:00, 139.60s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0259, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0250, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0199, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0096, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0033, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9911, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 320.71728515625\n","#############    Validation Set Stats\n","Total Validation Loss = 73.50636291503906\n","  Accuracy: 0.5744\n","  Micro F1: 0.5744\n","  Macro F1: 0.5454\n","\n"," 17% 1/6 [02:19<11:37, 139.53s/it]Loss = 0.0\n","Loss = tensor(0.8292, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8553, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8550, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8552, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8562, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8544, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 276.8732604980469\n","#############    Validation Set Stats\n","Total Validation Loss = 71.14208984375\n","  Accuracy: 0.6008\n","  Micro F1: 0.6007\n","  Macro F1: 0.5800\n","\n"," 33% 2/6 [04:39<09:18, 139.55s/it]Loss = 0.0\n","Loss = tensor(0.6996, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7327, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7374, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7452, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7433, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7367, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 240.62106323242188\n","#############    Validation Set Stats\n","Total Validation Loss = 71.06056213378906\n","  Accuracy: 0.6118\n","  Micro F1: 0.6115\n","  Macro F1: 0.5897\n","\n"," 50% 3/6 [06:58<06:58, 139.60s/it]Loss = 0.0\n","Loss = tensor(0.6080, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6241, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6197, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6223, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6224, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6249, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 203.05441284179688\n","#############    Validation Set Stats\n","Total Validation Loss = 74.38087463378906\n","  Accuracy: 0.6113\n","  Micro F1: 0.6111\n","  Macro F1: 0.5958\n","\n"," 67% 4/6 [09:18<04:39, 139.63s/it]Loss = 0.0\n","Loss = tensor(0.5271, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5238, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5311, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5401, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5326, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5321, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 171.99685668945312\n","#############    Validation Set Stats\n","Total Validation Loss = 79.77558898925781\n","  Accuracy: 0.6036\n","  Micro F1: 0.6034\n","  Macro F1: 0.5872\n","\n"," 83% 5/6 [11:38<02:19, 139.64s/it]Loss = 0.0\n","Loss = tensor(0.4787, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4698, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4661, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4665, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4582, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 148.42562866210938\n","#############    Validation Set Stats\n","Total Validation Loss = 82.37185668945312\n","  Accuracy: 0.5994\n","  Micro F1: 0.5991\n","  Macro F1: 0.5810\n","\n","100% 6/6 [13:57<00:00, 139.62s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6014\n","  Micro F1: 0.6013\n","  Macro F1: 0.5852\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uSvh03EANy4T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596321530192,"user_tz":-330,"elapsed":11607930,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"3967f7b8-dde5-4515-a777-858da56a84d2"},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-4 --num_labels 3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-01 18:34:56.866337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100% 996k/996k [00:00<00:00, 12.3MB/s]\n","Downloading: 100% 625/625 [00:00<00:00, 637kB/s]\n","Downloading: 100% 714M/714M [00:45<00:00, 15.8MB/s]\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(1.0382, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0210, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0118, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9991, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9918, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9822, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 317.313232421875\n","#############    Validation Set Stats\n","Total Validation Loss = 73.32585906982422\n","  Accuracy: 0.5918\n","  Micro F1: 0.5920\n","  Macro F1: 0.5540\n","\n"," 17% 1/6 [08:03<40:16, 483.29s/it]Loss = 0.0\n","Loss = tensor(0.8185, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8248, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8224, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8290, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8298, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8298, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 270.31500244140625\n","#############    Validation Set Stats\n","Total Validation Loss = 71.82588195800781\n","  Accuracy: 0.5899\n","  Micro F1: 0.5900\n","  Macro F1: 0.5847\n","\n"," 33% 2/6 [16:06<32:13, 483.41s/it]Loss = 0.0\n","Loss = tensor(0.7259, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7283, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7188, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7196, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7163, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7154, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 231.8617401123047\n","#############    Validation Set Stats\n","Total Validation Loss = 74.06306457519531\n","  Accuracy: 0.6112\n","  Micro F1: 0.6113\n","  Macro F1: 0.5881\n","\n"," 50% 3/6 [24:12<24:12, 484.17s/it]Loss = 0.0\n","Loss = tensor(0.5821, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5933, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6035, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6015, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5964, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5990, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 194.8642578125\n","#############    Validation Set Stats\n","Total Validation Loss = 77.15804290771484\n","  Accuracy: 0.6024\n","  Micro F1: 0.6024\n","  Macro F1: 0.5857\n","\n"," 67% 4/6 [32:19<16:09, 484.76s/it]Loss = 0.0\n","Loss = tensor(0.5371, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5198, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5039, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 162.08802795410156\n","#############    Validation Set Stats\n","Total Validation Loss = 84.0470199584961\n","  Accuracy: 0.5981\n","  Micro F1: 0.5981\n","  Macro F1: 0.5905\n","\n"," 83% 5/6 [40:25<08:05, 485.18s/it]Loss = 0.0\n","Loss = tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4223, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4190, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4211, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 136.04840087890625\n","#############    Validation Set Stats\n","Total Validation Loss = 88.33006286621094\n","  Accuracy: 0.5939\n","  Micro F1: 0.5939\n","  Macro F1: 0.5843\n","\n","100% 6/6 [48:30<00:00, 485.14s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0378, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0244, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0083, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9980, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9884, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9783, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 316.5652160644531\n","#############    Validation Set Stats\n","Total Validation Loss = 72.93113708496094\n","  Accuracy: 0.5694\n","  Micro F1: 0.5694\n","  Macro F1: 0.5432\n","\n"," 17% 1/6 [08:05<40:26, 485.24s/it]Loss = 0.0\n","Loss = tensor(0.8582, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8521, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8507, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8434, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8412, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8429, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 273.670654296875\n","#############    Validation Set Stats\n","Total Validation Loss = 71.83779907226562\n","  Accuracy: 0.6090\n","  Micro F1: 0.6092\n","  Macro F1: 0.5842\n","\n"," 33% 2/6 [16:11<32:22, 485.55s/it]Loss = 0.0\n","Loss = tensor(0.7085, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7233, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7215, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7125, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7107, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7113, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 231.50933837890625\n","#############    Validation Set Stats\n","Total Validation Loss = 75.66033935546875\n","  Accuracy: 0.5955\n","  Micro F1: 0.5957\n","  Macro F1: 0.5797\n","\n"," 50% 3/6 [24:17<24:17, 485.73s/it]Loss = 0.0\n","Loss = tensor(0.6245, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6099, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6071, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5994, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5905, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5961, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 193.86692810058594\n","#############    Validation Set Stats\n","Total Validation Loss = 80.48412322998047\n","  Accuracy: 0.5834\n","  Micro F1: 0.5833\n","  Macro F1: 0.5687\n","\n"," 67% 4/6 [32:23<16:11, 485.89s/it]Loss = 0.0\n","Loss = tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4942, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4921, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4926, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 160.99972534179688\n","#############    Validation Set Stats\n","Total Validation Loss = 84.56367492675781\n","  Accuracy: 0.5821\n","  Micro F1: 0.5821\n","  Macro F1: 0.5640\n","\n"," 83% 5/6 [40:28<08:05, 485.48s/it]Loss = 0.0\n","Loss = tensor(0.4070, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4258, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4214, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4226, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 137.1092529296875\n","#############    Validation Set Stats\n","Total Validation Loss = 91.18724060058594\n","  Accuracy: 0.5890\n","  Micro F1: 0.5891\n","  Macro F1: 0.5759\n","\n","100% 6/6 [48:33<00:00, 485.61s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0345, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0288, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0185, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0027, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9895, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9807, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 317.6674499511719\n","#############    Validation Set Stats\n","Total Validation Loss = 75.40178680419922\n","  Accuracy: 0.5686\n","  Micro F1: 0.5686\n","  Macro F1: 0.5441\n","\n"," 17% 1/6 [08:04<40:21, 484.33s/it]Loss = 0.0\n","Loss = tensor(0.8802, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8749, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8633, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8620, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8528, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8495, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 275.42498779296875\n","#############    Validation Set Stats\n","Total Validation Loss = 72.1830062866211\n","  Accuracy: 0.5979\n","  Micro F1: 0.5980\n","  Macro F1: 0.5684\n","\n"," 33% 2/6 [16:10<32:19, 484.96s/it]Loss = 0.0\n","Loss = tensor(0.7241, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7200, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7265, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7241, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7268, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7259, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 236.48385620117188\n","#############    Validation Set Stats\n","Total Validation Loss = 72.86914825439453\n","  Accuracy: 0.6103\n","  Micro F1: 0.6104\n","  Macro F1: 0.5895\n","\n"," 50% 3/6 [24:17<24:16, 485.46s/it]Loss = 0.0\n","Loss = tensor(0.5635, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5959, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6005, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6013, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6114, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6114, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 199.6367950439453\n","#############    Validation Set Stats\n","Total Validation Loss = 79.4013442993164\n","  Accuracy: 0.6061\n","  Micro F1: 0.6061\n","  Macro F1: 0.5793\n","\n"," 67% 4/6 [32:23<16:11, 485.67s/it]Loss = 0.0\n","Loss = tensor(0.5221, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5199, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5084, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5111, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 166.5042724609375\n","#############    Validation Set Stats\n","Total Validation Loss = 84.98336791992188\n","  Accuracy: 0.5936\n","  Micro F1: 0.5937\n","  Macro F1: 0.5784\n","\n"," 83% 5/6 [40:27<08:05, 485.15s/it]Loss = 0.0\n","Loss = tensor(0.4727, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4560, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4459, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4389, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4376, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4421, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 143.7841339111328\n","#############    Validation Set Stats\n","Total Validation Loss = 88.67601776123047\n","  Accuracy: 0.5983\n","  Micro F1: 0.5984\n","  Macro F1: 0.5822\n","\n","100% 6/6 [48:31<00:00, 485.24s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0426, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0471, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0349, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0218, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0054, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9937, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 321.7283630371094\n","#############    Validation Set Stats\n","Total Validation Loss = 74.43484497070312\n","  Accuracy: 0.5657\n","  Micro F1: 0.5655\n","  Macro F1: 0.4854\n","\n"," 17% 1/6 [08:03<40:18, 483.77s/it]Loss = 0.0\n","Loss = tensor(0.8591, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8609, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8514, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8519, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8525, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8516, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 275.49078369140625\n","#############    Validation Set Stats\n","Total Validation Loss = 73.84165954589844\n","  Accuracy: 0.5777\n","  Micro F1: 0.5775\n","  Macro F1: 0.5653\n","\n"," 33% 2/6 [16:09<32:17, 484.26s/it]Loss = 0.0\n","Loss = tensor(0.7131, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7416, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7336, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7274, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7207, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7165, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 232.97093200683594\n","#############    Validation Set Stats\n","Total Validation Loss = 73.10997009277344\n","  Accuracy: 0.5985\n","  Micro F1: 0.5984\n","  Macro F1: 0.5857\n","\n"," 50% 3/6 [24:14<24:13, 484.56s/it]Loss = 0.0\n","Loss = tensor(0.5844, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6050, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6177, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6157, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6113, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6094, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 198.281005859375\n","#############    Validation Set Stats\n","Total Validation Loss = 79.31352233886719\n","  Accuracy: 0.5923\n","  Micro F1: 0.5922\n","  Macro F1: 0.5800\n","\n"," 67% 4/6 [32:18<16:08, 484.29s/it]Loss = 0.0\n","Loss = tensor(0.5167, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5153, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5174, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5245, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5203, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 166.67520141601562\n","#############    Validation Set Stats\n","Total Validation Loss = 83.95420837402344\n","  Accuracy: 0.6065\n","  Micro F1: 0.6065\n","  Macro F1: 0.5835\n","\n"," 83% 5/6 [40:22<08:04, 484.38s/it]Loss = 0.0\n","Loss = tensor(0.4551, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4506, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4529, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4457, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4461, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 145.3227996826172\n","#############    Validation Set Stats\n","Total Validation Loss = 87.25654602050781\n","  Accuracy: 0.5891\n","  Micro F1: 0.5891\n","  Macro F1: 0.5742\n","\n","100% 6/6 [48:28<00:00, 484.72s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0348, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0336, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0287, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0156, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0026, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9989, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 323.10284423828125\n","#############    Validation Set Stats\n","Total Validation Loss = 74.32454681396484\n","  Accuracy: 0.5741\n","  Micro F1: 0.5740\n","  Macro F1: 0.5225\n","\n"," 17% 1/6 [08:05<40:26, 485.20s/it]Loss = 0.0\n","Loss = tensor(0.8787, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8719, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8660, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8680, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8627, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8640, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 280.99853515625\n","#############    Validation Set Stats\n","Total Validation Loss = 72.253662109375\n","  Accuracy: 0.5780\n","  Micro F1: 0.5779\n","  Macro F1: 0.5693\n","\n"," 33% 2/6 [16:10<32:20, 485.24s/it]Loss = 0.0\n","Loss = tensor(0.7443, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7460, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7453, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7466, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7497, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7510, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 243.12916564941406\n","#############    Validation Set Stats\n","Total Validation Loss = 71.89998626708984\n","  Accuracy: 0.6086\n","  Micro F1: 0.6084\n","  Macro F1: 0.5959\n","\n"," 50% 3/6 [24:13<24:14, 484.70s/it]Loss = 0.0\n","Loss = tensor(0.6295, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6254, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6261, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6346, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6373, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6348, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 206.18319702148438\n","#############    Validation Set Stats\n","Total Validation Loss = 76.1542739868164\n","  Accuracy: 0.6008\n","  Micro F1: 0.6007\n","  Macro F1: 0.5860\n","\n"," 67% 4/6 [32:18<16:09, 484.69s/it]Loss = 0.0\n","Loss = tensor(0.5409, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5449, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5398, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5407, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5412, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5353, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 174.51649475097656\n","#############    Validation Set Stats\n","Total Validation Loss = 80.87432861328125\n","  Accuracy: 0.6082\n","  Micro F1: 0.6080\n","  Macro F1: 0.5853\n","\n"," 83% 5/6 [40:23<08:04, 484.63s/it]Loss = 0.0\n","Loss = tensor(0.4691, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4609, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4698, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4650, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4701, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4679, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 152.3348846435547\n","#############    Validation Set Stats\n","Total Validation Loss = 83.56704711914062\n","  Accuracy: 0.6020\n","  Micro F1: 0.6019\n","  Macro F1: 0.5864\n","\n","100% 6/6 [48:27<00:00, 484.53s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6049\n","  Micro F1: 0.6049\n","  Macro F1: 0.5892\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TpQ4yUegNzvX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c4b86fd9-d238-47e1-e493-3b004e3f486d"},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-4 --num_labels 3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-01 22:38:56.746265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(1.0397, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0217, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0085, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9977, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9844, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9709, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 314.2978820800781\n","#############    Validation Set Stats\n","Total Validation Loss = 74.81474304199219\n","  Accuracy: 0.5680\n","  Micro F1: 0.5680\n","  Macro F1: 0.5282\n","\n"," 17% 1/6 [08:12<41:01, 492.36s/it]Loss = 0.0\n","Loss = tensor(0.8063, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8415, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8453, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8377, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8374, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8332, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 271.4236755371094\n","#############    Validation Set Stats\n","Total Validation Loss = 73.62838745117188\n","  Accuracy: 0.5841\n","  Micro F1: 0.5842\n","  Macro F1: 0.5710\n","\n"," 33% 2/6 [16:21<32:45, 491.45s/it]Loss = 0.0\n","Loss = tensor(0.6991, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6954, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7023, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7034, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7069, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7059, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 229.22598266601562\n","#############    Validation Set Stats\n","Total Validation Loss = 75.56552124023438\n","  Accuracy: 0.6128\n","  Micro F1: 0.6128\n","  Macro F1: 0.5856\n","\n"," 50% 3/6 [24:32<24:33, 491.27s/it]Loss = 0.0\n","Loss = tensor(0.5555, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5823, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5762, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5814, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5873, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 190.41000366210938\n","#############    Validation Set Stats\n","Total Validation Loss = 80.38548278808594\n","  Accuracy: 0.5930\n","  Micro F1: 0.5931\n","  Macro F1: 0.5769\n","\n"," 67% 4/6 [32:43<16:22, 491.07s/it]Loss = 0.0\n","Loss = tensor(0.4950, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4829, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4868, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4880, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 157.80792236328125\n","#############    Validation Set Stats\n","Total Validation Loss = 88.9529037475586\n","  Accuracy: 0.5970\n","  Micro F1: 0.5970\n","  Macro F1: 0.5753\n","\n"," 83% 5/6 [40:54<08:11, 491.27s/it]Loss = 0.0\n","Loss = tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4052, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4184, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4196, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 135.915771484375\n","#############    Validation Set Stats\n","Total Validation Loss = 92.01154327392578\n","  Accuracy: 0.5881\n","  Micro F1: 0.5881\n","  Macro F1: 0.5731\n","\n","100% 6/6 [49:07<00:00, 491.21s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0457, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0405, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0268, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0147, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9931, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 320.1420593261719\n","#############    Validation Set Stats\n","Total Validation Loss = 73.60342407226562\n","  Accuracy: 0.5731\n","  Micro F1: 0.5733\n","  Macro F1: 0.5434\n","\n"," 17% 1/6 [08:11<40:58, 491.74s/it]Loss = 0.0\n","Loss = tensor(0.8303, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8497, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8467, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8483, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8491, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8485, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 275.39654541015625\n","#############    Validation Set Stats\n","Total Validation Loss = 71.94342041015625\n","  Accuracy: 0.6038\n","  Micro F1: 0.6038\n","  Macro F1: 0.5779\n","\n"," 33% 2/6 [16:23<32:47, 491.76s/it]Loss = 0.0\n","Loss = tensor(0.7445, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7237, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7215, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7200, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7202, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7155, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 233.14053344726562\n","#############    Validation Set Stats\n","Total Validation Loss = 73.34447479248047\n","  Accuracy: 0.6001\n","  Micro F1: 0.5999\n","  Macro F1: 0.5833\n","\n"," 50% 3/6 [24:35<24:35, 491.93s/it]Loss = 0.0\n","Loss = tensor(0.6030, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5920, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5929, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5971, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6026, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6003, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 195.14540100097656\n","#############    Validation Set Stats\n","Total Validation Loss = 83.99305725097656\n","  Accuracy: 0.5852\n","  Micro F1: 0.5852\n","  Macro F1: 0.5661\n","\n"," 67% 4/6 [32:48<16:24, 492.02s/it]Loss = 0.0\n","Loss = tensor(0.4711, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4826, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4891, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4857, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4870, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 158.74766540527344\n","#############    Validation Set Stats\n","Total Validation Loss = 88.94230651855469\n","  Accuracy: 0.5826\n","  Micro F1: 0.5825\n","  Macro F1: 0.5664\n","\n"," 83% 5/6 [41:00<08:12, 492.12s/it]Loss = 0.0\n","Loss = tensor(0.4244, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4191, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 136.7427978515625\n","#############    Validation Set Stats\n","Total Validation Loss = 93.29237365722656\n","  Accuracy: 0.5821\n","  Micro F1: 0.5821\n","  Macro F1: 0.5663\n","\n","100% 6/6 [49:12<00:00, 492.04s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0343, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0224, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0135, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0012, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9902, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9772, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 315.62115478515625\n","#############    Validation Set Stats\n","Total Validation Loss = 74.55265045166016\n","  Accuracy: 0.5598\n","  Micro F1: 0.5597\n","  Macro F1: 0.5485\n","\n"," 17% 1/6 [08:09<40:47, 489.44s/it]Loss = 0.0\n","Loss = tensor(0.8383, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8355, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8479, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8487, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8416, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8379, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 271.77264404296875\n","#############    Validation Set Stats\n","Total Validation Loss = 74.57569122314453\n","  Accuracy: 0.5939\n","  Micro F1: 0.5937\n","  Macro F1: 0.5674\n","\n"," 33% 2/6 [16:19<32:39, 489.75s/it]Loss = 0.0\n","Loss = tensor(0.6945, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7107, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7090, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7156, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7144, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7150, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 231.60560607910156\n","#############    Validation Set Stats\n","Total Validation Loss = 75.7030258178711\n","  Accuracy: 0.6035\n","  Micro F1: 0.6034\n","  Macro F1: 0.5792\n","\n"," 50% 3/6 [24:29<24:29, 489.76s/it]Loss = 0.0\n","Loss = tensor(0.5763, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5780, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5849, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5833, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5878, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5915, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 193.015380859375\n","#############    Validation Set Stats\n","Total Validation Loss = 79.14053344726562\n","  Accuracy: 0.5981\n","  Micro F1: 0.5980\n","  Macro F1: 0.5869\n","\n"," 67% 4/6 [32:40<16:20, 490.06s/it]Loss = 0.0\n","Loss = tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5165, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5053, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5061, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5020, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4976, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 161.1298370361328\n","#############    Validation Set Stats\n","Total Validation Loss = 87.2893295288086\n","  Accuracy: 0.6043\n","  Micro F1: 0.6042\n","  Macro F1: 0.5880\n","\n"," 83% 5/6 [40:51<08:10, 490.30s/it]Loss = 0.0\n","Loss = tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4406, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4416, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4360, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4333, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4295, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 138.8323211669922\n","#############    Validation Set Stats\n","Total Validation Loss = 91.94937896728516\n","  Accuracy: 0.6008\n","  Micro F1: 0.6007\n","  Macro F1: 0.5839\n","\n","100% 6/6 [49:01<00:00, 490.17s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0372, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0263, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0135, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0012, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9876, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9777, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 315.4763488769531\n","#############    Validation Set Stats\n","Total Validation Loss = 74.15219116210938\n","  Accuracy: 0.5795\n","  Micro F1: 0.5794\n","  Macro F1: 0.5344\n","\n"," 17% 1/6 [08:12<41:01, 492.25s/it]Loss = 0.0\n","Loss = tensor(0.8235, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8305, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8282, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8327, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8330, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8269, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 268.6620178222656\n","#############    Validation Set Stats\n","Total Validation Loss = 70.80308532714844\n","  Accuracy: 0.6015\n","  Micro F1: 0.6015\n","  Macro F1: 0.5781\n","\n"," 33% 2/6 [16:22<32:47, 491.77s/it]Loss = 0.0\n","Loss = tensor(0.6757, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.6920, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7007, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7078, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7092, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.7051, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 228.5322265625\n","#############    Validation Set Stats\n","Total Validation Loss = 73.17486572265625\n","  Accuracy: 0.6011\n","  Micro F1: 0.6011\n","  Macro F1: 0.5797\n","\n"," 50% 3/6 [24:34<24:34, 491.65s/it]Loss = 0.0\n","Loss = tensor(0.5627, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5715, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5845, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5768, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.5816, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 189.03199768066406\n","#############    Validation Set Stats\n","Total Validation Loss = 77.8118896484375\n","  Accuracy: 0.6018\n","  Micro F1: 0.6019\n","  Macro F1: 0.5787\n","\n"," 67% 4/6 [32:46<16:23, 491.73s/it]Loss = 0.0\n","Loss = tensor(0.4635, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4706, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4728, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4729, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4772, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4799, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 155.7848358154297\n","#############    Validation Set Stats\n","Total Validation Loss = 84.73088073730469\n","  Accuracy: 0.5916\n","  Micro F1: 0.5914\n","  Macro F1: 0.5733\n","\n"," 83% 5/6 [40:58<08:11, 491.83s/it]Loss = 0.0\n","Loss = tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4120, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4086, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4023, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 131.52162170410156\n","#############    Validation Set Stats\n","Total Validation Loss = 92.66830444335938\n","  Accuracy: 0.5896\n","  Micro F1: 0.5895\n","  Macro F1: 0.5714\n","\n","100% 6/6 [49:10<00:00, 491.69s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(1.0403, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0344, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0208, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(1.0086, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9959, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.9875, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 319.81292724609375\n","#############    Validation Set Stats\n","Total Validation Loss = 73.03842163085938\n","  Accuracy: 0.5888\n","  Micro F1: 0.5887\n","  Macro F1: 0.5684\n","\n"," 17% 1/6 [08:11<40:59, 491.90s/it]Loss = 0.0\n","Loss = tensor(0.8452, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8476, device='cuda:0', grad_fn=<DivBackward0>)\n","Loss = tensor(0.8520, device='cuda:0', grad_fn=<DivBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NGMckR71N0fX","colab_type":"code","colab":{}},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-3 --num_labels 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNi2sdhrN1Zy","colab_type":"code","colab":{}},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-3 --num_labels 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MAxuqc-2N20r","colab_type":"code","colab":{}},"source":["!python bert_han_cross_val.py -f Datasets/Sentiment/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-3 --num_labels 3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cZPQqAOYw4f_","colab_type":"text"},"source":["## HATE 22"]},{"cell_type":"code","metadata":{"id":"JJZNBPBQN6sn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596350736194,"user_tz":-330,"elapsed":2359320,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"9a012685-60b9-4583-b050-a125dec9f285"},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-4 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-02 06:06:30.562850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100% 996k/996k [00:00<00:00, 2.62MB/s]\n","Downloading: 100% 625/625 [00:00<00:00, 537kB/s]\n","Downloading: 100% 714M/714M [01:22<00:00, 8.61MB/s]\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6436, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.690155029296875\n","#############    Validation Set Stats\n","Total Validation Loss = 13.685133934020996\n","  Accuracy: 0.6847\n","  Micro F1: 0.6895\n","  Macro F1: 0.5777\n","\n"," 17% 1/6 [01:10<05:52, 70.45s/it]Loss = 0.0\n","Loss = tensor(0.5937, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.133968353271484\n","#############    Validation Set Stats\n","Total Validation Loss = 13.524555206298828\n","  Accuracy: 0.6753\n","  Micro F1: 0.6837\n","  Macro F1: 0.5877\n","\n"," 33% 2/6 [02:25<04:47, 71.77s/it]Loss = 0.0\n","Loss = tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.56751251220703\n","#############    Validation Set Stats\n","Total Validation Loss = 14.340886116027832\n","  Accuracy: 0.6353\n","  Micro F1: 0.6370\n","  Macro F1: 0.6191\n","\n"," 50% 3/6 [03:40<03:37, 72.66s/it]Loss = 0.0\n","Loss = tensor(0.5184, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.45903778076172\n","#############    Validation Set Stats\n","Total Validation Loss = 14.759408950805664\n","  Accuracy: 0.6536\n","  Micro F1: 0.6633\n","  Macro F1: 0.6194\n","\n"," 67% 4/6 [04:54<02:26, 73.32s/it]Loss = 0.0\n","Loss = tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.610313415527344\n","#############    Validation Set Stats\n","Total Validation Loss = 15.593955039978027\n","  Accuracy: 0.6536\n","  Micro F1: 0.6633\n","  Macro F1: 0.6159\n","\n"," 83% 5/6 [06:09<01:13, 73.65s/it]Loss = 0.0\n","Loss = tensor(0.3786, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.38057327270508\n","#############    Validation Set Stats\n","Total Validation Loss = 16.232229232788086\n","  Accuracy: 0.6437\n","  Micro F1: 0.6531\n","  Macro F1: 0.6141\n","\n","100% 6/6 [07:23<00:00, 73.99s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6487, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.19875717163086\n","#############    Validation Set Stats\n","Total Validation Loss = 13.670439720153809\n","  Accuracy: 0.6843\n","  Micro F1: 0.6778\n","  Macro F1: 0.5618\n","\n"," 17% 1/6 [01:14<06:11, 74.29s/it]Loss = 0.0\n","Loss = tensor(0.6045, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.78928756713867\n","#############    Validation Set Stats\n","Total Validation Loss = 13.940738677978516\n","  Accuracy: 0.6729\n","  Micro F1: 0.6662\n","  Macro F1: 0.5583\n","\n"," 33% 2/6 [02:28<04:57, 74.36s/it]Loss = 0.0\n","Loss = tensor(0.5646, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 50.23606491088867\n","#############    Validation Set Stats\n","Total Validation Loss = 14.066709518432617\n","  Accuracy: 0.6601\n","  Micro F1: 0.6531\n","  Macro F1: 0.6274\n","\n"," 50% 3/6 [03:43<03:43, 74.48s/it]Loss = 0.0\n","Loss = tensor(0.5388, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.35482406616211\n","#############    Validation Set Stats\n","Total Validation Loss = 13.961186408996582\n","  Accuracy: 0.6804\n","  Micro F1: 0.6720\n","  Macro F1: 0.5988\n","\n"," 67% 4/6 [04:58<02:29, 74.55s/it]Loss = 0.0\n","Loss = tensor(0.4616, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.25174331665039\n","#############    Validation Set Stats\n","Total Validation Loss = 14.359766960144043\n","  Accuracy: 0.6772\n","  Micro F1: 0.6706\n","  Macro F1: 0.6228\n","\n"," 83% 5/6 [06:12<01:14, 74.59s/it]Loss = 0.0\n","Loss = tensor(0.4206, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.8907585144043\n","#############    Validation Set Stats\n","Total Validation Loss = 14.80370044708252\n","  Accuracy: 0.6814\n","  Micro F1: 0.6749\n","  Macro F1: 0.6373\n","\n","100% 6/6 [07:27<00:00, 74.61s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6536, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.9145622253418\n","#############    Validation Set Stats\n","Total Validation Loss = 13.537372589111328\n","  Accuracy: 0.6887\n","  Micro F1: 0.6880\n","  Macro F1: 0.5800\n","\n"," 17% 1/6 [01:14<06:11, 74.29s/it]Loss = 0.0\n","Loss = tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.34071731567383\n","#############    Validation Set Stats\n","Total Validation Loss = 13.502662658691406\n","  Accuracy: 0.6920\n","  Micro F1: 0.6895\n","  Macro F1: 0.5669\n","\n"," 33% 2/6 [02:28<04:57, 74.35s/it]Loss = 0.0\n","Loss = tensor(0.5790, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.81739807128906\n","#############    Validation Set Stats\n","Total Validation Loss = 13.345734596252441\n","  Accuracy: 0.6796\n","  Micro F1: 0.6749\n","  Macro F1: 0.5852\n","\n"," 50% 3/6 [03:43<03:43, 74.41s/it]Loss = 0.0\n","Loss = tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.92914962768555\n","#############    Validation Set Stats\n","Total Validation Loss = 14.189358711242676\n","  Accuracy: 0.6483\n","  Micro F1: 0.6429\n","  Macro F1: 0.6023\n","\n"," 67% 4/6 [04:57<02:28, 74.45s/it]Loss = 0.0\n","Loss = tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.04716491699219\n","#############    Validation Set Stats\n","Total Validation Loss = 14.950563430786133\n","  Accuracy: 0.6234\n","  Micro F1: 0.6210\n","  Macro F1: 0.5998\n","\n"," 83% 5/6 [06:12<01:14, 74.48s/it]Loss = 0.0\n","Loss = tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.39607238769531\n","#############    Validation Set Stats\n","Total Validation Loss = 15.136695861816406\n","  Accuracy: 0.6483\n","  Micro F1: 0.6429\n","  Macro F1: 0.6100\n","\n","100% 6/6 [07:26<00:00, 74.49s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6388, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.259300231933594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.704496383666992\n","  Accuracy: 0.6955\n","  Micro F1: 0.6934\n","  Macro F1: 0.5924\n","\n"," 17% 1/6 [01:14<06:10, 74.13s/it]Loss = 0.0\n","Loss = tensor(0.6003, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.82707595825195\n","#############    Validation Set Stats\n","Total Validation Loss = 13.207789421081543\n","  Accuracy: 0.6955\n","  Micro F1: 0.6934\n","  Macro F1: 0.6164\n","\n"," 33% 2/6 [02:28<04:56, 74.21s/it]Loss = 0.0\n","Loss = tensor(0.5585, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.937129974365234\n","#############    Validation Set Stats\n","Total Validation Loss = 12.948197364807129\n","  Accuracy: 0.7182\n","  Micro F1: 0.7168\n","  Macro F1: 0.6544\n","\n"," 50% 3/6 [03:43<03:42, 74.29s/it]Loss = 0.0\n","Loss = tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.159950256347656\n","#############    Validation Set Stats\n","Total Validation Loss = 13.675911903381348\n","  Accuracy: 0.6685\n","  Micro F1: 0.6657\n","  Macro F1: 0.6265\n","\n"," 67% 4/6 [04:57<02:28, 74.40s/it]Loss = 0.0\n","Loss = tensor(0.4406, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.36967468261719\n","#############    Validation Set Stats\n","Total Validation Loss = 14.71829891204834\n","  Accuracy: 0.6685\n","  Micro F1: 0.6657\n","  Macro F1: 0.6378\n","\n"," 83% 5/6 [06:12<01:14, 74.48s/it]Loss = 0.0\n","Loss = tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.305946350097656\n","#############    Validation Set Stats\n","Total Validation Loss = 15.091313362121582\n","  Accuracy: 0.6827\n","  Micro F1: 0.6803\n","  Macro F1: 0.6372\n","\n","100% 6/6 [07:27<00:00, 74.51s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6429, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.71573257446289\n","#############    Validation Set Stats\n","Total Validation Loss = 13.75051212310791\n","  Accuracy: 0.6749\n","  Micro F1: 0.6745\n","  Macro F1: 0.5403\n","\n"," 17% 1/6 [01:14<06:12, 74.47s/it]Loss = 0.0\n","Loss = tensor(0.5823, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.48556900024414\n","#############    Validation Set Stats\n","Total Validation Loss = 13.579183578491211\n","  Accuracy: 0.6792\n","  Micro F1: 0.6788\n","  Macro F1: 0.5283\n","\n"," 33% 2/6 [02:29<04:58, 74.55s/it]Loss = 0.0\n","Loss = tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.56291198730469\n","#############    Validation Set Stats\n","Total Validation Loss = 14.15229320526123\n","  Accuracy: 0.6749\n","  Micro F1: 0.6745\n","  Macro F1: 0.5424\n","\n"," 50% 3/6 [03:43<03:43, 74.62s/it]Loss = 0.0\n","Loss = tensor(0.5065, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.488224029541016\n","#############    Validation Set Stats\n","Total Validation Loss = 14.798169136047363\n","  Accuracy: 0.6558\n","  Micro F1: 0.6569\n","  Macro F1: 0.6107\n","\n"," 67% 4/6 [04:58<02:29, 74.58s/it]Loss = 0.0\n","Loss = tensor(0.4325, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.66872787475586\n","#############    Validation Set Stats\n","Total Validation Loss = 15.840755462646484\n","  Accuracy: 0.6473\n","  Micro F1: 0.6482\n","  Macro F1: 0.5961\n","\n"," 83% 5/6 [06:13<01:14, 74.58s/it]Loss = 0.0\n","Loss = tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.80261993408203\n","#############    Validation Set Stats\n","Total Validation Loss = 16.157108306884766\n","  Accuracy: 0.6558\n","  Micro F1: 0.6569\n","  Macro F1: 0.6213\n","\n","100% 6/6 [07:27<00:00, 74.64s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6715\n","  Micro F1: 0.6710\n","  Macro F1: 0.6285\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kDJyvyNlxizc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596353003075,"user_tz":-330,"elapsed":328799,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"89d4fdd0-9989-43b7-b0fd-2a446b86b953"},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-4 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-02 06:45:38.703362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6453, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.339622497558594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.543801307678223\n","  Accuracy: 0.6889\n","  Micro F1: 0.6939\n","  Macro F1: 0.5828\n","\n"," 17% 1/6 [01:15<06:16, 75.30s/it]Loss = 0.0\n","Loss = tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.7987174987793\n","#############    Validation Set Stats\n","Total Validation Loss = 13.267304420471191\n","  Accuracy: 0.6993\n","  Micro F1: 0.7026\n","  Macro F1: 0.5861\n","\n"," 33% 2/6 [02:30<05:00, 75.20s/it]Loss = 0.0\n","Loss = tensor(0.5461, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.154293060302734\n","#############    Validation Set Stats\n","Total Validation Loss = 13.340502738952637\n","  Accuracy: 0.6761\n","  Micro F1: 0.6808\n","  Macro F1: 0.6350\n","\n"," 50% 3/6 [03:45<03:45, 75.17s/it]Loss = 0.0\n","Loss = tensor(0.4832, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.66376495361328\n","#############    Validation Set Stats\n","Total Validation Loss = 13.849925994873047\n","  Accuracy: 0.6684\n","  Micro F1: 0.6691\n","  Macro F1: 0.6466\n","\n"," 67% 4/6 [05:00<02:30, 75.05s/it]Loss = 0.0\n","Loss = tensor(0.4239, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.08877182006836\n","#############    Validation Set Stats\n","Total Validation Loss = 14.393515586853027\n","  Accuracy: 0.6656\n","  Micro F1: 0.6662\n","  Macro F1: 0.6283\n","\n"," 83% 5/6 [06:14<01:14, 74.99s/it]Loss = 0.0\n","Loss = tensor(0.3845, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.67692947387695\n","#############    Validation Set Stats\n","Total Validation Loss = 15.24031925201416\n","  Accuracy: 0.6680\n","  Micro F1: 0.6706\n","  Macro F1: 0.6406\n","\n","100% 6/6 [07:29<00:00, 75.00s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.63246154785156\n","#############    Validation Set Stats\n","Total Validation Loss = 13.622833251953125\n","  Accuracy: 0.6814\n","  Micro F1: 0.6749\n","  Macro F1: 0.5596\n","\n"," 17% 1/6 [01:14<06:14, 74.92s/it]Loss = 0.0\n","Loss = tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.509944915771484\n","#############    Validation Set Stats\n","Total Validation Loss = 13.763851165771484\n","  Accuracy: 0.6540\n","  Micro F1: 0.6487\n","  Macro F1: 0.5729\n","\n"," 33% 2/6 [02:30<04:59, 75.00s/it]Loss = 0.0\n","Loss = tensor(0.5474, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.410213470458984\n","#############    Validation Set Stats\n","Total Validation Loss = 13.889631271362305\n","  Accuracy: 0.6554\n","  Micro F1: 0.6501\n","  Macro F1: 0.6224\n","\n"," 50% 3/6 [03:45<03:45, 75.05s/it]Loss = 0.0\n","Loss = tensor(0.4929, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.034481048583984\n","#############    Validation Set Stats\n","Total Validation Loss = 13.713724136352539\n","  Accuracy: 0.6743\n","  Micro F1: 0.6676\n","  Macro F1: 0.6186\n","\n"," 67% 4/6 [05:00<02:30, 75.01s/it]Loss = 0.0\n","Loss = tensor(0.4247, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.33937072753906\n","#############    Validation Set Stats\n","Total Validation Loss = 15.391932487487793\n","  Accuracy: 0.6487\n","  Micro F1: 0.6414\n","  Macro F1: 0.6173\n","\n"," 83% 5/6 [06:15<01:15, 75.02s/it]Loss = 0.0\n","Loss = tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.17082214355469\n","#############    Validation Set Stats\n","Total Validation Loss = 15.69084644317627\n","  Accuracy: 0.6601\n","  Micro F1: 0.6531\n","  Macro F1: 0.6100\n","\n","100% 6/6 [07:30<00:00, 75.07s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6513, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.12272262573242\n","#############    Validation Set Stats\n","Total Validation Loss = 14.64079761505127\n","  Accuracy: 0.6333\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 17% 1/6 [01:14<06:14, 74.88s/it]Loss = 0.0\n","Loss = tensor(0.6460, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.99800109863281\n","#############    Validation Set Stats\n","Total Validation Loss = 14.564234733581543\n","  Accuracy: 0.6333\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 33% 2/6 [02:29<04:58, 74.72s/it]Loss = 0.0\n","Loss = tensor(0.6441, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.68011474609375\n","#############    Validation Set Stats\n","Total Validation Loss = 14.482250213623047\n","  Accuracy: 0.6333\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 50% 3/6 [03:43<03:43, 74.49s/it]Loss = 0.0\n","Loss = tensor(0.6438, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.59947204589844\n","#############    Validation Set Stats\n","Total Validation Loss = 14.460399627685547\n","  Accuracy: 0.6333\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 67% 4/6 [04:57<02:28, 74.36s/it]Loss = 0.0\n","Loss = tensor(0.6497, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.083492279052734\n","#############    Validation Set Stats\n","Total Validation Loss = 13.7380952835083\n","  Accuracy: 0.6863\n","  Micro F1: 0.6837\n","  Macro F1: 0.5568\n","\n"," 83% 5/6 [06:11<01:14, 74.45s/it]Loss = 0.0\n","Loss = tensor(0.6089, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.995609283447266\n","#############    Validation Set Stats\n","Total Validation Loss = 13.49770450592041\n","  Accuracy: 0.6948\n","  Micro F1: 0.6924\n","  Macro F1: 0.5850\n","\n","100% 6/6 [07:26<00:00, 74.49s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6575, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.72325134277344\n","#############    Validation Set Stats\n","Total Validation Loss = 13.222029685974121\n","  Accuracy: 0.7026\n","  Micro F1: 0.7007\n","  Macro F1: 0.6014\n","\n"," 17% 1/6 [01:14<06:13, 74.74s/it]Loss = 0.0\n","Loss = tensor(0.6077, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.61045455932617\n","#############    Validation Set Stats\n","Total Validation Loss = 12.915997505187988\n","  Accuracy: 0.7040\n","  Micro F1: 0.7022\n","  Macro F1: 0.5911\n","\n"," 33% 2/6 [02:29<04:59, 74.83s/it]Loss = 0.0\n","Loss = tensor(0.5723, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.0398063659668\n","#############    Validation Set Stats\n","Total Validation Loss = 13.580687522888184\n","  Accuracy: 0.6339\n","  Micro F1: 0.6365\n","  Macro F1: 0.6192\n","\n"," 50% 3/6 [03:44<03:44, 74.91s/it]Loss = 0.0\n","Loss = tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.690216064453125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.14678955078125\n","  Accuracy: 0.6806\n","  Micro F1: 0.6803\n","  Macro F1: 0.6450\n","\n"," 67% 4/6 [04:59<02:29, 74.95s/it]Loss = 0.0\n","Loss = tensor(0.4447, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.46088409423828\n","#############    Validation Set Stats\n","Total Validation Loss = 14.11408805847168\n","  Accuracy: 0.6800\n","  Micro F1: 0.6818\n","  Macro F1: 0.6498\n","\n"," 83% 5/6 [06:14<01:14, 74.98s/it]Loss = 0.0\n","Loss = tensor(0.4096, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.33856201171875\n","#############    Validation Set Stats\n","Total Validation Loss = 14.554947853088379\n","  Accuracy: 0.6907\n","  Micro F1: 0.6949\n","  Macro F1: 0.6497\n","\n","100% 6/6 [07:29<00:00, 75.00s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6485, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.435890197753906\n","#############    Validation Set Stats\n","Total Validation Loss = 13.699588775634766\n","  Accuracy: 0.6764\n","  Micro F1: 0.6759\n","  Macro F1: 0.5414\n","\n"," 17% 1/6 [01:14<06:13, 74.73s/it]Loss = 0.0\n","Loss = tensor(0.5803, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.115509033203125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.554634094238281\n","  Accuracy: 0.6678\n","  Micro F1: 0.6672\n","  Macro F1: 0.5038\n","\n"," 33% 2/6 [02:29<04:59, 74.80s/it]Loss = 0.0\n","Loss = tensor(0.5304, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.047515869140625\n","#############    Validation Set Stats\n","Total Validation Loss = 13.851649284362793\n","  Accuracy: 0.6785\n","  Micro F1: 0.6803\n","  Macro F1: 0.6162\n","\n"," 50% 3/6 [03:44<03:44, 74.85s/it]Loss = 0.0\n","Loss = tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.28396224975586\n","#############    Validation Set Stats\n","Total Validation Loss = 15.165590286254883\n","  Accuracy: 0.6615\n","  Micro F1: 0.6628\n","  Macro F1: 0.5940\n","\n"," 67% 4/6 [04:59<02:29, 74.88s/it]Loss = 0.0\n","Loss = tensor(0.3680, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.53835678100586\n","#############    Validation Set Stats\n","Total Validation Loss = 17.045146942138672\n","  Accuracy: 0.6317\n","  Micro F1: 0.6321\n","  Macro F1: 0.6025\n","\n"," 83% 5/6 [06:14<01:14, 74.89s/it]Loss = 0.0\n","Loss = tensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.348678588867188\n","#############    Validation Set Stats\n","Total Validation Loss = 16.91439437866211\n","  Accuracy: 0.6601\n","  Micro F1: 0.6613\n","  Macro F1: 0.6097\n","\n","100% 6/6 [07:29<00:00, 74.90s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6754\n","  Micro F1: 0.6747\n","  Macro F1: 0.6240\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N6_jIlPVx0c2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596355295658,"user_tz":-330,"elapsed":2292596,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"6d5a6c80-e4f5-455d-9b26-8468c32a5555"},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-4 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-02 07:23:30.653477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6552, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.33035659790039\n","#############    Validation Set Stats\n","Total Validation Loss = 14.088149070739746\n","  Accuracy: 0.6435\n","  Micro F1: 0.6472\n","  Macro F1: 0.5980\n","\n"," 17% 1/6 [01:15<06:17, 75.58s/it]Loss = 0.0\n","Loss = tensor(0.6049, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.42306137084961\n","#############    Validation Set Stats\n","Total Validation Loss = 13.180846214294434\n","  Accuracy: 0.6932\n","  Micro F1: 0.6983\n","  Macro F1: 0.5844\n","\n"," 33% 2/6 [02:31<05:02, 75.55s/it]Loss = 0.0\n","Loss = tensor(0.5434, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.48180389404297\n","#############    Validation Set Stats\n","Total Validation Loss = 13.41775131225586\n","  Accuracy: 0.6832\n","  Micro F1: 0.6880\n","  Macro F1: 0.6190\n","\n"," 50% 3/6 [03:46<03:46, 75.60s/it]Loss = 0.0\n","Loss = tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.33808898925781\n","#############    Validation Set Stats\n","Total Validation Loss = 14.628533363342285\n","  Accuracy: 0.6595\n","  Micro F1: 0.6618\n","  Macro F1: 0.6173\n","\n"," 67% 4/6 [05:02<02:31, 75.66s/it]Loss = 0.0\n","Loss = tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.030494689941406\n","#############    Validation Set Stats\n","Total Validation Loss = 16.07306480407715\n","  Accuracy: 0.6520\n","  Micro F1: 0.6560\n","  Macro F1: 0.6267\n","\n"," 83% 5/6 [06:18<01:15, 75.69s/it]Loss = 0.0\n","Loss = tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.348031997680664\n","#############    Validation Set Stats\n","Total Validation Loss = 16.65870475769043\n","  Accuracy: 0.6581\n","  Micro F1: 0.6603\n","  Macro F1: 0.6325\n","\n","100% 6/6 [07:33<00:00, 75.63s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6562, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.10459518432617\n","#############    Validation Set Stats\n","Total Validation Loss = 14.468135833740234\n","  Accuracy: 0.6388\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 17% 1/6 [01:14<06:14, 74.98s/it]Loss = 0.0\n","Loss = tensor(0.6291, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.346431732177734\n","#############    Validation Set Stats\n","Total Validation Loss = 13.599468231201172\n","  Accuracy: 0.6885\n","  Micro F1: 0.6822\n","  Macro F1: 0.5596\n","\n"," 33% 2/6 [02:30<05:00, 75.16s/it]Loss = 0.0\n","Loss = tensor(0.5792, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.31388854980469\n","#############    Validation Set Stats\n","Total Validation Loss = 13.63650894165039\n","  Accuracy: 0.6800\n","  Micro F1: 0.6735\n","  Macro F1: 0.5586\n","\n"," 50% 3/6 [03:45<03:45, 75.19s/it]Loss = 0.0\n","Loss = tensor(0.5623, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.52417755126953\n","#############    Validation Set Stats\n","Total Validation Loss = 13.626609802246094\n","  Accuracy: 0.6743\n","  Micro F1: 0.6676\n","  Macro F1: 0.6139\n","\n"," 67% 4/6 [05:01<02:30, 75.29s/it]Loss = 0.0\n","Loss = tensor(0.5009, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.42353439331055\n","#############    Validation Set Stats\n","Total Validation Loss = 14.101578712463379\n","  Accuracy: 0.6676\n","  Micro F1: 0.6589\n","  Macro F1: 0.6057\n","\n"," 83% 5/6 [06:17<01:15, 75.42s/it]Loss = 0.0\n","Loss = tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.48305130004883\n","#############    Validation Set Stats\n","Total Validation Loss = 14.483309745788574\n","  Accuracy: 0.6715\n","  Micro F1: 0.6647\n","  Macro F1: 0.6214\n","\n","100% 6/6 [07:32<00:00, 75.47s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6524, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.89302062988281\n","#############    Validation Set Stats\n","Total Validation Loss = 14.34891414642334\n","  Accuracy: 0.6333\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 17% 1/6 [01:15<06:16, 75.32s/it]Loss = 0.0\n","Loss = tensor(0.6259, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.06696701049805\n","#############    Validation Set Stats\n","Total Validation Loss = 13.54951000213623\n","  Accuracy: 0.6934\n","  Micro F1: 0.6910\n","  Macro F1: 0.5717\n","\n"," 33% 2/6 [02:30<05:01, 75.28s/it]Loss = 0.0\n","Loss = tensor(0.5714, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 50.317996978759766\n","#############    Validation Set Stats\n","Total Validation Loss = 13.284013748168945\n","  Accuracy: 0.6782\n","  Micro F1: 0.6735\n","  Macro F1: 0.5827\n","\n"," 50% 3/6 [03:46<03:46, 75.36s/it]Loss = 0.0\n","Loss = tensor(0.5167, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.11656951904297\n","#############    Validation Set Stats\n","Total Validation Loss = 13.58218765258789\n","  Accuracy: 0.6654\n","  Micro F1: 0.6603\n","  Macro F1: 0.6125\n","\n"," 67% 4/6 [05:01<02:30, 75.50s/it]Loss = 0.0\n","Loss = tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.149078369140625\n","#############    Validation Set Stats\n","Total Validation Loss = 14.385137557983398\n","  Accuracy: 0.6692\n","  Micro F1: 0.6662\n","  Macro F1: 0.6355\n","\n"," 83% 5/6 [06:17<01:15, 75.55s/it]Loss = 0.0\n","Loss = tensor(0.4032, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.695716857910156\n","#############    Validation Set Stats\n","Total Validation Loss = 15.608430862426758\n","  Accuracy: 0.6550\n","  Micro F1: 0.6516\n","  Macro F1: 0.6160\n","\n","100% 6/6 [07:33<00:00, 75.55s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6330, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.49285125732422\n","#############    Validation Set Stats\n","Total Validation Loss = 14.047891616821289\n","  Accuracy: 0.6459\n","  Micro F1: 0.6467\n","  Macro F1: 0.6176\n","\n"," 17% 1/6 [01:15<06:17, 75.46s/it]Loss = 0.0\n","Loss = tensor(0.5903, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.179534912109375\n","#############    Validation Set Stats\n","Total Validation Loss = 13.447181701660156\n","  Accuracy: 0.6749\n","  Micro F1: 0.6745\n","  Macro F1: 0.6166\n","\n"," 33% 2/6 [02:30<05:01, 75.47s/it]Loss = 0.0\n","Loss = tensor(0.5625, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.058982849121094\n","#############    Validation Set Stats\n","Total Validation Loss = 13.85634708404541\n","  Accuracy: 0.6452\n","  Micro F1: 0.6482\n","  Macro F1: 0.6363\n","\n"," 50% 3/6 [03:46<03:46, 75.51s/it]Loss = 0.0\n","Loss = tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.37108612060547\n","#############    Validation Set Stats\n","Total Validation Loss = 14.781058311462402\n","  Accuracy: 0.6367\n","  Micro F1: 0.6394\n","  Macro F1: 0.5880\n","\n"," 67% 4/6 [05:02<02:31, 75.56s/it]Loss = 0.0\n","Loss = tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.102561950683594\n","#############    Validation Set Stats\n","Total Validation Loss = 15.87031364440918\n","  Accuracy: 0.6481\n","  Micro F1: 0.6511\n","  Macro F1: 0.6186\n","\n"," 83% 5/6 [06:17<01:15, 75.52s/it]Loss = 0.0\n","Loss = tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.860666275024414\n","#############    Validation Set Stats\n","Total Validation Loss = 17.179685592651367\n","  Accuracy: 0.6481\n","  Micro F1: 0.6511\n","  Macro F1: 0.6200\n","\n","100% 6/6 [07:33<00:00, 75.52s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6574, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.05890655517578\n","#############    Validation Set Stats\n","Total Validation Loss = 13.747722625732422\n","  Accuracy: 0.6735\n","  Micro F1: 0.6730\n","  Macro F1: 0.5453\n","\n"," 17% 1/6 [01:15<06:15, 75.18s/it]Loss = 0.0\n","Loss = tensor(0.5944, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.630889892578125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.578988075256348\n","  Accuracy: 0.6806\n","  Micro F1: 0.6803\n","  Macro F1: 0.5445\n","\n"," 33% 2/6 [02:30<05:01, 75.28s/it]Loss = 0.0\n","Loss = tensor(0.5374, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.23649215698242\n","#############    Validation Set Stats\n","Total Validation Loss = 13.541215896606445\n","  Accuracy: 0.6700\n","  Micro F1: 0.6715\n","  Macro F1: 0.6100\n","\n"," 50% 3/6 [03:46<03:46, 75.43s/it]Loss = 0.0\n","Loss = tensor(0.4691, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.55422592163086\n","#############    Validation Set Stats\n","Total Validation Loss = 15.440092086791992\n","  Accuracy: 0.6217\n","  Micro F1: 0.6219\n","  Macro F1: 0.5739\n","\n"," 67% 4/6 [05:02<02:31, 75.58s/it]Loss = 0.0\n","Loss = tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.003135681152344\n","#############    Validation Set Stats\n","Total Validation Loss = 16.826189041137695\n","  Accuracy: 0.6424\n","  Micro F1: 0.6453\n","  Macro F1: 0.5855\n","\n"," 83% 5/6 [06:18<01:15, 75.72s/it]Loss = 0.0\n","Loss = tensor(0.3290, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.32684898376465\n","#############    Validation Set Stats\n","Total Validation Loss = 17.7205753326416\n","  Accuracy: 0.6160\n","  Micro F1: 0.6161\n","  Macro F1: 0.5909\n","\n","100% 6/6 [07:34<00:00, 75.76s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6628\n","  Micro F1: 0.6622\n","  Macro F1: 0.6271\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J71qgK7dx0_W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596357557769,"user_tz":-330,"elapsed":2262132,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"1616f697-4fbe-4ca8-ff6e-a6a61651250f"},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 50 --learning_rate 1e-3 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-02 08:01:43.233193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6436, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.690155029296875\n","#############    Validation Set Stats\n","Total Validation Loss = 13.685133934020996\n","  Accuracy: 0.6847\n","  Micro F1: 0.6895\n","  Macro F1: 0.5777\n","\n"," 17% 1/6 [01:15<06:15, 75.11s/it]Loss = 0.0\n","Loss = tensor(0.5937, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.133968353271484\n","#############    Validation Set Stats\n","Total Validation Loss = 13.524555206298828\n","  Accuracy: 0.6753\n","  Micro F1: 0.6837\n","  Macro F1: 0.5877\n","\n"," 33% 2/6 [02:29<04:59, 74.95s/it]Loss = 0.0\n","Loss = tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.56751251220703\n","#############    Validation Set Stats\n","Total Validation Loss = 14.340886116027832\n","  Accuracy: 0.6353\n","  Micro F1: 0.6370\n","  Macro F1: 0.6191\n","\n"," 50% 3/6 [03:44<03:44, 74.80s/it]Loss = 0.0\n","Loss = tensor(0.5184, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.45903778076172\n","#############    Validation Set Stats\n","Total Validation Loss = 14.759408950805664\n","  Accuracy: 0.6536\n","  Micro F1: 0.6633\n","  Macro F1: 0.6194\n","\n"," 67% 4/6 [04:58<02:29, 74.81s/it]Loss = 0.0\n","Loss = tensor(0.4501, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.610313415527344\n","#############    Validation Set Stats\n","Total Validation Loss = 15.593955039978027\n","  Accuracy: 0.6536\n","  Micro F1: 0.6633\n","  Macro F1: 0.6159\n","\n"," 83% 5/6 [06:13<01:14, 74.71s/it]Loss = 0.0\n","Loss = tensor(0.3786, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.38057327270508\n","#############    Validation Set Stats\n","Total Validation Loss = 16.232229232788086\n","  Accuracy: 0.6437\n","  Micro F1: 0.6531\n","  Macro F1: 0.6141\n","\n","100% 6/6 [07:27<00:00, 74.67s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6487, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.19875717163086\n","#############    Validation Set Stats\n","Total Validation Loss = 13.670439720153809\n","  Accuracy: 0.6843\n","  Micro F1: 0.6778\n","  Macro F1: 0.5618\n","\n"," 17% 1/6 [01:14<06:11, 74.27s/it]Loss = 0.0\n","Loss = tensor(0.6045, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.78928756713867\n","#############    Validation Set Stats\n","Total Validation Loss = 13.940738677978516\n","  Accuracy: 0.6729\n","  Micro F1: 0.6662\n","  Macro F1: 0.5583\n","\n"," 33% 2/6 [02:28<04:57, 74.33s/it]Loss = 0.0\n","Loss = tensor(0.5646, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 50.23606491088867\n","#############    Validation Set Stats\n","Total Validation Loss = 14.066709518432617\n","  Accuracy: 0.6601\n","  Micro F1: 0.6531\n","  Macro F1: 0.6274\n","\n"," 50% 3/6 [03:43<03:43, 74.44s/it]Loss = 0.0\n","Loss = tensor(0.5388, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.35482406616211\n","#############    Validation Set Stats\n","Total Validation Loss = 13.961186408996582\n","  Accuracy: 0.6804\n","  Micro F1: 0.6720\n","  Macro F1: 0.5988\n","\n"," 67% 4/6 [04:58<02:28, 74.50s/it]Loss = 0.0\n","Loss = tensor(0.4616, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.25174331665039\n","#############    Validation Set Stats\n","Total Validation Loss = 14.359766960144043\n","  Accuracy: 0.6772\n","  Micro F1: 0.6706\n","  Macro F1: 0.6228\n","\n"," 83% 5/6 [06:12<01:14, 74.54s/it]Loss = 0.0\n","Loss = tensor(0.4206, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.8907585144043\n","#############    Validation Set Stats\n","Total Validation Loss = 14.80370044708252\n","  Accuracy: 0.6814\n","  Micro F1: 0.6749\n","  Macro F1: 0.6373\n","\n","100% 6/6 [07:27<00:00, 74.55s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6536, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.9145622253418\n","#############    Validation Set Stats\n","Total Validation Loss = 13.537372589111328\n","  Accuracy: 0.6887\n","  Micro F1: 0.6880\n","  Macro F1: 0.5800\n","\n"," 17% 1/6 [01:14<06:10, 74.20s/it]Loss = 0.0\n","Loss = tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.34071731567383\n","#############    Validation Set Stats\n","Total Validation Loss = 13.502662658691406\n","  Accuracy: 0.6920\n","  Micro F1: 0.6895\n","  Macro F1: 0.5669\n","\n"," 33% 2/6 [02:28<04:57, 74.25s/it]Loss = 0.0\n","Loss = tensor(0.5790, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.81739807128906\n","#############    Validation Set Stats\n","Total Validation Loss = 13.345734596252441\n","  Accuracy: 0.6796\n","  Micro F1: 0.6749\n","  Macro F1: 0.5852\n","\n"," 50% 3/6 [03:43<03:42, 74.32s/it]Loss = 0.0\n","Loss = tensor(0.5364, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.92914962768555\n","#############    Validation Set Stats\n","Total Validation Loss = 14.189358711242676\n","  Accuracy: 0.6483\n","  Micro F1: 0.6429\n","  Macro F1: 0.6023\n","\n"," 67% 4/6 [04:57<02:28, 74.36s/it]Loss = 0.0\n","Loss = tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.04716491699219\n","#############    Validation Set Stats\n","Total Validation Loss = 14.950563430786133\n","  Accuracy: 0.6234\n","  Micro F1: 0.6210\n","  Macro F1: 0.5998\n","\n"," 83% 5/6 [06:12<01:14, 74.41s/it]Loss = 0.0\n","Loss = tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.39607238769531\n","#############    Validation Set Stats\n","Total Validation Loss = 15.136695861816406\n","  Accuracy: 0.6483\n","  Micro F1: 0.6429\n","  Macro F1: 0.6100\n","\n","100% 6/6 [07:26<00:00, 74.45s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6388, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.259300231933594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.704496383666992\n","  Accuracy: 0.6955\n","  Micro F1: 0.6934\n","  Macro F1: 0.5924\n","\n"," 17% 1/6 [01:14<06:11, 74.33s/it]Loss = 0.0\n","Loss = tensor(0.6003, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.82707595825195\n","#############    Validation Set Stats\n","Total Validation Loss = 13.207789421081543\n","  Accuracy: 0.6955\n","  Micro F1: 0.6934\n","  Macro F1: 0.6164\n","\n"," 33% 2/6 [02:28<04:57, 74.41s/it]Loss = 0.0\n","Loss = tensor(0.5585, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.937129974365234\n","#############    Validation Set Stats\n","Total Validation Loss = 12.948197364807129\n","  Accuracy: 0.7182\n","  Micro F1: 0.7168\n","  Macro F1: 0.6544\n","\n"," 50% 3/6 [03:43<03:43, 74.54s/it]Loss = 0.0\n","Loss = tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.159950256347656\n","#############    Validation Set Stats\n","Total Validation Loss = 13.675911903381348\n","  Accuracy: 0.6685\n","  Micro F1: 0.6657\n","  Macro F1: 0.6265\n","\n"," 67% 4/6 [04:58<02:29, 74.56s/it]Loss = 0.0\n","Loss = tensor(0.4406, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.36967468261719\n","#############    Validation Set Stats\n","Total Validation Loss = 14.71829891204834\n","  Accuracy: 0.6685\n","  Micro F1: 0.6657\n","  Macro F1: 0.6378\n","\n"," 83% 5/6 [06:12<01:14, 74.55s/it]Loss = 0.0\n","Loss = tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.305946350097656\n","#############    Validation Set Stats\n","Total Validation Loss = 15.091313362121582\n","  Accuracy: 0.6827\n","  Micro F1: 0.6803\n","  Macro F1: 0.6372\n","\n","100% 6/6 [07:27<00:00, 74.56s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6429, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.71573257446289\n","#############    Validation Set Stats\n","Total Validation Loss = 13.75051212310791\n","  Accuracy: 0.6749\n","  Micro F1: 0.6745\n","  Macro F1: 0.5403\n","\n"," 17% 1/6 [01:14<06:10, 74.12s/it]Loss = 0.0\n","Loss = tensor(0.5823, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.48556900024414\n","#############    Validation Set Stats\n","Total Validation Loss = 13.579183578491211\n","  Accuracy: 0.6792\n","  Micro F1: 0.6788\n","  Macro F1: 0.5283\n","\n"," 33% 2/6 [02:28<04:56, 74.21s/it]Loss = 0.0\n","Loss = tensor(0.5444, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.56291198730469\n","#############    Validation Set Stats\n","Total Validation Loss = 14.15229320526123\n","  Accuracy: 0.6749\n","  Micro F1: 0.6745\n","  Macro F1: 0.5424\n","\n"," 50% 3/6 [03:43<03:43, 74.37s/it]Loss = 0.0\n","Loss = tensor(0.5065, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.488224029541016\n","#############    Validation Set Stats\n","Total Validation Loss = 14.798169136047363\n","  Accuracy: 0.6558\n","  Micro F1: 0.6569\n","  Macro F1: 0.6107\n","\n"," 67% 4/6 [04:58<02:28, 74.48s/it]Loss = 0.0\n","Loss = tensor(0.4325, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.66872787475586\n","#############    Validation Set Stats\n","Total Validation Loss = 15.840755462646484\n","  Accuracy: 0.6473\n","  Micro F1: 0.6482\n","  Macro F1: 0.5961\n","\n"," 83% 5/6 [06:12<01:14, 74.46s/it]Loss = 0.0\n","Loss = tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.80261993408203\n","#############    Validation Set Stats\n","Total Validation Loss = 16.157108306884766\n","  Accuracy: 0.6558\n","  Micro F1: 0.6569\n","  Macro F1: 0.6213\n","\n","100% 6/6 [07:27<00:00, 74.51s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6715\n","  Micro F1: 0.6710\n","  Macro F1: 0.6285\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OyHdhdmox03P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596359826597,"user_tz":-330,"elapsed":2268842,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"42e188c4-06af-4c98-dd65-16529d4841e9"},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 100 --learning_rate 1e-3 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-02 08:39:25.391893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6453, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.339622497558594\n","#############    Validation Set Stats\n","Total Validation Loss = 13.543801307678223\n","  Accuracy: 0.6889\n","  Micro F1: 0.6939\n","  Macro F1: 0.5828\n","\n"," 17% 1/6 [01:15<06:16, 75.33s/it]Loss = 0.0\n","Loss = tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.7987174987793\n","#############    Validation Set Stats\n","Total Validation Loss = 13.267304420471191\n","  Accuracy: 0.6993\n","  Micro F1: 0.7026\n","  Macro F1: 0.5861\n","\n"," 33% 2/6 [02:30<05:00, 75.23s/it]Loss = 0.0\n","Loss = tensor(0.5461, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.154293060302734\n","#############    Validation Set Stats\n","Total Validation Loss = 13.340502738952637\n","  Accuracy: 0.6761\n","  Micro F1: 0.6808\n","  Macro F1: 0.6350\n","\n"," 50% 3/6 [03:45<03:45, 75.16s/it]Loss = 0.0\n","Loss = tensor(0.4832, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.66376495361328\n","#############    Validation Set Stats\n","Total Validation Loss = 13.849925994873047\n","  Accuracy: 0.6684\n","  Micro F1: 0.6691\n","  Macro F1: 0.6466\n","\n"," 67% 4/6 [05:00<02:30, 75.12s/it]Loss = 0.0\n","Loss = tensor(0.4239, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.08877182006836\n","#############    Validation Set Stats\n","Total Validation Loss = 14.393515586853027\n","  Accuracy: 0.6656\n","  Micro F1: 0.6662\n","  Macro F1: 0.6283\n","\n"," 83% 5/6 [06:15<01:15, 75.02s/it]Loss = 0.0\n","Loss = tensor(0.3845, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.67692947387695\n","#############    Validation Set Stats\n","Total Validation Loss = 15.24031925201416\n","  Accuracy: 0.6680\n","  Micro F1: 0.6706\n","  Macro F1: 0.6406\n","\n","100% 6/6 [07:30<00:00, 75.01s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.63246154785156\n","#############    Validation Set Stats\n","Total Validation Loss = 13.622833251953125\n","  Accuracy: 0.6814\n","  Micro F1: 0.6749\n","  Macro F1: 0.5596\n","\n"," 17% 1/6 [01:14<06:14, 74.98s/it]Loss = 0.0\n","Loss = tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.509944915771484\n","#############    Validation Set Stats\n","Total Validation Loss = 13.763851165771484\n","  Accuracy: 0.6540\n","  Micro F1: 0.6487\n","  Macro F1: 0.5729\n","\n"," 33% 2/6 [02:29<04:59, 74.97s/it]Loss = 0.0\n","Loss = tensor(0.5474, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.410213470458984\n","#############    Validation Set Stats\n","Total Validation Loss = 13.889631271362305\n","  Accuracy: 0.6554\n","  Micro F1: 0.6501\n","  Macro F1: 0.6224\n","\n"," 50% 3/6 [03:44<03:44, 74.95s/it]Loss = 0.0\n","Loss = tensor(0.4929, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.034481048583984\n","#############    Validation Set Stats\n","Total Validation Loss = 13.713724136352539\n","  Accuracy: 0.6743\n","  Micro F1: 0.6676\n","  Macro F1: 0.6186\n","\n"," 67% 4/6 [04:59<02:29, 74.91s/it]Loss = 0.0\n","Loss = tensor(0.4247, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.33937072753906\n","#############    Validation Set Stats\n","Total Validation Loss = 15.391932487487793\n","  Accuracy: 0.6487\n","  Micro F1: 0.6414\n","  Macro F1: 0.6173\n","\n"," 83% 5/6 [06:14<01:14, 74.88s/it]Loss = 0.0\n","Loss = tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.17082214355469\n","#############    Validation Set Stats\n","Total Validation Loss = 15.69084644317627\n","  Accuracy: 0.6601\n","  Micro F1: 0.6531\n","  Macro F1: 0.6100\n","\n","100% 6/6 [07:29<00:00, 74.88s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6513, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.12272262573242\n","#############    Validation Set Stats\n","Total Validation Loss = 14.64079761505127\n","  Accuracy: 0.6333\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 17% 1/6 [01:14<06:12, 74.50s/it]Loss = 0.0\n","Loss = tensor(0.6460, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.99800109863281\n","#############    Validation Set Stats\n","Total Validation Loss = 14.564234733581543\n","  Accuracy: 0.6333\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 33% 2/6 [02:28<04:57, 74.38s/it]Loss = 0.0\n","Loss = tensor(0.6441, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.68011474609375\n","#############    Validation Set Stats\n","Total Validation Loss = 14.482250213623047\n","  Accuracy: 0.6333\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 50% 3/6 [03:42<03:42, 74.26s/it]Loss = 0.0\n","Loss = tensor(0.6438, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.59947204589844\n","#############    Validation Set Stats\n","Total Validation Loss = 14.460399627685547\n","  Accuracy: 0.6333\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 67% 4/6 [04:56<02:28, 74.19s/it]Loss = 0.0\n","Loss = tensor(0.6497, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.083492279052734\n","#############    Validation Set Stats\n","Total Validation Loss = 13.7380952835083\n","  Accuracy: 0.6863\n","  Micro F1: 0.6837\n","  Macro F1: 0.5568\n","\n"," 83% 5/6 [06:11<01:14, 74.29s/it]Loss = 0.0\n","Loss = tensor(0.6089, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.995609283447266\n","#############    Validation Set Stats\n","Total Validation Loss = 13.49770450592041\n","  Accuracy: 0.6948\n","  Micro F1: 0.6924\n","  Macro F1: 0.5850\n","\n","100% 6/6 [07:26<00:00, 74.34s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6575, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.72325134277344\n","#############    Validation Set Stats\n","Total Validation Loss = 13.222029685974121\n","  Accuracy: 0.7026\n","  Micro F1: 0.7007\n","  Macro F1: 0.6014\n","\n"," 17% 1/6 [01:14<06:12, 74.57s/it]Loss = 0.0\n","Loss = tensor(0.6077, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.61045455932617\n","#############    Validation Set Stats\n","Total Validation Loss = 12.915997505187988\n","  Accuracy: 0.7040\n","  Micro F1: 0.7022\n","  Macro F1: 0.5911\n","\n"," 33% 2/6 [02:29<04:58, 74.62s/it]Loss = 0.0\n","Loss = tensor(0.5723, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.0398063659668\n","#############    Validation Set Stats\n","Total Validation Loss = 13.580687522888184\n","  Accuracy: 0.6339\n","  Micro F1: 0.6365\n","  Macro F1: 0.6192\n","\n"," 50% 3/6 [03:44<03:44, 74.68s/it]Loss = 0.0\n","Loss = tensor(0.5189, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.690216064453125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.14678955078125\n","  Accuracy: 0.6806\n","  Micro F1: 0.6803\n","  Macro F1: 0.6450\n","\n"," 67% 4/6 [04:58<02:29, 74.73s/it]Loss = 0.0\n","Loss = tensor(0.4447, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.46088409423828\n","#############    Validation Set Stats\n","Total Validation Loss = 14.11408805847168\n","  Accuracy: 0.6800\n","  Micro F1: 0.6818\n","  Macro F1: 0.6498\n","\n"," 83% 5/6 [06:13<01:14, 74.78s/it]Loss = 0.0\n","Loss = tensor(0.4096, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.33856201171875\n","#############    Validation Set Stats\n","Total Validation Loss = 14.554947853088379\n","  Accuracy: 0.6907\n","  Micro F1: 0.6949\n","  Macro F1: 0.6497\n","\n","100% 6/6 [07:28<00:00, 74.80s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6485, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.435890197753906\n","#############    Validation Set Stats\n","Total Validation Loss = 13.699588775634766\n","  Accuracy: 0.6764\n","  Micro F1: 0.6759\n","  Macro F1: 0.5414\n","\n"," 17% 1/6 [01:14<06:13, 74.74s/it]Loss = 0.0\n","Loss = tensor(0.5803, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.115509033203125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.554634094238281\n","  Accuracy: 0.6678\n","  Micro F1: 0.6672\n","  Macro F1: 0.5038\n","\n"," 33% 2/6 [02:29<04:59, 74.80s/it]Loss = 0.0\n","Loss = tensor(0.5304, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.047515869140625\n","#############    Validation Set Stats\n","Total Validation Loss = 13.851649284362793\n","  Accuracy: 0.6785\n","  Micro F1: 0.6803\n","  Macro F1: 0.6162\n","\n"," 50% 3/6 [03:44<03:44, 74.83s/it]Loss = 0.0\n","Loss = tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.28396224975586\n","#############    Validation Set Stats\n","Total Validation Loss = 15.165590286254883\n","  Accuracy: 0.6615\n","  Micro F1: 0.6628\n","  Macro F1: 0.5940\n","\n"," 67% 4/6 [04:59<02:29, 74.88s/it]Loss = 0.0\n","Loss = tensor(0.3680, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.53835678100586\n","#############    Validation Set Stats\n","Total Validation Loss = 17.045146942138672\n","  Accuracy: 0.6317\n","  Micro F1: 0.6321\n","  Macro F1: 0.6025\n","\n"," 83% 5/6 [06:14<01:14, 74.98s/it]Loss = 0.0\n","Loss = tensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.348678588867188\n","#############    Validation Set Stats\n","Total Validation Loss = 16.91439437866211\n","  Accuracy: 0.6601\n","  Micro F1: 0.6613\n","  Macro F1: 0.6097\n","\n","100% 6/6 [07:29<00:00, 74.97s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6754\n","  Micro F1: 0.6747\n","  Macro F1: 0.6240\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vGHXFsoXx0SP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596362120511,"user_tz":-330,"elapsed":2293926,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"08417a98-7340-4e64-9ace-08fd1a164927"},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_22.pkl --feature_dim 22 --hidden_size 200 --learning_rate 1e-3 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-02 09:17:14.205578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n","Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6552, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.33035659790039\n","#############    Validation Set Stats\n","Total Validation Loss = 14.088149070739746\n","  Accuracy: 0.6435\n","  Micro F1: 0.6472\n","  Macro F1: 0.5980\n","\n"," 17% 1/6 [01:15<06:18, 75.73s/it]Loss = 0.0\n","Loss = tensor(0.6049, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.42306137084961\n","#############    Validation Set Stats\n","Total Validation Loss = 13.180846214294434\n","  Accuracy: 0.6932\n","  Micro F1: 0.6983\n","  Macro F1: 0.5844\n","\n"," 33% 2/6 [02:31<05:02, 75.71s/it]Loss = 0.0\n","Loss = tensor(0.5434, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.48180389404297\n","#############    Validation Set Stats\n","Total Validation Loss = 13.41775131225586\n","  Accuracy: 0.6832\n","  Micro F1: 0.6880\n","  Macro F1: 0.6190\n","\n"," 50% 3/6 [03:46<03:46, 75.66s/it]Loss = 0.0\n","Loss = tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.33808898925781\n","#############    Validation Set Stats\n","Total Validation Loss = 14.628533363342285\n","  Accuracy: 0.6595\n","  Micro F1: 0.6618\n","  Macro F1: 0.6173\n","\n"," 67% 4/6 [05:02<02:31, 75.75s/it]Loss = 0.0\n","Loss = tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.030494689941406\n","#############    Validation Set Stats\n","Total Validation Loss = 16.07306480407715\n","  Accuracy: 0.6520\n","  Micro F1: 0.6560\n","  Macro F1: 0.6267\n","\n"," 83% 5/6 [06:18<01:15, 75.73s/it]Loss = 0.0\n","Loss = tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.348031997680664\n","#############    Validation Set Stats\n","Total Validation Loss = 16.65870475769043\n","  Accuracy: 0.6581\n","  Micro F1: 0.6603\n","  Macro F1: 0.6325\n","\n","100% 6/6 [07:34<00:00, 75.69s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6562, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.10459518432617\n","#############    Validation Set Stats\n","Total Validation Loss = 14.468135833740234\n","  Accuracy: 0.6388\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 17% 1/6 [01:15<06:16, 75.37s/it]Loss = 0.0\n","Loss = tensor(0.6291, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.346431732177734\n","#############    Validation Set Stats\n","Total Validation Loss = 13.599468231201172\n","  Accuracy: 0.6885\n","  Micro F1: 0.6822\n","  Macro F1: 0.5596\n","\n"," 33% 2/6 [02:30<05:01, 75.42s/it]Loss = 0.0\n","Loss = tensor(0.5792, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.31388854980469\n","#############    Validation Set Stats\n","Total Validation Loss = 13.63650894165039\n","  Accuracy: 0.6800\n","  Micro F1: 0.6735\n","  Macro F1: 0.5586\n","\n"," 50% 3/6 [03:46<03:46, 75.49s/it]Loss = 0.0\n","Loss = tensor(0.5623, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.52417755126953\n","#############    Validation Set Stats\n","Total Validation Loss = 13.626609802246094\n","  Accuracy: 0.6743\n","  Micro F1: 0.6676\n","  Macro F1: 0.6139\n","\n"," 67% 4/6 [05:02<02:31, 75.66s/it]Loss = 0.0\n","Loss = tensor(0.5009, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.42353439331055\n","#############    Validation Set Stats\n","Total Validation Loss = 14.101578712463379\n","  Accuracy: 0.6676\n","  Micro F1: 0.6589\n","  Macro F1: 0.6057\n","\n"," 83% 5/6 [06:18<01:15, 75.67s/it]Loss = 0.0\n","Loss = tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.48305130004883\n","#############    Validation Set Stats\n","Total Validation Loss = 14.483309745788574\n","  Accuracy: 0.6715\n","  Micro F1: 0.6647\n","  Macro F1: 0.6214\n","\n","100% 6/6 [07:33<00:00, 75.63s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6524, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.89302062988281\n","#############    Validation Set Stats\n","Total Validation Loss = 14.34891414642334\n","  Accuracy: 0.6333\n","  Micro F1: 0.6312\n","  Macro F1: 0.3870\n","\n"," 17% 1/6 [01:15<06:15, 75.18s/it]Loss = 0.0\n","Loss = tensor(0.6259, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 54.06696701049805\n","#############    Validation Set Stats\n","Total Validation Loss = 13.54951000213623\n","  Accuracy: 0.6934\n","  Micro F1: 0.6910\n","  Macro F1: 0.5717\n","\n"," 33% 2/6 [02:30<05:01, 75.30s/it]Loss = 0.0\n","Loss = tensor(0.5714, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 50.317996978759766\n","#############    Validation Set Stats\n","Total Validation Loss = 13.284013748168945\n","  Accuracy: 0.6782\n","  Micro F1: 0.6735\n","  Macro F1: 0.5827\n","\n"," 50% 3/6 [03:46<03:46, 75.46s/it]Loss = 0.0\n","Loss = tensor(0.5167, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.11656951904297\n","#############    Validation Set Stats\n","Total Validation Loss = 13.58218765258789\n","  Accuracy: 0.6654\n","  Micro F1: 0.6603\n","  Macro F1: 0.6125\n","\n"," 67% 4/6 [05:02<02:30, 75.48s/it]Loss = 0.0\n","Loss = tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.149078369140625\n","#############    Validation Set Stats\n","Total Validation Loss = 14.385137557983398\n","  Accuracy: 0.6692\n","  Micro F1: 0.6662\n","  Macro F1: 0.6355\n","\n"," 83% 5/6 [06:17<01:15, 75.52s/it]Loss = 0.0\n","Loss = tensor(0.4032, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.695716857910156\n","#############    Validation Set Stats\n","Total Validation Loss = 15.608430862426758\n","  Accuracy: 0.6550\n","  Micro F1: 0.6516\n","  Macro F1: 0.6160\n","\n","100% 6/6 [07:33<00:00, 75.60s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6330, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.49285125732422\n","#############    Validation Set Stats\n","Total Validation Loss = 14.047891616821289\n","  Accuracy: 0.6459\n","  Micro F1: 0.6467\n","  Macro F1: 0.6176\n","\n"," 17% 1/6 [01:15<06:17, 75.59s/it]Loss = 0.0\n","Loss = tensor(0.5903, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.179534912109375\n","#############    Validation Set Stats\n","Total Validation Loss = 13.447181701660156\n","  Accuracy: 0.6749\n","  Micro F1: 0.6745\n","  Macro F1: 0.6166\n","\n"," 33% 2/6 [02:31<05:02, 75.60s/it]Loss = 0.0\n","Loss = tensor(0.5625, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.058982849121094\n","#############    Validation Set Stats\n","Total Validation Loss = 13.85634708404541\n","  Accuracy: 0.6452\n","  Micro F1: 0.6482\n","  Macro F1: 0.6363\n","\n"," 50% 3/6 [03:46<03:46, 75.59s/it]Loss = 0.0\n","Loss = tensor(0.4702, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.37108612060547\n","#############    Validation Set Stats\n","Total Validation Loss = 14.781058311462402\n","  Accuracy: 0.6367\n","  Micro F1: 0.6394\n","  Macro F1: 0.5880\n","\n"," 67% 4/6 [05:02<02:31, 75.64s/it]Loss = 0.0\n","Loss = tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.102561950683594\n","#############    Validation Set Stats\n","Total Validation Loss = 15.87031364440918\n","  Accuracy: 0.6481\n","  Micro F1: 0.6511\n","  Macro F1: 0.6186\n","\n"," 83% 5/6 [06:18<01:15, 75.66s/it]Loss = 0.0\n","Loss = tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 29.860666275024414\n","#############    Validation Set Stats\n","Total Validation Loss = 17.179685592651367\n","  Accuracy: 0.6481\n","  Micro F1: 0.6511\n","  Macro F1: 0.6200\n","\n","100% 6/6 [07:33<00:00, 75.64s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6574, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.05890655517578\n","#############    Validation Set Stats\n","Total Validation Loss = 13.747722625732422\n","  Accuracy: 0.6735\n","  Micro F1: 0.6730\n","  Macro F1: 0.5453\n","\n"," 17% 1/6 [01:15<06:17, 75.49s/it]Loss = 0.0\n","Loss = tensor(0.5944, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.630889892578125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.578988075256348\n","  Accuracy: 0.6806\n","  Micro F1: 0.6803\n","  Macro F1: 0.5445\n","\n"," 33% 2/6 [02:31<05:02, 75.63s/it]Loss = 0.0\n","Loss = tensor(0.5374, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.23649215698242\n","#############    Validation Set Stats\n","Total Validation Loss = 13.541215896606445\n","  Accuracy: 0.6700\n","  Micro F1: 0.6715\n","  Macro F1: 0.6100\n","\n"," 50% 3/6 [03:46<03:46, 75.59s/it]Loss = 0.0\n","Loss = tensor(0.4691, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 40.55422592163086\n","#############    Validation Set Stats\n","Total Validation Loss = 15.440092086791992\n","  Accuracy: 0.6217\n","  Micro F1: 0.6219\n","  Macro F1: 0.5739\n","\n"," 67% 4/6 [05:02<02:31, 75.59s/it]Loss = 0.0\n","Loss = tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.003135681152344\n","#############    Validation Set Stats\n","Total Validation Loss = 16.826189041137695\n","  Accuracy: 0.6424\n","  Micro F1: 0.6453\n","  Macro F1: 0.5855\n","\n"," 83% 5/6 [06:18<01:15, 75.63s/it]Loss = 0.0\n","Loss = tensor(0.3290, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 28.32684898376465\n","#############    Validation Set Stats\n","Total Validation Loss = 17.7205753326416\n","  Accuracy: 0.6160\n","  Micro F1: 0.6161\n","  Macro F1: 0.5909\n","\n","100% 6/6 [07:34<00:00, 75.68s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6628\n","  Micro F1: 0.6622\n","  Macro F1: 0.6271\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kSi6514dx_8Z","colab_type":"text"},"source":["## Hate 9"]},{"cell_type":"code","metadata":{"id":"YrTis5YNyBFf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596372564191,"user_tz":-330,"elapsed":3673060,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"0dd80739-533f-4446-f127-fb3826676076"},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-4 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-02 11:48:24.875468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100% 996k/996k [00:00<00:00, 6.36MB/s]\n","Downloading: 100% 625/625 [00:00<00:00, 725kB/s]\n","Downloading: 100% 714M/714M [00:14<00:00, 49.9MB/s]\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6531, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.46624755859375\n","#############    Validation Set Stats\n","Total Validation Loss = 13.889232635498047\n","  Accuracy: 0.6640\n","  Micro F1: 0.6720\n","  Macro F1: 0.5756\n","\n"," 17% 1/6 [01:59<09:57, 119.43s/it]Loss = 0.0\n","Loss = tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.27334213256836\n","#############    Validation Set Stats\n","Total Validation Loss = 14.054346084594727\n","  Accuracy: 0.6772\n","  Micro F1: 0.6837\n","  Macro F1: 0.5815\n","\n"," 33% 2/6 [04:00<07:59, 119.86s/it]Loss = 0.0\n","Loss = tensor(0.5453, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.77689743041992\n","#############    Validation Set Stats\n","Total Validation Loss = 13.939587593078613\n","  Accuracy: 0.6696\n","  Micro F1: 0.6778\n","  Macro F1: 0.6095\n","\n"," 50% 3/6 [06:00<06:00, 120.06s/it]Loss = 0.0\n","Loss = tensor(0.4914, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.505428314208984\n","#############    Validation Set Stats\n","Total Validation Loss = 15.761645317077637\n","  Accuracy: 0.5929\n","  Micro F1: 0.5991\n","  Macro F1: 0.5854\n","\n"," 67% 4/6 [08:01<04:00, 120.13s/it]Loss = 0.0\n","Loss = tensor(0.4175, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.46263122558594\n","#############    Validation Set Stats\n","Total Validation Loss = 16.11012077331543\n","  Accuracy: 0.6345\n","  Micro F1: 0.6399\n","  Macro F1: 0.6090\n","\n"," 83% 5/6 [10:01<02:00, 120.21s/it]Loss = 0.0\n","Loss = tensor(0.3785, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.145145416259766\n","#############    Validation Set Stats\n","Total Validation Loss = 16.6690673828125\n","  Accuracy: 0.6360\n","  Micro F1: 0.6414\n","  Macro F1: 0.6074\n","\n","100% 6/6 [12:02<00:00, 120.38s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6414, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.28293991088867\n","#############    Validation Set Stats\n","Total Validation Loss = 13.820210456848145\n","  Accuracy: 0.6757\n","  Micro F1: 0.6691\n","  Macro F1: 0.5517\n","\n"," 17% 1/6 [01:59<09:59, 119.84s/it]Loss = 0.0\n","Loss = tensor(0.6038, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.26608657836914\n","#############    Validation Set Stats\n","Total Validation Loss = 13.701509475708008\n","  Accuracy: 0.6843\n","  Micro F1: 0.6778\n","  Macro F1: 0.5653\n","\n"," 33% 2/6 [04:00<07:59, 119.98s/it]Loss = 0.0\n","Loss = tensor(0.5643, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.483299255371094\n","#############    Validation Set Stats\n","Total Validation Loss = 13.551942825317383\n","  Accuracy: 0.6658\n","  Micro F1: 0.6589\n","  Macro F1: 0.5594\n","\n"," 50% 3/6 [06:01<06:01, 120.34s/it]Loss = 0.0\n","Loss = tensor(0.5243, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.63916015625\n","#############    Validation Set Stats\n","Total Validation Loss = 14.269397735595703\n","  Accuracy: 0.6569\n","  Micro F1: 0.6516\n","  Macro F1: 0.5968\n","\n"," 67% 4/6 [08:02<04:01, 120.67s/it]Loss = 0.0\n","Loss = tensor(0.5043, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.225860595703125\n","#############    Validation Set Stats\n","Total Validation Loss = 14.749377250671387\n","  Accuracy: 0.6427\n","  Micro F1: 0.6370\n","  Macro F1: 0.6007\n","\n"," 83% 5/6 [10:04<02:01, 121.00s/it]Loss = 0.0\n","Loss = tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.92815399169922\n","#############    Validation Set Stats\n","Total Validation Loss = 15.142162322998047\n","  Accuracy: 0.6483\n","  Micro F1: 0.6429\n","  Macro F1: 0.6063\n","\n","100% 6/6 [12:06<00:00, 121.00s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6534, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.7412109375\n","#############    Validation Set Stats\n","Total Validation Loss = 13.601229667663574\n","  Accuracy: 0.6891\n","  Micro F1: 0.6866\n","  Macro F1: 0.5666\n","\n"," 17% 1/6 [02:01<10:05, 121.17s/it]Loss = 0.0\n","Loss = tensor(0.5998, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.92744064331055\n","#############    Validation Set Stats\n","Total Validation Loss = 13.315492630004883\n","  Accuracy: 0.6948\n","  Micro F1: 0.6924\n","  Macro F1: 0.5883\n","\n"," 33% 2/6 [04:02<08:04, 121.24s/it]Loss = 0.0\n","Loss = tensor(0.5416, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.26097869873047\n","#############    Validation Set Stats\n","Total Validation Loss = 14.03456974029541\n","  Accuracy: 0.6938\n","  Micro F1: 0.6895\n","  Macro F1: 0.5923\n","\n"," 50% 3/6 [06:04<06:04, 121.38s/it]Loss = 0.0\n","Loss = tensor(0.5049, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.217769622802734\n","#############    Validation Set Stats\n","Total Validation Loss = 14.391385078430176\n","  Accuracy: 0.6532\n","  Micro F1: 0.6516\n","  Macro F1: 0.6268\n","\n"," 67% 4/6 [08:04<04:02, 121.18s/it]Loss = 0.0\n","Loss = tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.426395416259766\n","#############    Validation Set Stats\n","Total Validation Loss = 15.855254173278809\n","  Accuracy: 0.6319\n","  Micro F1: 0.6297\n","  Macro F1: 0.6155\n","\n"," 83% 5/6 [10:04<02:00, 120.67s/it]Loss = 0.0\n","Loss = tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.25804901123047\n","#############    Validation Set Stats\n","Total Validation Loss = 16.176986694335938\n","  Accuracy: 0.6418\n","  Micro F1: 0.6399\n","  Macro F1: 0.6178\n","\n","100% 6/6 [12:04<00:00, 120.82s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6458, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.214473724365234\n","#############    Validation Set Stats\n","Total Validation Loss = 13.11589527130127\n","  Accuracy: 0.7068\n","  Micro F1: 0.7051\n","  Macro F1: 0.5934\n","\n"," 17% 1/6 [02:00<10:00, 120.19s/it]Loss = 0.0\n","Loss = tensor(0.6084, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.62509536743164\n","#############    Validation Set Stats\n","Total Validation Loss = 13.103766441345215\n","  Accuracy: 0.7083\n","  Micro F1: 0.7066\n","  Macro F1: 0.5893\n","\n"," 33% 2/6 [04:00<08:00, 120.19s/it]Loss = 0.0\n","Loss = tensor(0.5725, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 50.49994659423828\n","#############    Validation Set Stats\n","Total Validation Loss = 13.668635368347168\n","  Accuracy: 0.6416\n","  Micro F1: 0.6423\n","  Macro F1: 0.6277\n","\n"," 50% 3/6 [06:01<06:01, 120.36s/it]Loss = 0.0\n","Loss = tensor(0.5351, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.82861328125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.482784271240234\n","  Accuracy: 0.7012\n","  Micro F1: 0.6993\n","  Macro F1: 0.6237\n","\n"," 67% 4/6 [08:01<04:00, 120.37s/it]Loss = 0.0\n","Loss = tensor(0.4773, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.88479232788086\n","#############    Validation Set Stats\n","Total Validation Loss = 13.700318336486816\n","  Accuracy: 0.6863\n","  Micro F1: 0.6861\n","  Macro F1: 0.6430\n","\n"," 83% 5/6 [10:02<02:00, 120.51s/it]Loss = 0.0\n","Loss = tensor(0.4551, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.235435485839844\n","#############    Validation Set Stats\n","Total Validation Loss = 14.560704231262207\n","  Accuracy: 0.6672\n","  Micro F1: 0.6686\n","  Macro F1: 0.6371\n","\n","100% 6/6 [12:02<00:00, 120.43s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6487, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.4796142578125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.728809356689453\n","  Accuracy: 0.6735\n","  Micro F1: 0.6730\n","  Macro F1: 0.5309\n","\n"," 17% 1/6 [01:59<09:58, 119.65s/it]Loss = 0.0\n","Loss = tensor(0.5858, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.01689910888672\n","#############    Validation Set Stats\n","Total Validation Loss = 13.584772109985352\n","  Accuracy: 0.6735\n","  Micro F1: 0.6730\n","  Macro F1: 0.5373\n","\n"," 33% 2/6 [04:00<07:59, 119.94s/it]Loss = 0.0\n","Loss = tensor(0.5396, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 46.58782196044922\n","#############    Validation Set Stats\n","Total Validation Loss = 14.047819137573242\n","  Accuracy: 0.6651\n","  Micro F1: 0.6686\n","  Macro F1: 0.5998\n","\n"," 50% 3/6 [06:01<06:00, 120.22s/it]Loss = 0.0\n","Loss = tensor(0.4744, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.102439880371094\n","#############    Validation Set Stats\n","Total Validation Loss = 14.9240083694458\n","  Accuracy: 0.6430\n","  Micro F1: 0.6438\n","  Macro F1: 0.6095\n","\n"," 67% 4/6 [08:01<04:00, 120.29s/it]Loss = 0.0\n","Loss = tensor(0.4003, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.61743927001953\n","#############    Validation Set Stats\n","Total Validation Loss = 16.455596923828125\n","  Accuracy: 0.6260\n","  Micro F1: 0.6263\n","  Macro F1: 0.5704\n","\n"," 83% 5/6 [10:01<02:00, 120.26s/it]Loss = 0.0\n","Loss = tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.039752960205078\n","#############    Validation Set Stats\n","Total Validation Loss = 17.238948822021484\n","  Accuracy: 0.6352\n","  Micro F1: 0.6336\n","  Macro F1: 0.5987\n","\n","100% 6/6 [12:02<00:00, 120.39s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6601\n","  Micro F1: 0.6604\n","  Macro F1: 0.6190\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"32yEHcgqXIs3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596398462366,"user_tz":-330,"elapsed":4087998,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"2bcbc457-92d7-4b87-8a2a-6001284bfab0"},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-4 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-02 18:53:04.403876: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100% 996k/996k [00:00<00:00, 1.83MB/s]\n","Downloading: 100% 625/625 [00:00<00:00, 416kB/s]\n","Downloading: 100% 714M/714M [00:22<00:00, 31.5MB/s]\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6488, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.22383499145508\n","#############    Validation Set Stats\n","Total Validation Loss = 13.946554183959961\n","  Accuracy: 0.6861\n","  Micro F1: 0.6910\n","  Macro F1: 0.5788\n","\n"," 17% 1/6 [02:14<11:11, 134.32s/it]Loss = 0.0\n","Loss = tensor(0.5905, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.9278564453125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.293558120727539\n","  Accuracy: 0.6857\n","  Micro F1: 0.6924\n","  Macro F1: 0.5915\n","\n"," 33% 2/6 [04:28<08:56, 134.24s/it]Loss = 0.0\n","Loss = tensor(0.5268, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.297576904296875\n","#############    Validation Set Stats\n","Total Validation Loss = 13.927535057067871\n","  Accuracy: 0.6441\n","  Micro F1: 0.6516\n","  Macro F1: 0.6243\n","\n"," 50% 3/6 [06:42<06:42, 134.25s/it]Loss = 0.0\n","Loss = tensor(0.4601, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.2182731628418\n","#############    Validation Set Stats\n","Total Validation Loss = 14.696985244750977\n","  Accuracy: 0.6554\n","  Micro F1: 0.6633\n","  Macro F1: 0.6167\n","\n"," 67% 4/6 [08:57<04:28, 134.34s/it]Loss = 0.0\n","Loss = tensor(0.4199, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.102874755859375\n","#############    Validation Set Stats\n","Total Validation Loss = 16.005739212036133\n","  Accuracy: 0.6654\n","  Micro F1: 0.6735\n","  Macro F1: 0.6216\n","\n"," 83% 5/6 [11:11<02:14, 134.32s/it]Loss = 0.0\n","Loss = tensor(0.3562, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 30.54286766052246\n","#############    Validation Set Stats\n","Total Validation Loss = 16.72179412841797\n","  Accuracy: 0.6544\n","  Micro F1: 0.6603\n","  Macro F1: 0.6312\n","\n","100% 6/6 [13:25<00:00, 134.26s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6470, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.926212310791016\n","#############    Validation Set Stats\n","Total Validation Loss = 14.218841552734375\n","  Accuracy: 0.6700\n","  Micro F1: 0.6633\n","  Macro F1: 0.5689\n","\n"," 17% 1/6 [02:13<11:08, 133.65s/it]Loss = 0.0\n","Loss = tensor(0.6070, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.28755187988281\n","#############    Validation Set Stats\n","Total Validation Loss = 13.506296157836914\n","  Accuracy: 0.6747\n","  Micro F1: 0.6662\n","  Macro F1: 0.5812\n","\n"," 33% 2/6 [04:27<08:55, 133.78s/it]Loss = 0.0\n","Loss = tensor(0.5502, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.06886672973633\n","#############    Validation Set Stats\n","Total Validation Loss = 13.612342834472656\n","  Accuracy: 0.6672\n","  Micro F1: 0.6603\n","  Macro F1: 0.5975\n","\n"," 50% 3/6 [06:42<06:41, 133.94s/it]Loss = 0.0\n","Loss = tensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.592742919921875\n","#############    Validation Set Stats\n","Total Validation Loss = 15.26196002960205\n","  Accuracy: 0.6530\n","  Micro F1: 0.6458\n","  Macro F1: 0.5869\n","\n"," 67% 4/6 [08:56<04:27, 133.98s/it]Loss = 0.0\n","Loss = tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.493309020996094\n","#############    Validation Set Stats\n","Total Validation Loss = 15.854381561279297\n","  Accuracy: 0.6422\n","  Micro F1: 0.6385\n","  Macro F1: 0.6011\n","\n"," 83% 5/6 [11:10<02:14, 134.07s/it]Loss = 0.0\n","Loss = tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.217878341674805\n","#############    Validation Set Stats\n","Total Validation Loss = 16.632352828979492\n","  Accuracy: 0.6380\n","  Micro F1: 0.6341\n","  Macro F1: 0.5990\n","\n","100% 6/6 [13:24<00:00, 134.09s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6514, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.501468658447266\n","#############    Validation Set Stats\n","Total Validation Loss = 13.883761405944824\n","  Accuracy: 0.6934\n","  Micro F1: 0.6910\n","  Macro F1: 0.5661\n","\n"," 17% 1/6 [02:13<11:08, 133.73s/it]Loss = 0.0\n","Loss = tensor(0.6003, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.47328186035156\n","#############    Validation Set Stats\n","Total Validation Loss = 13.482852935791016\n","  Accuracy: 0.6853\n","  Micro F1: 0.6808\n","  Macro F1: 0.6034\n","\n"," 33% 2/6 [04:27<08:55, 133.86s/it]Loss = 0.0\n","Loss = tensor(0.5419, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.4231071472168\n","#############    Validation Set Stats\n","Total Validation Loss = 14.172384262084961\n","  Accuracy: 0.6820\n","  Micro F1: 0.6793\n","  Macro F1: 0.6337\n","\n"," 50% 3/6 [06:41<06:41, 133.93s/it]Loss = 0.0\n","Loss = tensor(0.4854, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 41.88634490966797\n","#############    Validation Set Stats\n","Total Validation Loss = 14.886241912841797\n","  Accuracy: 0.6778\n","  Micro F1: 0.6749\n","  Macro F1: 0.6373\n","\n"," 67% 4/6 [08:56<04:28, 134.02s/it]Loss = 0.0\n","Loss = tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.70225143432617\n","#############    Validation Set Stats\n","Total Validation Loss = 17.548879623413086\n","  Accuracy: 0.6017\n","  Micro F1: 0.6006\n","  Macro F1: 0.5956\n","\n"," 83% 5/6 [11:10<02:14, 134.14s/it]Loss = 0.0\n","Loss = tensor(0.3611, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.02652359008789\n","#############    Validation Set Stats\n","Total Validation Loss = 16.33262062072754\n","  Accuracy: 0.6593\n","  Micro F1: 0.6560\n","  Macro F1: 0.6287\n","\n","100% 6/6 [13:24<00:00, 134.14s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6406, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.80946731567383\n","#############    Validation Set Stats\n","Total Validation Loss = 13.395787239074707\n","  Accuracy: 0.6941\n","  Micro F1: 0.6920\n","  Macro F1: 0.5897\n","\n"," 17% 1/6 [02:13<11:08, 133.61s/it]Loss = 0.0\n","Loss = tensor(0.5962, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.85689926147461\n","#############    Validation Set Stats\n","Total Validation Loss = 12.857697486877441\n","  Accuracy: 0.7125\n","  Micro F1: 0.7109\n","  Macro F1: 0.6157\n","\n"," 33% 2/6 [04:27<08:54, 133.70s/it]Loss = 0.0\n","Loss = tensor(0.5527, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.11114501953125\n","#############    Validation Set Stats\n","Total Validation Loss = 13.538023948669434\n","  Accuracy: 0.6367\n","  Micro F1: 0.6394\n","  Macro F1: 0.6175\n","\n"," 50% 3/6 [06:41<06:41, 133.91s/it]Loss = 0.0\n","Loss = tensor(0.5088, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.09173583984375\n","#############    Validation Set Stats\n","Total Validation Loss = 14.057771682739258\n","  Accuracy: 0.6501\n","  Micro F1: 0.6511\n","  Macro F1: 0.6258\n","\n"," 67% 4/6 [08:56<04:28, 134.12s/it]Loss = 0.0\n","Loss = tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.13508987426758\n","#############    Validation Set Stats\n","Total Validation Loss = 14.470292091369629\n","  Accuracy: 0.6891\n","  Micro F1: 0.6891\n","  Macro F1: 0.6455\n","\n"," 83% 5/6 [11:10<02:14, 134.15s/it]Loss = 0.0\n","Loss = tensor(0.3778, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.07737350463867\n","#############    Validation Set Stats\n","Total Validation Loss = 15.559259414672852\n","  Accuracy: 0.6650\n","  Micro F1: 0.6642\n","  Macro F1: 0.6312\n","\n","100% 6/6 [13:24<00:00, 134.12s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6502, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.12440490722656\n","#############    Validation Set Stats\n","Total Validation Loss = 13.887903213500977\n","  Accuracy: 0.6749\n","  Micro F1: 0.6745\n","  Macro F1: 0.5341\n","\n"," 17% 1/6 [02:13<11:07, 133.45s/it]Loss = 0.0\n","Loss = tensor(0.6106, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.670345306396484\n","#############    Validation Set Stats\n","Total Validation Loss = 13.687273979187012\n","  Accuracy: 0.6792\n","  Micro F1: 0.6788\n","  Macro F1: 0.5534\n","\n"," 33% 2/6 [04:27<08:54, 133.54s/it]Loss = 0.0\n","Loss = tensor(0.5657, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.00716781616211\n","#############    Validation Set Stats\n","Total Validation Loss = 13.845599174499512\n","  Accuracy: 0.6474\n","  Micro F1: 0.6526\n","  Macro F1: 0.6191\n","\n"," 50% 3/6 [06:41<06:41, 133.76s/it]Loss = 0.0\n","Loss = tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.14828872680664\n","#############    Validation Set Stats\n","Total Validation Loss = 13.933879852294922\n","  Accuracy: 0.6672\n","  Micro F1: 0.6686\n","  Macro F1: 0.6044\n","\n"," 67% 4/6 [08:55<04:27, 133.86s/it]Loss = 0.0\n","Loss = tensor(0.4577, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.61903762817383\n","#############    Validation Set Stats\n","Total Validation Loss = 15.74755573272705\n","  Accuracy: 0.6402\n","  Micro F1: 0.6409\n","  Macro F1: 0.6078\n","\n"," 83% 5/6 [11:09<02:13, 133.96s/it]Loss = 0.0\n","Loss = tensor(0.3999, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 34.517433166503906\n","#############    Validation Set Stats\n","Total Validation Loss = 16.104331970214844\n","  Accuracy: 0.6501\n","  Micro F1: 0.6511\n","  Macro F1: 0.6085\n","\n","100% 6/6 [13:24<00:00, 134.02s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6622\n","  Micro F1: 0.6631\n","  Macro F1: 0.6268\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cIhZbh9SXJQt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596402549226,"user_tz":-330,"elapsed":8161944,"user":{"displayName":"Ayush Suhane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghr6DOVqzslON58L-Ss6UQIxRgfg0Q77bLJSlPeDw=s64","userId":"16041326713818823680"}},"outputId":"1d97891d-678e-4548-c970-664c32ec6708"},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-4 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-02 20:01:04.114039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6466, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.60493850708008\n","#############    Validation Set Stats\n","Total Validation Loss = 13.391907691955566\n","  Accuracy: 0.6893\n","  Micro F1: 0.6924\n","  Macro F1: 0.5799\n","\n"," 17% 1/6 [02:15<11:19, 135.82s/it]Loss = 0.0\n","Loss = tensor(0.5876, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.801692962646484\n","#############    Validation Set Stats\n","Total Validation Loss = 13.701056480407715\n","  Accuracy: 0.6445\n","  Micro F1: 0.6501\n","  Macro F1: 0.5995\n","\n"," 33% 2/6 [04:31<09:03, 135.83s/it]Loss = 0.0\n","Loss = tensor(0.5500, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.583160400390625\n","#############    Validation Set Stats\n","Total Validation Loss = 13.493005752563477\n","  Accuracy: 0.6629\n","  Micro F1: 0.6691\n","  Macro F1: 0.6179\n","\n"," 50% 3/6 [06:47<06:47, 135.79s/it]Loss = 0.0\n","Loss = tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.10630416870117\n","#############    Validation Set Stats\n","Total Validation Loss = 14.770318031311035\n","  Accuracy: 0.6577\n","  Micro F1: 0.6618\n","  Macro F1: 0.6222\n","\n"," 67% 4/6 [09:03<04:31, 135.84s/it]Loss = 0.0\n","Loss = tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.581764221191406\n","#############    Validation Set Stats\n","Total Validation Loss = 15.753067016601562\n","  Accuracy: 0.6648\n","  Micro F1: 0.6691\n","  Macro F1: 0.6331\n","\n"," 83% 5/6 [11:19<02:15, 135.96s/it]Loss = 0.0\n","Loss = tensor(0.3561, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.49186134338379\n","#############    Validation Set Stats\n","Total Validation Loss = 16.497615814208984\n","  Accuracy: 0.6392\n","  Micro F1: 0.6429\n","  Macro F1: 0.6204\n","\n","100% 6/6 [13:35<00:00, 135.92s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6490, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.37129211425781\n","#############    Validation Set Stats\n","Total Validation Loss = 14.007953643798828\n","  Accuracy: 0.6743\n","  Micro F1: 0.6676\n","  Macro F1: 0.5676\n","\n"," 17% 1/6 [02:15<11:15, 135.12s/it]Loss = 0.0\n","Loss = tensor(0.5984, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.66167449951172\n","#############    Validation Set Stats\n","Total Validation Loss = 13.615721702575684\n","  Accuracy: 0.6857\n","  Micro F1: 0.6793\n","  Macro F1: 0.5611\n","\n"," 33% 2/6 [04:30<09:01, 135.32s/it]Loss = 0.0\n","Loss = tensor(0.5550, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.998199462890625\n","#############    Validation Set Stats\n","Total Validation Loss = 13.476740837097168\n","  Accuracy: 0.6828\n","  Micro F1: 0.6764\n","  Macro F1: 0.5920\n","\n"," 50% 3/6 [06:46<06:46, 135.45s/it]Loss = 0.0\n","Loss = tensor(0.5003, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.785125732421875\n","#############    Validation Set Stats\n","Total Validation Loss = 13.898463249206543\n","  Accuracy: 0.6743\n","  Micro F1: 0.6676\n","  Macro F1: 0.5810\n","\n"," 67% 4/6 [09:02<04:30, 135.49s/it]Loss = 0.0\n","Loss = tensor(0.4337, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 37.633243560791016\n","#############    Validation Set Stats\n","Total Validation Loss = 15.04911994934082\n","  Accuracy: 0.6597\n","  Micro F1: 0.6545\n","  Macro F1: 0.6031\n","\n"," 83% 5/6 [11:18<02:15, 135.57s/it]Loss = 0.0\n","Loss = tensor(0.3588, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 31.814748764038086\n","#############    Validation Set Stats\n","Total Validation Loss = 16.096288681030273\n","  Accuracy: 0.6654\n","  Micro F1: 0.6603\n","  Macro F1: 0.6143\n","\n","100% 6/6 [13:33<00:00, 135.61s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6506, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.78420639038086\n","#############    Validation Set Stats\n","Total Validation Loss = 13.893660545349121\n","  Accuracy: 0.6451\n","  Micro F1: 0.6414\n","  Macro F1: 0.4264\n","\n"," 17% 1/6 [02:15<11:15, 135.04s/it]Loss = 0.0\n","Loss = tensor(0.6005, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.43733596801758\n","#############    Validation Set Stats\n","Total Validation Loss = 13.238945007324219\n","  Accuracy: 0.7037\n","  Micro F1: 0.6997\n","  Macro F1: 0.6121\n","\n"," 33% 2/6 [04:30<09:01, 135.30s/it]Loss = 0.0\n","Loss = tensor(0.5576, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.450138092041016\n","#############    Validation Set Stats\n","Total Validation Loss = 13.417508125305176\n","  Accuracy: 0.6802\n","  Micro F1: 0.6793\n","  Macro F1: 0.6215\n","\n"," 50% 3/6 [06:46<06:46, 135.49s/it]Loss = 0.0\n","Loss = tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.34283447265625\n","#############    Validation Set Stats\n","Total Validation Loss = 14.772627830505371\n","  Accuracy: 0.6585\n","  Micro F1: 0.6589\n","  Macro F1: 0.6382\n","\n"," 67% 4/6 [09:02<04:31, 135.52s/it]Loss = 0.0\n","Loss = tensor(0.4472, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.20642852783203\n","#############    Validation Set Stats\n","Total Validation Loss = 15.159293174743652\n","  Accuracy: 0.6759\n","  Micro F1: 0.6749\n","  Macro F1: 0.6402\n","\n"," 83% 5/6 [11:18<02:15, 135.63s/it]Loss = 0.0\n","Loss = tensor(0.3748, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.15572738647461\n","#############    Validation Set Stats\n","Total Validation Loss = 16.168807983398438\n","  Accuracy: 0.6745\n","  Micro F1: 0.6735\n","  Macro F1: 0.6397\n","\n","100% 6/6 [13:34<00:00, 135.75s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6410, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.93803787231445\n","#############    Validation Set Stats\n","Total Validation Loss = 13.689419746398926\n","  Accuracy: 0.7068\n","  Micro F1: 0.7051\n","  Macro F1: 0.5917\n","\n"," 17% 1/6 [02:15<11:17, 135.49s/it]Loss = 0.0\n","Loss = tensor(0.6032, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.07231903076172\n","#############    Validation Set Stats\n","Total Validation Loss = 13.006363868713379\n","  Accuracy: 0.7048\n","  Micro F1: 0.7051\n","  Macro F1: 0.6391\n","\n"," 33% 2/6 [04:31<09:02, 135.52s/it]Loss = 0.0\n","Loss = tensor(0.5430, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.11922836303711\n","#############    Validation Set Stats\n","Total Validation Loss = 13.373270034790039\n","  Accuracy: 0.7139\n","  Micro F1: 0.7124\n","  Macro F1: 0.6124\n","\n"," 50% 3/6 [06:46<06:46, 135.55s/it]Loss = 0.0\n","Loss = tensor(0.5139, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.709537506103516\n","#############    Validation Set Stats\n","Total Validation Loss = 13.747499465942383\n","  Accuracy: 0.6658\n","  Micro F1: 0.6672\n","  Macro F1: 0.6433\n","\n"," 67% 4/6 [09:02<04:31, 135.61s/it]Loss = 0.0\n","Loss = tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.964168548583984\n","#############    Validation Set Stats\n","Total Validation Loss = 15.287964820861816\n","  Accuracy: 0.6793\n","  Micro F1: 0.6832\n","  Macro F1: 0.6497\n","\n"," 83% 5/6 [11:18<02:15, 135.61s/it]Loss = 0.0\n","Loss = tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 32.1037712097168\n","#############    Validation Set Stats\n","Total Validation Loss = 16.14219856262207\n","  Accuracy: 0.6608\n","  Micro F1: 0.6642\n","  Macro F1: 0.6312\n","\n","100% 6/6 [13:33<00:00, 135.63s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6528, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 57.0240364074707\n","#############    Validation Set Stats\n","Total Validation Loss = 14.15866470336914\n","  Accuracy: 0.6416\n","  Micro F1: 0.6423\n","  Macro F1: 0.4202\n","\n"," 17% 1/6 [02:14<11:13, 134.78s/it]Loss = 0.0\n","Loss = tensor(0.6118, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 53.41246032714844\n","#############    Validation Set Stats\n","Total Validation Loss = 13.723219871520996\n","  Accuracy: 0.6778\n","  Micro F1: 0.6774\n","  Macro F1: 0.5361\n","\n"," 33% 2/6 [04:30<08:59, 134.98s/it]Loss = 0.0\n","Loss = tensor(0.5965, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.465057373046875\n","#############    Validation Set Stats\n","Total Validation Loss = 13.775856018066406\n","  Accuracy: 0.6820\n","  Micro F1: 0.6818\n","  Macro F1: 0.5456\n","\n"," 50% 3/6 [06:45<06:45, 135.06s/it]Loss = 0.0\n","Loss = tensor(0.5453, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.114173889160156\n","#############    Validation Set Stats\n","Total Validation Loss = 14.184526443481445\n","  Accuracy: 0.6269\n","  Micro F1: 0.6336\n","  Macro F1: 0.5971\n","\n"," 67% 4/6 [09:00<04:30, 135.19s/it]Loss = 0.0\n","Loss = tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.58894729614258\n","#############    Validation Set Stats\n","Total Validation Loss = 14.934885025024414\n","  Accuracy: 0.6360\n","  Micro F1: 0.6409\n","  Macro F1: 0.5841\n","\n"," 83% 5/6 [11:16<02:15, 135.34s/it]Loss = 0.0\n","Loss = tensor(0.4565, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.54081726074219\n","#############    Validation Set Stats\n","Total Validation Loss = 15.61573314666748\n","  Accuracy: 0.6147\n","  Micro F1: 0.6190\n","  Macro F1: 0.5769\n","\n","100% 6/6 [13:32<00:00, 135.36s/it]\n","==================FINAL RESULTS====================\n","  Accuracy: 0.6625\n","  Micro F1: 0.6642\n","  Macro F1: 0.6269\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B5A_FlFsXJ6w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"9b643f7b-d090-4420-e46a-02fc6f579e5e"},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-3 --num_labels 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-08-03 09:06:36.369263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","Downloading: 100% 996k/996k [00:00<00:00, 1.79MB/s]\n","Downloading: 100% 625/625 [00:00<00:00, 397kB/s]\n","Downloading: 100% 714M/714M [00:12<00:00, 57.3MB/s]\n","  0% 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:577: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n","  self.dropout, self.training, self.bidirectional, self.batch_first)\n","Loss = 0.0\n","Loss = tensor(0.6531, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.46624755859375\n","#############    Validation Set Stats\n","Total Validation Loss = 13.889232635498047\n","  Accuracy: 0.6640\n","  Micro F1: 0.6720\n","  Macro F1: 0.5756\n","\n"," 17% 1/6 [01:59<09:58, 119.61s/it]Loss = 0.0\n","Loss = tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.27334213256836\n","#############    Validation Set Stats\n","Total Validation Loss = 14.054346084594727\n","  Accuracy: 0.6772\n","  Micro F1: 0.6837\n","  Macro F1: 0.5815\n","\n"," 33% 2/6 [04:01<08:01, 120.39s/it]Loss = 0.0\n","Loss = tensor(0.5453, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 47.77689743041992\n","#############    Validation Set Stats\n","Total Validation Loss = 13.939587593078613\n","  Accuracy: 0.6696\n","  Micro F1: 0.6778\n","  Macro F1: 0.6095\n","\n"," 50% 3/6 [06:03<06:02, 120.91s/it]Loss = 0.0\n","Loss = tensor(0.4914, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 42.505428314208984\n","#############    Validation Set Stats\n","Total Validation Loss = 15.761645317077637\n","  Accuracy: 0.5929\n","  Micro F1: 0.5991\n","  Macro F1: 0.5854\n","\n"," 67% 4/6 [08:06<04:02, 121.30s/it]Loss = 0.0\n","Loss = tensor(0.4175, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 36.46263122558594\n","#############    Validation Set Stats\n","Total Validation Loss = 16.11012077331543\n","  Accuracy: 0.6345\n","  Micro F1: 0.6399\n","  Macro F1: 0.6090\n","\n"," 83% 5/6 [10:08<02:01, 121.52s/it]Loss = 0.0\n","Loss = tensor(0.3785, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 33.145145416259766\n","#############    Validation Set Stats\n","Total Validation Loss = 16.6690673828125\n","  Accuracy: 0.6360\n","  Micro F1: 0.6414\n","  Macro F1: 0.6074\n","\n","100% 6/6 [12:10<00:00, 121.71s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6414, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.28293991088867\n","#############    Validation Set Stats\n","Total Validation Loss = 13.820210456848145\n","  Accuracy: 0.6757\n","  Micro F1: 0.6691\n","  Macro F1: 0.5517\n","\n"," 17% 1/6 [02:01<10:07, 121.51s/it]Loss = 0.0\n","Loss = tensor(0.6038, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.26608657836914\n","#############    Validation Set Stats\n","Total Validation Loss = 13.701509475708008\n","  Accuracy: 0.6843\n","  Micro F1: 0.6778\n","  Macro F1: 0.5653\n","\n"," 33% 2/6 [04:03<08:06, 121.56s/it]Loss = 0.0\n","Loss = tensor(0.5643, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 49.483299255371094\n","#############    Validation Set Stats\n","Total Validation Loss = 13.551942825317383\n","  Accuracy: 0.6658\n","  Micro F1: 0.6589\n","  Macro F1: 0.5594\n","\n"," 50% 3/6 [06:05<06:04, 121.65s/it]Loss = 0.0\n","Loss = tensor(0.5243, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 45.63916015625\n","#############    Validation Set Stats\n","Total Validation Loss = 14.269397735595703\n","  Accuracy: 0.6569\n","  Micro F1: 0.6516\n","  Macro F1: 0.5968\n","\n"," 67% 4/6 [08:06<04:03, 121.70s/it]Loss = 0.0\n","Loss = tensor(0.5043, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 43.225860595703125\n","#############    Validation Set Stats\n","Total Validation Loss = 14.749377250671387\n","  Accuracy: 0.6427\n","  Micro F1: 0.6370\n","  Macro F1: 0.6007\n","\n"," 83% 5/6 [10:08<02:01, 121.79s/it]Loss = 0.0\n","Loss = tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 38.92815399169922\n","#############    Validation Set Stats\n","Total Validation Loss = 15.142162322998047\n","  Accuracy: 0.6483\n","  Micro F1: 0.6429\n","  Macro F1: 0.6063\n","\n","100% 6/6 [12:10<00:00, 121.80s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6534, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 55.7412109375\n","#############    Validation Set Stats\n","Total Validation Loss = 13.601229667663574\n","  Accuracy: 0.6891\n","  Micro F1: 0.6866\n","  Macro F1: 0.5666\n","\n"," 17% 1/6 [02:01<10:07, 121.57s/it]Loss = 0.0\n","Loss = tensor(0.5998, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 51.92744064331055\n","#############    Validation Set Stats\n","Total Validation Loss = 13.315492630004883\n","  Accuracy: 0.6948\n","  Micro F1: 0.6924\n","  Macro F1: 0.5883\n","\n"," 33% 2/6 [04:03<08:06, 121.66s/it]Loss = 0.0\n","Loss = tensor(0.5416, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 48.26097869873047\n","#############    Validation Set Stats\n","Total Validation Loss = 14.03456974029541\n","  Accuracy: 0.6938\n","  Micro F1: 0.6895\n","  Macro F1: 0.5923\n","\n"," 50% 3/6 [06:05<06:05, 121.78s/it]Loss = 0.0\n","Loss = tensor(0.5049, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 44.217769622802734\n","#############    Validation Set Stats\n","Total Validation Loss = 14.391385078430176\n","  Accuracy: 0.6532\n","  Micro F1: 0.6516\n","  Macro F1: 0.6268\n","\n"," 67% 4/6 [08:07<04:03, 121.78s/it]Loss = 0.0\n","Loss = tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 39.426395416259766\n","#############    Validation Set Stats\n","Total Validation Loss = 15.855254173278809\n","  Accuracy: 0.6319\n","  Micro F1: 0.6297\n","  Macro F1: 0.6155\n","\n"," 83% 5/6 [10:08<02:01, 121.75s/it]Loss = 0.0\n","Loss = tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 35.25804901123047\n","#############    Validation Set Stats\n","Total Validation Loss = 16.176986694335938\n","  Accuracy: 0.6418\n","  Micro F1: 0.6399\n","  Macro F1: 0.6178\n","\n","100% 6/6 [12:11<00:00, 121.85s/it]\n","  0% 0/6 [00:00<?, ?it/s]Loss = 0.0\n","Loss = tensor(0.6458, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 56.214473724365234\n","#############    Validation Set Stats\n","Total Validation Loss = 13.11589527130127\n","  Accuracy: 0.7068\n","  Micro F1: 0.7051\n","  Macro F1: 0.5934\n","\n"," 17% 1/6 [02:01<10:09, 121.91s/it]Loss = 0.0\n","Loss = tensor(0.6084, device='cuda:0', grad_fn=<DivBackward0>)\n","\n","Total Train Loss = 52.62509536743164\n","#############    Validation Set Stats\n","Total Validation Loss = 13.103766441345215\n","  Accuracy: 0.7083\n","  Micro F1: 0.7066\n","  Macro F1: 0.5893\n","\n"," 33% 2/6 [04:03<08:07, 121.92s/it]Loss = 0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RFk9iSNKXKzb","colab_type":"code","colab":{}},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 50 --learning_rate 1e-4 --num_labels 2!python bert_han_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 100 --learning_rate 1e-3 --num_labels 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6bvpJA6XL7T","colab_type":"code","colab":{}},"source":["!python bert_han_cross_val.py -f Datasets/Hate/data_frame_9.pkl --feature_dim 9 --hidden_size 200 --learning_rate 1e-3 --num_labels 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IoTWDi1D6PJ5","colab_type":"code","colab":{}},"source":["\n"],"execution_count":null,"outputs":[]}]}